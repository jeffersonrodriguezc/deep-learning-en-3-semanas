[
  {
    "objectID": "semana_3/notebooks/Nb_3b_Introduccion_explicabilidad_interpretabilidad.html",
    "href": "semana_3/notebooks/Nb_3b_Introduccion_explicabilidad_interpretabilidad.html",
    "title": "Introducción a la explicabilidad e interpretabilidad en modelos",
    "section": "",
    "text": "Open In Colab\nEn este notebook encontrarás material introductorio para entender los conceptos de expicabilidad e interpretabilidad en modelos de inteligencia artificial.\nAbordaremos el siguiente paso a paso:\n#importamos las librerias necesarias a utilizar\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom sklearn.datasets import load_wine\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\n\n%matplotlib inline"
  },
  {
    "objectID": "semana_3/notebooks/Nb_3b_Introduccion_explicabilidad_interpretabilidad.html#dataset",
    "href": "semana_3/notebooks/Nb_3b_Introduccion_explicabilidad_interpretabilidad.html#dataset",
    "title": "Introducción a la explicabilidad e interpretabilidad en modelos",
    "section": "Dataset",
    "text": "Dataset\nEl dataset cuenta con 178 registros, cada uno con 13 caracteristicas:\n\nAlcohol\nMalic Acid\nAsh\nAlcalinity of Ash\nMagnesium\nTotal Phenols\nFlavanoids\nNonflavanoid Phenols\nProanthocyanins\nColour Intensity\nHue\nOD280/OD315 of diluted wines\nProline\n\nEl dataset contiene 3 clases diferentes.\n\n#Cargamos el conjunto de datos y procesamos\nwine = load_wine()\nX, y = wine.data, wine.target\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\nencoder = OneHotEncoder(sparse_output=False)\ny = encoder.fit_transform(y.reshape(-1, 1))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\nprint(\"Dimension datos de entrenamiento: \", X_train.shape)\nprint(\"Dimension datos de prueba: \", X_test.shape)\n\nDimension datos de entrenamiento:  (124, 13)\nDimension datos de prueba:  (54, 13)\n\n\n\n#Definimos la red neuronal a entrenar y compilamos el modelo\nmodel = Sequential()\n\nmodel.add(Dense(64, input_shape=(X_train.shape[1],), activation='relu'))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(y_train.shape[1], activation='softmax'))\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n\n\n\n#Entrenamos la red\nhistory = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n\n\nEpoch 1/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 5s 457ms/step - accuracy: 0.4024 - loss: 1.0690 - val_accuracy: 0.4800 - val_loss: 0.9569\n\nEpoch 2/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 1s 10ms/step - accuracy: 0.5859 - loss: 0.9022 - val_accuracy: 0.7200 - val_loss: 0.8264\n\nEpoch 3/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.5531 - loss: 0.9294 - val_accuracy: 0.6800 - val_loss: 0.7181\n\nEpoch 4/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.6510 - loss: 0.7846 - val_accuracy: 0.8000 - val_loss: 0.6285\n\nEpoch 5/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step - accuracy: 0.7954 - loss: 0.6378 - val_accuracy: 0.8400 - val_loss: 0.5544\n\nEpoch 6/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.8550 - loss: 0.5862 - val_accuracy: 0.8800 - val_loss: 0.4913\n\nEpoch 7/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.8047 - loss: 0.5755 - val_accuracy: 0.9200 - val_loss: 0.4398\n\nEpoch 8/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.9135 - loss: 0.4490 - val_accuracy: 0.9200 - val_loss: 0.3962\n\nEpoch 9/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.8631 - loss: 0.4508 - val_accuracy: 0.9200 - val_loss: 0.3582\n\nEpoch 10/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.9351 - loss: 0.3836 - val_accuracy: 0.9200 - val_loss: 0.3259\n\nEpoch 11/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.9187 - loss: 0.3678 - val_accuracy: 0.9600 - val_loss: 0.2962\n\nEpoch 12/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.9166 - loss: 0.3108 - val_accuracy: 0.9600 - val_loss: 0.2697\n\nEpoch 13/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.9599 - loss: 0.2927 - val_accuracy: 0.9600 - val_loss: 0.2453\n\nEpoch 14/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.9816 - loss: 0.2769 - val_accuracy: 0.9600 - val_loss: 0.2245\n\nEpoch 15/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step - accuracy: 0.9754 - loss: 0.2512 - val_accuracy: 0.9600 - val_loss: 0.2060\n\nEpoch 16/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.9598 - loss: 0.2288 - val_accuracy: 0.9600 - val_loss: 0.1885\n\nEpoch 17/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.9661 - loss: 0.2238 - val_accuracy: 0.9600 - val_loss: 0.1739\n\nEpoch 18/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - accuracy: 0.9846 - loss: 0.1901 - val_accuracy: 0.9600 - val_loss: 0.1605\n\nEpoch 19/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - accuracy: 0.9228 - loss: 0.2142 - val_accuracy: 0.9600 - val_loss: 0.1489\n\nEpoch 20/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.9784 - loss: 0.1613 - val_accuracy: 0.9600 - val_loss: 0.1389\n\nEpoch 21/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 11ms/step - accuracy: 0.9475 - loss: 0.1762 - val_accuracy: 0.9600 - val_loss: 0.1297\n\nEpoch 22/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.9753 - loss: 0.1485 - val_accuracy: 0.9600 - val_loss: 0.1224\n\nEpoch 23/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.9629 - loss: 0.1458 - val_accuracy: 0.9600 - val_loss: 0.1158\n\nEpoch 24/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.9845 - loss: 0.1045 - val_accuracy: 0.9600 - val_loss: 0.1095\n\nEpoch 25/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.9815 - loss: 0.1060 - val_accuracy: 0.9600 - val_loss: 0.1036\n\nEpoch 26/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.9753 - loss: 0.1269 - val_accuracy: 0.9600 - val_loss: 0.0981\n\nEpoch 27/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.9506 - loss: 0.1140 - val_accuracy: 1.0000 - val_loss: 0.0927\n\nEpoch 28/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step - accuracy: 0.9690 - loss: 0.1359 - val_accuracy: 1.0000 - val_loss: 0.0889\n\nEpoch 29/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.9784 - loss: 0.1052 - val_accuracy: 1.0000 - val_loss: 0.0858\n\nEpoch 30/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.9845 - loss: 0.0811 - val_accuracy: 0.9600 - val_loss: 0.0830\n\nEpoch 31/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.9845 - loss: 0.0730 - val_accuracy: 0.9600 - val_loss: 0.0809\n\nEpoch 32/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 14ms/step - accuracy: 0.9845 - loss: 0.0843 - val_accuracy: 0.9600 - val_loss: 0.0789\n\nEpoch 33/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 13ms/step - accuracy: 0.9939 - loss: 0.0606 - val_accuracy: 0.9600 - val_loss: 0.0763\n\nEpoch 34/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step - accuracy: 1.0000 - loss: 0.0582 - val_accuracy: 0.9600 - val_loss: 0.0733\n\nEpoch 35/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.9845 - loss: 0.0953 - val_accuracy: 0.9600 - val_loss: 0.0708\n\nEpoch 36/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.9690 - loss: 0.0910 - val_accuracy: 0.9600 - val_loss: 0.0694\n\nEpoch 37/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step - accuracy: 0.9960 - loss: 0.0598 - val_accuracy: 0.9600 - val_loss: 0.0684\n\nEpoch 38/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.9939 - loss: 0.0693 - val_accuracy: 0.9600 - val_loss: 0.0696\n\nEpoch 39/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step - accuracy: 0.9939 - loss: 0.0582 - val_accuracy: 0.9600 - val_loss: 0.0703\n\nEpoch 40/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.9815 - loss: 0.0470 - val_accuracy: 0.9600 - val_loss: 0.0717\n\nEpoch 41/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.9753 - loss: 0.0844 - val_accuracy: 1.0000 - val_loss: 0.0715\n\nEpoch 42/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 1.0000 - loss: 0.0556 - val_accuracy: 1.0000 - val_loss: 0.0696\n\nEpoch 43/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.9939 - loss: 0.0501 - val_accuracy: 1.0000 - val_loss: 0.0650\n\nEpoch 44/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 1.0000 - loss: 0.0542 - val_accuracy: 1.0000 - val_loss: 0.0614\n\nEpoch 45/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 1.0000 - loss: 0.0597 - val_accuracy: 1.0000 - val_loss: 0.0559\n\nEpoch 46/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.9753 - loss: 0.0617 - val_accuracy: 1.0000 - val_loss: 0.0512\n\nEpoch 47/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.9845 - loss: 0.0432 - val_accuracy: 1.0000 - val_loss: 0.0481\n\nEpoch 48/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 11ms/step - accuracy: 1.0000 - loss: 0.0344 - val_accuracy: 1.0000 - val_loss: 0.0460\n\nEpoch 49/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step - accuracy: 1.0000 - loss: 0.0337 - val_accuracy: 1.0000 - val_loss: 0.0444\n\nEpoch 50/50\n\n4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 1.0000 - loss: 0.0323 - val_accuracy: 1.0000 - val_loss: 0.0441\n\n\n\n\n\ny_pred = model.predict(X_test)\ny_pred_classes = np.argmax(y_pred, axis=1)\ny_test_classes = np.argmax(y_test, axis=1)\n\naccuracy = accuracy_score(y_test_classes, y_pred_classes)\nprint(f\"Accuracy en el conjunto de prueba: {accuracy:.4f}\")\n\n\n2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step \n\nAccuracy en el conjunto de prueba: 1.0000\n\n\n\n\n\nplt.figure(figsize=(6, 3))\nplt.plot(history.history['accuracy'], label='accuray en entrenamiento')\nplt.plot(history.history['val_accuracy'], label='accuracy de validación')\nplt.xlabel('épocas')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.title('Rendimiento del modelo durante el entrenamiento')\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\n\n\nAhora intentemos explicar/interpretar la red. Que caracteristicas son las que están aportando mas valor a la predicciones. Así, a primera vista, podemos ver que la red neural tiene un rendimiento perfecto, pero no sabemos que es lo que hace. Vamos a convertir esa caja negra el algo mas explicable.\n\n\nwine.feature_names\n\n['alcohol',\n 'malic_acid',\n 'ash',\n 'alcalinity_of_ash',\n 'magnesium',\n 'total_phenols',\n 'flavanoids',\n 'nonflavanoid_phenols',\n 'proanthocyanins',\n 'color_intensity',\n 'hue',\n 'od280/od315_of_diluted_wines',\n 'proline']\n\n\n\n#instalamos SHAP\n!pip install shap\n\n\nCollecting shap\n\n  Downloading shap-0.46.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (24 kB)\n\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap) (1.26.4)\n\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.13.1)\n\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.3.2)\n\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (2.1.4)\n\nRequirement already satisfied: tqdm&gt;=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap) (4.66.5)\n\nRequirement already satisfied: packaging&gt;20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (24.1)\n\nCollecting slicer==0.0.8 (from shap)\n\n  Downloading slicer-0.0.8-py3-none-any.whl.metadata (4.0 kB)\n\nRequirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.60.0)\n\nRequirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.1)\n\nRequirement already satisfied: llvmlite&lt;0.44,&gt;=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba-&gt;shap) (0.43.0)\n\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas-&gt;shap) (2.8.2)\n\nRequirement already satisfied: pytz&gt;=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas-&gt;shap) (2024.1)\n\nRequirement already satisfied: tzdata&gt;=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas-&gt;shap) (2024.1)\n\nRequirement already satisfied: joblib&gt;=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn-&gt;shap) (1.4.2)\n\nRequirement already satisfied: threadpoolctl&gt;=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn-&gt;shap) (3.5.0)\n\nRequirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil&gt;=2.8.2-&gt;pandas-&gt;shap) (1.16.0)\n\nDownloading shap-0.46.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (540 kB)\n\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 540.1/540.1 kB 18.0 MB/s eta 0:00:00\n\nDownloading slicer-0.0.8-py3-none-any.whl (15 kB)\n\nInstalling collected packages: slicer, shap\n\nSuccessfully installed shap-0.46.0 slicer-0.0.8\n\n\n\n\n\n#Computemos los valores SHAP de nuestro modelo\nimport shap\nexplainer = shap.Explainer(model, X_train,feature_names=wine.feature_names)\nshap_values = explainer(X_train)\n\nPermutationExplainer explainer: 125it [00:11,  1.92it/s]\n\n\n\nPor ejemplo. Para nuestro modelo, la caracteristica que mas aporta para que se prediga de la clase 1, es proline, y la que menos aporta es malic_acid.\n\n\nshap.plots.bar(shap_values[:,:,0], max_display=X_train.shape[1])\n\n\n\n\n\n\n\n\n\nPara la clase 2, la caracteristica que mas aporta es alcohol y la que menos aporta a dicha predicción es nonflavanoid_phenols.\n\n\nshap.plots.bar(shap_values[:,:,1], max_display=X_train.shape[1])\n\n\n\n\n\n\n\n\n\nPara la tercera clase, la caracteristica mas importante es huge y la menos importante es magnesium\n\n\nshap.plots.bar(shap_values[:,:,2], max_display=X_train.shape[1])\n\n\n\n\n\n\n\n\n\nAhora tomemos un dato de entrenamiento y veamos como las caracteristicas influyeron para que la red se inclinara por la categoría cierta.\n\n\nclase = y_train[4]\nprint(\"clase: \", clase)\nshap.plots.bar(shap_values[4,:,np.argmax(clase)], max_display=X_train.shape[1])\n\nclase:  [0. 1. 0.]\n\n\n\n\n\n\n\n\n\n\nDel gráfico anterior podemos evidenciar que este ejemplo en contreto tuvo caracteristicas que no influyeron en la decision del modelo (alcalinity_os_ash, malic_acid, nonflavanoid_phenols). Por otro lado la caracteristica que mas influyó en este dato en particular fue proline.\nTambien podriamos ver para cada clase como aporta cada caracteristica a la predicción del modelo.\n\n\nprint(\"clase 1\")\nshap.plots.beeswarm(shap_values[:,:,0], max_display=X.shape[1])\n\nclase 1\n\n\n\n\n\n\n\n\n\n\nprint(\"clase 2\")\nshap.plots.beeswarm(shap_values[:,:,1], max_display=X.shape[1])\n\nclase 2\n\n\n\n\n\n\n\n\n\n\nprint(\"clase 3\")\nshap.plots.beeswarm(shap_values[:,:,2], max_display=X.shape[1])\n\nclase 3"
  },
  {
    "objectID": "semana_3/notebooks/Nb_3b_Introduccion_explicabilidad_interpretabilidad.html#conclusión",
    "href": "semana_3/notebooks/Nb_3b_Introduccion_explicabilidad_interpretabilidad.html#conclusión",
    "title": "Introducción a la explicabilidad e interpretabilidad en modelos",
    "section": "Conclusión:",
    "text": "Conclusión:\n\nNote que ahora podemos entender mucho mejor nuestra red, y que caracteristicas son mas importantes para determinar la clase a predecir. Por ejemplo, esto es muy útil para poder explicar nuestro modelo, para que una persona pueda entender cómo funciona. Por ejemplo, si fuese un conjunto de datos bancarios, saber por cuales caracteristicas fue rechazado un crédito y que así el cliente pueda mejorar."
  },
  {
    "objectID": "semana_3/index.html",
    "href": "semana_3/index.html",
    "title": "Semana 3: Técnicas Avanzadas y Robustez",
    "section": "",
    "text": "La última semana se centra en refinar y aplicar técnicas avanzadas para construir modelos robustos e interpretables.\nTemas Clave:\n\nPrincipios de Generalización.\nTransferencia de Aprendizaje y Fine-tuning.\nExplicabilidad e Interpretabilidad de modelos.\nOptimización de hiperparámetros.\nEntrenamiento Adversarial y Robustez.\n\nEnfoque Práctico: Desarrollarás habilidades para mejorar la eficacia de tus modelos en entornos reales. Implementarás técnicas de transferencia de aprendizaje, fine-tuning, generalización y usarás herramientas de explicabilidad para comprender y comunicar los resultados de modelos complejos.\nMateriales de la Semana:\n\nSlides de la Semana 3 (Próximamente)\nNotebook: Introducción a Transfer Learning y Finetuning\nNotebook: Introducción a Explicabilidad e Interpretabilidad"
  },
  {
    "objectID": "semana_2/notebooks/Nb_2a_Implementando_una_CNN_usando_Keras.html",
    "href": "semana_2/notebooks/Nb_2a_Implementando_una_CNN_usando_Keras.html",
    "title": "Implementado una Red Neuronal Convolucional",
    "section": "",
    "text": "Open In Colab\n#@title Importar librerías\n#importar librerías necesarias\nimport random\nfrom random import randint\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport random\n\nimport tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Input\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.datasets import mnist\n#@title Funciones complementarias\ndef plot_samples_dataset(X, y):\n    # Convertir las etiquetas a enteros\n    y = y.astype(int)\n\n    # Crear la grilla de 4x4\n    fig, axes = plt.subplots(4, 4, figsize=(6, 6))\n    fig.suptitle('Grilla de imágenes del dataset MNIST')\n\n    # Iterar para mostrar las primeras 16 imágenes con sus etiquetas\n    for i, ax in enumerate(axes.flat):\n        img = X.iloc[i].values.reshape(28, 28)\n        label = y[i]\n        ax.imshow(img, cmap='gray')\n        ax.set_title(f'Label: {label}')\n        ax.axis('off')\n\n    plt.show()\n\ndef plot_curva_aprendizaje(mlp):\n    plt.figure(figsize=(8, 5))\n    plt.plot(mlp.loss_curve_, marker='o')\n    plt.title('Pérdida durante el entrenamiento del MLP por iteración')\n    plt.xlabel('Iteración')\n    plt.ylabel('Pérdida (Loss)')\n    plt.grid()\n    plt.show()\n\ndef plot_matriz_confusion(cm):\n    # Visualizar la matriz de confusión usando Seaborn\n    plt.figure(figsize=(10, 7))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=range(10), yticklabels=range(10))\n    plt.xlabel('Etiqueta predicha')\n    plt.ylabel('Etiqueta real')\n    plt.title('Matriz de Confusión para el MLP en el dataset MNIST')\n    plt.show()\n\ndef encontrar_dim_imagen(n_neurons):\n    \"\"\"\n    Encuentra la mejor forma cuadrada (filas, columnas) para una cantidad dada de neuronas.\n    \"\"\"\n    side_length = int(np.sqrt(n_neurons))  # Calcular la raíz cuadrada del número de neuronas\n    if side_length * side_length == n_neurons:\n        return (side_length, side_length)  # Si es un cuadrado perfecto\n    else:\n        # Si no es un cuadrado perfecto, buscamos la mejor aproximación (filas, columnas)\n        for i in range(side_length, 0, -1):\n            if n_neurons % i == 0:\n                return (i, n_neurons // i)  # Devolver filas y columnas\n    return (n_neurons, 1)  # Si no encuentra, retornar en forma de vector (n_neurons, 1)\n\ndef plot_loss_historia_keras(history):\n    # Graficar el histórico de pérdida durante el entrenamiento\n    plt.plot(history.history['loss'], label='Pérdida de Entrenamiento')\n    plt.plot(history.history['val_loss'], label='Pérdida de Validación')\n    plt.title('Pérdida durante el Entrenamiento')\n    plt.xlabel('Época')\n    plt.ylabel('Pérdida')\n    plt.legend()\n    plt.show()\n\ndef plot_acc_historia_keras(history):\n    # Graficar la precisión durante el entrenamiento\n    plt.plot(history.history['accuracy'], label='Precisión de Entrenamiento')\n    plt.plot(history.history['val_accuracy'], label='Precisión de Validación')\n    plt.title('Precisión durante el Entrenamiento')\n    plt.xlabel('Época')\n    plt.ylabel('Precisión')\n    plt.legend()\n    plt.show()\n\ndef visualizacion_filtros_cnn_keras(model):\n    # Obtener las capas convolucionales del modelo\n    conv_layers = [layer for layer in model.layers if 'conv' in layer.name]\n\n    # Definir la figura con una fila por capa convolucional y varias columnas (5 filtros al azar por capa)\n    fig, axes = plt.subplots(len(conv_layers), 5, figsize=(10, len(conv_layers) * 3))\n\n    # Recorrer cada capa convolucional y sus pesos\n    for layer_index, (layer, ax_row) in enumerate(zip(conv_layers, axes)):\n        # Obtener los pesos de la capa (solo el primer tensor, ignorar bias)\n        layer_weights = layer.get_weights()[0]  # shape: (filter_height, filter_width, input_channels, num_filters)\n\n        # Seleccionar 5 filtros de la capa actual\n        num_filters = layer_weights.shape[-1]\n        random_filters = random.sample(range(num_filters), 5)\n\n        # Obtener los límites para la normalización de las imágenes\n        vmin, vmax = layer_weights.min(), layer_weights.max()\n\n        # Dibujar cada filtro seleccionado\n        for filter_index, ax in zip(random_filters, ax_row):\n            # Extraer el filtro correspondiente (shape: filter_height, filter_width, input_channels)\n            filter_weights = layer_weights[..., filter_index]\n\n            # Promediar los canales para visualizar como imagen en escala de grises\n            if filter_weights.shape[-1] &gt; 1:\n                filter_weights = np.mean(filter_weights, axis=-1)  # Promedio sobre los canales de entrada\n\n            # Dibujar la imagen del filtro\n            ax.matshow(filter_weights, cmap=plt.cm.gray, vmin=0.5 * vmin, vmax=0.5 * vmax)\n            ax.set_xticks([])\n            ax.set_yticks([])\n            ax.set_title(f'Capa {layer_index + 1}, Filtro {filter_index}')\n\n    plt.suptitle('Visualización de Filtros de las Capas Convolucionales de Keras')\n    plt.tight_layout()\n    plt.show()\n\ndef visualizacion_feature_maps(model, image):\n    # Crear un nuevo modelo que toma la misma entrada pero cuya salida son los mapas de características de cada capa convolucional\n    layer_outputs = [layer.output for layer in model.layers if 'conv' in layer.name]\n    feature_map_model = tf.keras.Model(inputs=model.input, outputs=layer_outputs)\n\n    # Obtener los mapas de características al pasar la imagen a través del modelo\n    feature_maps = feature_map_model.predict(np.expand_dims(image, axis=0))  # Añadir batch dimension\n\n    # Recorrer cada capa convolucional y sus feature maps correspondientes\n    for layer_index, feature_map in enumerate(feature_maps):\n        # Número de filtros en la capa actual\n        num_filters = feature_map.shape[-1]\n\n        # Definir la figura con una fila por cada filtro (limitado a 6 para evitar gráficos muy grandes)\n        fig, axes = plt.subplots(1, min(6, num_filters), figsize=(20, 5))\n\n        # Mostrar cada filtro como imagen en escala de grises\n        for i in range(min(6, num_filters)):  # Mostrar un máximo de 6 filtros\n            ax = axes[i]\n            # Extraer el feature map del filtro `i` y mostrarlo\n            ax.matshow(feature_map[0, :, :, i], cmap='viridis')\n            ax.set_xticks([])\n            ax.set_yticks([])\n            ax.set_title(f'Filtro {i+1}')\n\n        # Título de la capa y ajuste de la visualización\n        plt.suptitle(f'Visualización de Feature Maps - Capa {layer_index+1}')\n        plt.tight_layout()\n        plt.show()"
  },
  {
    "objectID": "semana_2/notebooks/Nb_2a_Implementando_una_CNN_usando_Keras.html#componentes-base-complementarios",
    "href": "semana_2/notebooks/Nb_2a_Implementando_una_CNN_usando_Keras.html#componentes-base-complementarios",
    "title": "Implementado una Red Neuronal Convolucional",
    "section": "Componentes base complementarios",
    "text": "Componentes base complementarios\n\nCapas de Pooling\nCapas de normalización\n\n\n1. Capas de Pooling\n\n\n\n1_vKYHxr5oI9cBw_hGhjQCrA.webp\n\n\n\n\n2. Capas de normalización\nEn nuestro ejemplo, no es necesario normalizar ya que nuestras entradas estan entre 0 y 1 y no tienen un alta complejidad. Pero en otros escenarios, con imágenes más complejas y en formato RGB la normalización se hace más común.\n\n\n\n1_dsl93qeGPteT3Zt7mBy1dQ-1.webp\n\n\n\n# Asumiendo que X_train y y_train ya están definidos como en el ejemplo anterior\n# Preprocesar las etiquetas para que sean categóricas (one-hot encoding)\ny_train_categorical = to_categorical(y_train)\ny_train_categorical\n\narray([[1., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 1., 0., ..., 0., 0., 0.],\n       [1., 0., 0., ..., 0., 0., 0.],\n       [1., 0., 0., ..., 0., 0., 0.]])\n\n\n\n# crear modelo usando el API funcional\ndef cnn_model(input_shape, num_classes):\n    # Definir la entrada\n    inputs = tf.keras.Input(shape=input_shape)\n\n    # Primera capa convolucional y de pooling\n    x = tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\",\n                               strides=(1, 1),\n                               padding=\"valid\")(inputs)\n    x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n\n    # Segunda capa convolucional y de pooling\n    x = tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\",\n                               strides=(1, 1),\n                               padding=\"valid\")(x)\n    x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n\n    # Aplanar y añadir Dropout\n    x = tf.keras.layers.Flatten()(x)\n    x = tf.keras.layers.Dropout(0.5)(x)\n\n    # Capa de salida\n    outputs = tf.keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n\n    # Crear el modelo usando la API funcional\n    model = tf.keras.Model(inputs=inputs, outputs=outputs, name='cnn_keras')\n\n    return model\n\n\n# Ahora se definen los input shape y el numero de clases\ninput_shape = (dim_imagen[0], dim_imagen[1], n_canales)\nnum_classes = 10\n\n# Crear el modelo cnn\ncnn_keras = cnn_model(input_shape, num_classes)\n\n# Visualizar el resumen del modelo\ncnn_keras.summary()\n\nModel: \"cnn_keras\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_4 (InputLayer)           │ (None, 28, 28, 1)           │               0 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_8 (Conv2D)                    │ (None, 26, 26, 32)          │             320 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d_8 (MaxPooling2D)       │ (None, 13, 13, 32)          │               0 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_9 (Conv2D)                    │ (None, 11, 11, 64)          │          18,496 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d_9 (MaxPooling2D)       │ (None, 5, 5, 64)            │               0 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten_4 (Flatten)                  │ (None, 1600)                │               0 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_4 (Dropout)                  │ (None, 1600)                │               0 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_4 (Dense)                      │ (None, 10)                  │          16,010 │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n\n\n\n Total params: 34,826 (136.04 KB)\n\n\n\n Trainable params: 34,826 (136.04 KB)\n\n\n\n Non-trainable params: 0 (0.00 B)\n\n\n\n\n# tambien es posible visualizar nuestra red en formato de grafo\ntf.keras.utils.plot_model(cnn_keras, rankdir='LR',show_dtype=True)\n\n\n\n\n\n\n\n\n\n# Compilar el modelo\ncnn_keras.compile(loss='categorical_crossentropy',\n            optimizer=SGD(),\n            metrics=['accuracy'])\n\n# Entrenar el modelo\nhistory = cnn_keras.fit(X_train, y_train_categorical,\n                    epochs=30,\n                    batch_size=128,\n                    validation_split=0.2,\n                    verbose=1)\n\n\nEpoch 1/30\n\n307/307 ━━━━━━━━━━━━━━━━━━━━ 37s 114ms/step - accuracy: 0.2201 - loss: 2.2057 - val_accuracy: 0.7818 - val_loss: 1.0697\n\nEpoch 2/30\n\n307/307 ━━━━━━━━━━━━━━━━━━━━ 41s 114ms/step - accuracy: 0.6966 - loss: 0.9674 - val_accuracy: 0.8851 - val_loss: 0.4270\n\nEpoch 3/30\n\n307/307 ━━━━━━━━━━━━━━━━━━━━ 42s 117ms/step - accuracy: 0.8352 - loss: 0.5283 - val_accuracy: 0.9119 - val_loss: 0.3104\n\nEpoch 4/30\n\n307/307 ━━━━━━━━━━━━━━━━━━━━ 38s 107ms/step - accuracy: 0.8783 - loss: 0.3987 - val_accuracy: 0.9287 - val_loss: 0.2499\n\nEpoch 5/30\n\n307/307 ━━━━━━━━━━━━━━━━━━━━ 35s 113ms/step - accuracy: 0.8973 - loss: 0.3304 - val_accuracy: 0.9379 - val_loss: 0.2164\n\nEpoch 6/30\n\n307/307 ━━━━━━━━━━━━━━━━━━━━ 40s 110ms/step - accuracy: 0.9098 - loss: 0.2894 - val_accuracy: 0.9452 - val_loss: 0.1902\n\nEpoch 7/30\n\n307/307 ━━━━━━━━━━━━━━━━━━━━ 33s 108ms/step - accuracy: 0.9211 - loss: 0.2539 - val_accuracy: 0.9516 - val_loss: 0.1763\n\nEpoch 8/30\n\n307/307 ━━━━━━━━━━━━━━━━━━━━ 33s 107ms/step - accuracy: 0.9284 - loss: 0.2354 - val_accuracy: 0.9534 - val_loss: 0.1646\n\nEpoch 9/30\n\n307/307 ━━━━━━━━━━━━━━━━━━━━ 41s 106ms/step - accuracy: 0.9343 - loss: 0.2212 - val_accuracy: 0.9570 - val_loss: 0.1519\n\nEpoch 10/30\n\n307/307 ━━━━━━━━━━━━━━━━━━━━ 41s 105ms/step - accuracy: 0.9395 - loss: 0.2012 - val_accuracy: 0.9598 - val_loss: 0.1423\n\nEpoch 11/30\n\n307/307 ━━━━━━━━━━━━━━━━━━━━ 36s 117ms/step - accuracy: 0.9442 - loss: 0.1924 - val_accuracy: 0.9606 - val_loss: 0.1350\n\nEpoch 12/30\n\n307/307 ━━━━━━━━━━━━━━━━━━━━ 33s 107ms/step - accuracy: 0.9440 - loss: 0.1829 - val_accuracy: 0.9617 - val_loss: 0.1289\n\nEpoch 13/30\n\n307/307 ━━━━━━━━━━━━━━━━━━━━ 41s 107ms/step - accuracy: 0.9456 - loss: 0.1772 - val_accuracy: 0.9637 - val_loss: 0.1241\n\nEpoch 14/30\n\n307/307 ━━━━━━━━━━━━━━━━━━━━ 41s 106ms/step - accuracy: 0.9478 - loss: 0.1702 - val_accuracy: 0.9646 - val_loss: 0.1184\n\nEpoch 15/30\n\n307/307 ━━━━━━━━━━━━━━━━━━━━ 33s 108ms/step - accuracy: 0.9521 - loss: 0.1600 - val_accuracy: 0.9662 - val_loss: 0.1143\n\nEpoch 16/30\n\n307/307 ━━━━━━━━━━━━━━━━━━━━ 33s 109ms/step - accuracy: 0.9530 - loss: 0.1579 - val_accuracy: 0.9678 - val_loss: 0.1113\n\nEpoch 17/30\n\n307/307 ━━━━━━━━━━━━━━━━━━━━ 42s 113ms/step - accuracy: 0.9535 - loss: 0.1531 - val_accuracy: 0.9677 - val_loss: 0.1076\n\nEpoch 18/30\n\n307/307 ━━━━━━━━━━━━━━━━━━━━ 40s 112ms/step - accuracy: 0.9540 - loss: 0.1493 - val_accuracy: 0.9691 - val_loss: 0.1052\n\nEpoch 19/30\n\n307/307 ━━━━━━━━━━━━━━━━━━━━ 40s 108ms/step - accuracy: 0.9572 - loss: 0.1434 - val_accuracy: 0.9689 - val_loss: 0.1014\n\nEpoch 20/30\n\n307/307 ━━━━━━━━━━━━━━━━━━━━ 39s 128ms/step - accuracy: 0.9575 - loss: 0.1400 - val_accuracy: 0.9708 - val_loss: 0.0986\n\nEpoch 21/30\n\n307/307 ━━━━━━━━━━━━━━━━━━━━ 37s 116ms/step - accuracy: 0.9596 - loss: 0.1369 - val_accuracy: 0.9717 - val_loss: 0.0965\n\nEpoch 22/30\n\n307/307 ━━━━━━━━━━━━━━━━━━━━ 32s 105ms/step - accuracy: 0.9596 - loss: 0.1311 - val_accuracy: 0.9715 - val_loss: 0.0939\n\nEpoch 23/30\n\n307/307 ━━━━━━━━━━━━━━━━━━━━ 41s 106ms/step - accuracy: 0.9606 - loss: 0.1319 - val_accuracy: 0.9721 - val_loss: 0.0920\n\nEpoch 24/30\n\n307/307 ━━━━━━━━━━━━━━━━━━━━ 41s 105ms/step - accuracy: 0.9616 - loss: 0.1259 - val_accuracy: 0.9730 - val_loss: 0.0897\n\nEpoch 25/30\n\n307/307 ━━━━━━━━━━━━━━━━━━━━ 41s 106ms/step - accuracy: 0.9622 - loss: 0.1273 - val_accuracy: 0.9731 - val_loss: 0.0885\n\nEpoch 26/30\n\n307/307 ━━━━━━━━━━━━━━━━━━━━ 42s 109ms/step - accuracy: 0.9611 - loss: 0.1232 - val_accuracy: 0.9732 - val_loss: 0.0875\n\nEpoch 27/30\n\n307/307 ━━━━━━━━━━━━━━━━━━━━ 35s 113ms/step - accuracy: 0.9635 - loss: 0.1189 - val_accuracy: 0.9745 - val_loss: 0.0853\n\nEpoch 28/30\n\n307/307 ━━━━━━━━━━━━━━━━━━━━ 40s 109ms/step - accuracy: 0.9661 - loss: 0.1172 - val_accuracy: 0.9750 - val_loss: 0.0833\n\nEpoch 29/30\n\n307/307 ━━━━━━━━━━━━━━━━━━━━ 41s 108ms/step - accuracy: 0.9644 - loss: 0.1202 - val_accuracy: 0.9752 - val_loss: 0.0817\n\nEpoch 30/30\n\n307/307 ━━━━━━━━━━━━━━━━━━━━ 34s 110ms/step - accuracy: 0.9656 - loss: 0.1126 - val_accuracy: 0.9753 - val_loss: 0.0807\n\n\n\n\n\nplot_loss_historia_keras(history)\n\n\n\n\n\n\n\n\n\nplot_acc_historia_keras(history)"
  },
  {
    "objectID": "semana_2/notebooks/Nb_2a_Implementando_una_CNN_usando_Keras.html#evaluación-completa",
    "href": "semana_2/notebooks/Nb_2a_Implementando_una_CNN_usando_Keras.html#evaluación-completa",
    "title": "Implementado una Red Neuronal Convolucional",
    "section": "Evaluación completa",
    "text": "Evaluación completa\n\ny_test_categorical = to_categorical(y_test)\n\nscore = cnn_keras.evaluate(X_test, y_test_categorical, batch_size=128)\n\nscore\n\n\n165/165 ━━━━━━━━━━━━━━━━━━━━ 4s 27ms/step - accuracy: 0.9733 - loss: 0.0893\n\n\n\n\n[0.08807186037302017, 0.9740952253341675]\n\n\n\n# Realizar predicciones en el conjunto de prueba\ny_pred = cnn_keras.predict(X_test)\n\n# Convertir las predicciones en etiquetas (la clase con mayor probabilidad)\ny_pred_classes = np.argmax(y_pred, axis=1)\ny_true = y_test.values.astype(int)  # Las etiquetas reales del conjunto de prueba\n\n\n657/657 ━━━━━━━━━━━━━━━━━━━━ 6s 9ms/step\n\n\n\n\n\n# Generar el reporte de clasificación\nprint(\"Reporte de Clasificación para la red CNN en MNIST:\\n\")\nprint(classification_report(y_true, y_pred_classes))\n\n# Crear la matriz de confusión\ncm = confusion_matrix(y_true, y_pred_classes)\n\n# Visualizar la matriz de confusión usando Seaborn\nplot_matriz_confusion(cm)\n\nReporte de Clasificación para la red CNN en MNIST:\n\n              precision    recall  f1-score   support\n\n           0       0.98      0.99      0.98      2058\n           1       0.97      0.99      0.98      2364\n           2       0.96      0.97      0.97      2133\n           3       0.97      0.97      0.97      2176\n           4       0.97      0.98      0.98      1936\n           5       0.99      0.97      0.98      1915\n           6       0.99      0.98      0.99      2088\n           7       0.97      0.97      0.97      2248\n           8       0.97      0.95      0.96      1992\n           9       0.96      0.96      0.96      2090\n\n    accuracy                           0.97     21000\n   macro avg       0.97      0.97      0.97     21000\nweighted avg       0.97      0.97      0.97     21000"
  },
  {
    "objectID": "semana_2/notebooks/Nb_2a_Implementando_una_CNN_usando_Keras.html#visualización-de-filtros-convolucionales",
    "href": "semana_2/notebooks/Nb_2a_Implementando_una_CNN_usando_Keras.html#visualización-de-filtros-convolucionales",
    "title": "Implementado una Red Neuronal Convolucional",
    "section": "Visualización de filtros convolucionales",
    "text": "Visualización de filtros convolucionales\n\nvisualizacion_filtros_cnn_keras(cnn_keras)"
  },
  {
    "objectID": "semana_2/notebooks/Nb_2a_Implementando_una_CNN_usando_Keras.html#visualización-de-los-features-maps",
    "href": "semana_2/notebooks/Nb_2a_Implementando_una_CNN_usando_Keras.html#visualización-de-los-features-maps",
    "title": "Implementado una Red Neuronal Convolucional",
    "section": "Visualización de los features maps",
    "text": "Visualización de los features maps\n\nvisualizacion_feature_maps(cnn_keras, image=X_test[randint(0, 100),:,:,:])\n\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step"
  },
  {
    "objectID": "semana_1/slides/slides_semana_1.html#perceptrón-como-clasificador-básico",
    "href": "semana_1/slides/slides_semana_1.html#perceptrón-como-clasificador-básico",
    "title": "Semana 1: Fundamentos de Redes Neuronales",
    "section": "Perceptrón como Clasificador básico",
    "text": "Perceptrón como Clasificador básico"
  },
  {
    "objectID": "semana_1/notebooks/Nb_1b_Implementando_un_Percentron_Multiplicapa_MLP_usando_frameworks.html",
    "href": "semana_1/notebooks/Nb_1b_Implementando_un_Percentron_Multiplicapa_MLP_usando_frameworks.html",
    "title": "Implementado un Perceptrón multi-capa usando frameworks",
    "section": "",
    "text": "Open In Colab\n#@title Importar librerías\n#importar librerías necesarias\nimport random\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport random\n\nimport tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Input\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.datasets import mnist\n#@title Funciones complementarias\ndef plot_samples_dataset(X, y):\n    # Convertir las etiquetas a enteros\n    y = y.astype(int)\n\n    # Crear la grilla de 4x4\n    fig, axes = plt.subplots(4, 4, figsize=(6, 6))\n    fig.suptitle('Grilla de imágenes del dataset MNIST')\n\n    # Iterar para mostrar las primeras 16 imágenes con sus etiquetas\n    for i, ax in enumerate(axes.flat):\n        img = X.iloc[i].values.reshape(28, 28)\n        label = y[i]\n        ax.imshow(img, cmap='gray')\n        ax.set_title(f'Label: {label}')\n        ax.axis('off')\n\n    plt.show()\n\ndef plot_curva_aprendizaje(mlp):\n    plt.figure(figsize=(8, 5))\n    plt.plot(mlp.loss_curve_, marker='o')\n    plt.title('Pérdida durante el entrenamiento del MLP por iteración')\n    plt.xlabel('Iteración')\n    plt.ylabel('Pérdida (Loss)')\n    plt.grid()\n    plt.show()\n\ndef plot_matriz_confusion(cm):\n    # Visualizar la matriz de confusión usando Seaborn\n    plt.figure(figsize=(10, 7))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=range(10), yticklabels=range(10))\n    plt.xlabel('Etiqueta predicha')\n    plt.ylabel('Etiqueta real')\n    plt.title('Matriz de Confusión para el MLP en el dataset MNIST')\n    plt.show()\n\ndef encontrar_dim_imagen(n_neurons):\n    \"\"\"\n    Encuentra la mejor forma cuadrada (filas, columnas) para una cantidad dada de neuronas.\n    \"\"\"\n    side_length = int(np.sqrt(n_neurons))  # Calcular la raíz cuadrada del número de neuronas\n    if side_length * side_length == n_neurons:\n        return (side_length, side_length)  # Si es un cuadrado perfecto\n    else:\n        # Si no es un cuadrado perfecto, buscamos la mejor aproximación (filas, columnas)\n        for i in range(side_length, 0, -1):\n            if n_neurons % i == 0:\n                return (i, n_neurons // i)  # Devolver filas y columnas\n    return (n_neurons, 1)  # Si no encuentra, retornar en forma de vector (n_neurons, 1)\n\ndef visualizacion_pesos_mlp(mlp):\n    # Definir la figura con 3 filas y 5 columnas\n    fig, axes = plt.subplots(3, 5, figsize=(15, 9))\n\n    # Asignar las dimensiones para visualizar cada capa\n    layer_shapes = [encontrar_dim_imagen(layer.shape[0]) for layer in mlp.coefs_]\n\n    # Recorrer cada capa de coeficientes del MLP\n    for layer_index, (layer_coefs, ax_row) in enumerate(zip(mlp.coefs_, axes)):\n        # Seleccionar aleatoriamente 5 neuronas de la capa actual\n        num_neurons = layer_coefs.shape[1]\n        random_neurons = random.sample(range(num_neurons), 5)\n\n        # Obtener la forma de visualización para esta capa\n        layer_shape = layer_shapes[layer_index]\n\n        vmin, vmax = layer_coefs.min(), layer_coefs.max()\n\n        # Visualizar las neuronas seleccionadas\n        for neuron_index, ax in zip(random_neurons, ax_row):\n            # Seleccionar los pesos de la neurona específica y reestructurarlos en una matriz 2D\n            neuron_weights = layer_coefs[:, neuron_index].reshape(layer_shape)\n            # Dibujar la imagen de los pesos de la neurona\n            ax.matshow(neuron_weights, cmap=plt.cm.gray, vmin=0.5 * vmin, vmax=0.5 * vmax)\n            ax.set_xticks([])\n            ax.set_yticks([])\n            ax.set_title(f'Capa {layer_index+1}, Neurona {neuron_index}')\n\n    plt.suptitle('Visualización de Pesos de las Neuronas en las Capas Ocultas')\n    plt.tight_layout()\n    plt.show()\n\ndef plot_loss_historia_keras(history):\n    # Graficar el histórico de pérdida durante el entrenamiento\n    plt.plot(history.history['loss'], label='Pérdida de Entrenamiento')\n    plt.plot(history.history['val_loss'], label='Pérdida de Validación')\n    plt.title('Pérdida durante el Entrenamiento')\n    plt.xlabel('Época')\n    plt.ylabel('Pérdida')\n    plt.legend()\n    plt.show()\n\ndef plot_acc_historia_keras(history):\n    # Graficar la precisión durante el entrenamiento\n    plt.plot(history.history['accuracy'], label='Precisión de Entrenamiento')\n    plt.plot(history.history['val_accuracy'], label='Precisión de Validación')\n    plt.title('Precisión durante el Entrenamiento')\n    plt.xlabel('Época')\n    plt.ylabel('Precisión')\n    plt.legend()\n    plt.show()\n\ndef visualizacion_pesos_mlp_keras(model):\n    # Obtener los pesos del modelo (par de listas [pesos, biases] para cada capa)\n    weights = model.get_weights()\n\n    # Extraer solo los pesos de cada capa oculta, ignorando los bias\n    layer_weights = [weights[i] for i in range(0, len(weights), 2)]  # Solo los pesos, no los sesgos\n\n    # Definir la figura con 3 filas (una por cada capa) y 5 columnas (5 neuronas al azar)\n    fig, axes = plt.subplots(len(layer_weights), 5, figsize=(15, 9))\n\n    # Calcular las formas de cada capa de manera dinámica\n    layer_shapes = [encontrar_dim_imagen(layer.shape[0]) for layer in layer_weights]\n\n    # Recorrer cada capa y sus pesos\n    for layer_index, (layer_coefs, ax_row) in enumerate(zip(layer_weights, axes)):\n        # Seleccionar aleatoriamente 5 neuronas de la capa actual\n        num_neurons = layer_coefs.shape[1]\n        random_neurons = random.sample(range(num_neurons), 5)\n\n        # Obtener la forma de visualización para esta capa\n        layer_shape = layer_shapes[layer_index]\n        vmin, vmax = layer_coefs.min(), layer_coefs.max()\n\n\n        # Visualizar las neuronas seleccionadas\n        for neuron_index, ax in zip(random_neurons, ax_row):\n            # Seleccionar los pesos de la neurona específica y reestructurarlos en una matriz 2D\n            neuron_weights = layer_coefs[:, neuron_index].reshape(layer_shape)\n            # Dibujar la imagen de los pesos de la neurona\n            ax.matshow(neuron_weights, cmap=plt.cm.gray, vmin=0.5 * vmin, vmax=0.5 * vmax)\n            ax.set_xticks([])\n            ax.set_yticks([])\n            ax.set_title(f'Capa {layer_index+1}, Neurona {neuron_index}')\n\n    plt.suptitle('Visualización de Pesos de las Neuronas en las Capas Ocultas de Keras')\n    plt.tight_layout()\n    plt.show()"
  },
  {
    "objectID": "semana_1/notebooks/Nb_1b_Implementando_un_Percentron_Multiplicapa_MLP_usando_frameworks.html#evaluación-completa",
    "href": "semana_1/notebooks/Nb_1b_Implementando_un_Percentron_Multiplicapa_MLP_usando_frameworks.html#evaluación-completa",
    "title": "Implementado un Perceptrón multi-capa usando frameworks",
    "section": "Evaluación completa",
    "text": "Evaluación completa\nRealizaremos una evaluación completa revisando el rendimiento en ambos conjuntos, seguidamente generaremos el reporte de clasificación y la matriz de confusión.\n\nprint(f\"Training set score: {mlp.score(X_train, y_train):.3f}\")\nprint(f\"Test set score: {mlp.score(X_test, y_test):.3f}\")\n\nTraining set score: 1.000\nTest set score: 0.982\n\n\n\n# Realizar predicciones\ny_pred = mlp.predict(X_test)\n\n# Imprimir el reporte de métricas\nprint(\"Reporte de Clasificación del MLP en MNIST:\\n\")\nprint(classification_report(y_test, y_pred))\n\n# Generar la matriz de confusión\ncm = confusion_matrix(y_test, y_pred)\n\n# visualizar la matriz de confusión\nplot_matriz_confusion(cm)\n\nReporte de Clasificación del MLP en MNIST:\n\n              precision    recall  f1-score   support\n\n           0       0.99      0.99      0.99      2058\n           1       0.99      0.99      0.99      2364\n           2       0.98      0.98      0.98      2133\n           3       0.98      0.98      0.98      2176\n           4       0.98      0.98      0.98      1936\n           5       0.98      0.98      0.98      1915\n           6       0.98      0.99      0.99      2088\n           7       0.98      0.98      0.98      2248\n           8       0.98      0.97      0.97      1992\n           9       0.98      0.97      0.98      2090\n\n    accuracy                           0.98     21000\n   macro avg       0.98      0.98      0.98     21000\nweighted avg       0.98      0.98      0.98     21000"
  },
  {
    "objectID": "semana_1/notebooks/Nb_1b_Implementando_un_Percentron_Multiplicapa_MLP_usando_frameworks.html#visualización-de-pesos",
    "href": "semana_1/notebooks/Nb_1b_Implementando_un_Percentron_Multiplicapa_MLP_usando_frameworks.html#visualización-de-pesos",
    "title": "Implementado un Perceptrón multi-capa usando frameworks",
    "section": "Visualización de pesos",
    "text": "Visualización de pesos\n\n# pesos de la primera capa oculta. Todas las neuronas conectadas con cada pixel\nprint('Dimensión de la primera capa oculta: {}'.format(mlp.coefs_[0].shape))\nprint('Dimensión de la segunda capa oculta: {}'.format(mlp.coefs_[1].shape))\nprint('Dimensión de la tercera capa oculta: {}'.format(mlp.coefs_[2].shape))\n\nDimensión de la primera capa oculta: (784, 225)\nDimensión de la segunda capa oculta: (225, 100)\nDimensión de la tercera capa oculta: (100, 10)\n\n\n\nvisualizacion_pesos_mlp(mlp)\n\n\n\n\n\n\n\n\n\nTutoriales relacionados\n\nAnálisis de la variación del parametro de regularización alpha\nComparación de las diferentes estrategias de aprendizaje"
  },
  {
    "objectID": "semana_1/notebooks/Nb_1b_Implementando_un_Percentron_Multiplicapa_MLP_usando_frameworks.html#evaluación-completa-1",
    "href": "semana_1/notebooks/Nb_1b_Implementando_un_Percentron_Multiplicapa_MLP_usando_frameworks.html#evaluación-completa-1",
    "title": "Implementado un Perceptrón multi-capa usando frameworks",
    "section": "Evaluación completa",
    "text": "Evaluación completa\n\ny_test_categorical = to_categorical(y_test)\n\nscore = mlp_keras.evaluate(X_test.values.astype(float), y_test_categorical, batch_size=128)\n\nscore\n\n\n165/165 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step - accuracy: 0.9481 - loss: 0.1761\n\n\n\n\n[0.17650671303272247, 0.9479047656059265]\n\n\n\n# Realizar predicciones en el conjunto de prueba\ny_pred = mlp_keras.predict(X_test.values.astype(float))\n\n# Convertir las predicciones en etiquetas (la clase con mayor probabilidad)\ny_pred_classes = np.argmax(y_pred, axis=1)\ny_true = y_test.values.astype(int)  # Las etiquetas reales del conjunto de prueba\n\n\n657/657 ━━━━━━━━━━━━━━━━━━━━ 4s 6ms/step\n\n\n\n\n\n# Generar el reporte de clasificación\nprint(\"Reporte de Clasificación para el MLP en MNIST:\\n\")\nprint(classification_report(y_true, y_pred_classes))\n\n# Crear la matriz de confusión\ncm = confusion_matrix(y_true, y_pred_classes)\n\n# Visualizar la matriz de confusión usando Seaborn\nplot_matriz_confusion(cm)\n\nReporte de Clasificación para el MLP en MNIST:\n\n              precision    recall  f1-score   support\n\n           0       0.96      0.97      0.97      2058\n           1       0.96      0.98      0.97      2364\n           2       0.96      0.93      0.95      2133\n           3       0.93      0.93      0.93      2176\n           4       0.94      0.96      0.95      1936\n           5       0.95      0.93      0.94      1915\n           6       0.96      0.97      0.96      2088\n           7       0.95      0.95      0.95      2248\n           8       0.95      0.92      0.93      1992\n           9       0.93      0.93      0.93      2090\n\n    accuracy                           0.95     21000\n   macro avg       0.95      0.95      0.95     21000\nweighted avg       0.95      0.95      0.95     21000"
  },
  {
    "objectID": "semana_1/notebooks/Nb_1b_Implementando_un_Percentron_Multiplicapa_MLP_usando_frameworks.html#visualización-de-pesos-1",
    "href": "semana_1/notebooks/Nb_1b_Implementando_un_Percentron_Multiplicapa_MLP_usando_frameworks.html#visualización-de-pesos-1",
    "title": "Implementado un Perceptrón multi-capa usando frameworks",
    "section": "Visualización de pesos",
    "text": "Visualización de pesos\n\nvisualizacion_pesos_mlp_keras(mlp_keras)"
  },
  {
    "objectID": "semana_1/index.html",
    "href": "semana_1/index.html",
    "title": "Semana 1: Fundamentos de Redes Neuronales",
    "section": "",
    "text": "Esta semana sentamos las bases del Deep Learning. Cubriremos los conceptos esenciales, la estructura y el entrenamiento de las redes neuronales.\nTemas Clave:\n\nEstructura y entrenamiento de modelos en Deep Learning\nEl Perceptrón\nProceso de Retropropagación\nMétodos de optimización (Gradiente Descendente)\n\nEnfoque Práctico: Comprenderás el funcionamiento interno de una red y aplicarás técnicas de entrenamiento en modelos simples. Realizarás implementaciones prácticas para observar cómo aprenden los modelos.\nMateriales de la Semana:\n\nSlides de la Semana 1 (Próximamente)\nNotebook: Implementando Perceptrón Multicapa desde CERO\nNotebook: MLP usando Frameworks"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Curso Práctico: Neural Networks y Deep Learning",
    "section": "",
    "text": "¡Bienvenido al sitio web del curso práctico intensivo de Neural Networks y Deep Learning!\nEste curso está diseñado para proporcionarte una comprensión sólida y aplicada de los conceptos fundamentales de las redes neuronales y su aplicación en el campo de la inteligencia artificial, con un enfoque marcado en la implementación práctica y la resolución de problemas reales.\nA lo largo de tres semanas intensivas, explorarás desde los principios básicos hasta arquitecturas avanzadas y técnicas de vanguardia, preparándote para enfrentar desafíos complejos en el mundo del Deep Learning."
  },
  {
    "objectID": "index.html#qué-exploraremos",
    "href": "index.html#qué-exploraremos",
    "title": "Curso Práctico: Neural Networks y Deep Learning",
    "section": "¿Qué Exploraremos?",
    "text": "¿Qué Exploraremos?\nEl curso se estructura en tres unidades clave:\n\nFundamentos de Redes Neuronales: Introduce los conceptos esenciales, la estructura y el entrenamiento de modelos, abordando el perceptrón, la retropropagación y métodos de optimización como el gradiente descendente. Sentarás las bases para entender cómo aprenden las redes mientras aplicas de manera práctica los conceptos.\nArquitecturas de Redes Neuronales: Explorarás diversas arquitecturas, incluyendo Redes Neuronales Densas (DNN), Convolucionales (CNN) y Recurrentes (RNN). Ampliarás tu visión con una introducción a arquitecturas avanzadas como transformers y desarrollarás la habilidad para seleccionar la más adecuada según el problema.\nTécnicas Avanzadas y Robustez: Te centrarás en la construcción de modelos avanzados, cubriendo la generalización, la transferencia de aprendizaje, optimización de hiperparámetros y la explicabilidad. Se introducirá el entrenamiento adversarial y técnicas para crear modelos robustos y transferibles que funcionen bien en entornos de datos diversos."
  },
  {
    "objectID": "index.html#enfoque-práctico",
    "href": "index.html#enfoque-práctico",
    "title": "Curso Práctico: Neural Networks y Deep Learning",
    "section": "Enfoque Práctico",
    "text": "Enfoque Práctico\nEste curso es eminentemente práctico. A través de Implementaciones en Python y trabajo directo con notebooks, aplicarás los conceptos teóricos de inmediato. El objetivo es que no solo comprendas cómo funcionan las redes neuronales, sino que también ganes experiencia práctica en cómo construirlas y utilizarlas para resolver problemas reales.\nCada semana incluye componentes prácticos diseñados para consolidar tu aprendizaje y permitirte experimentar con diferentes arquitecturas y técnicas."
  },
  {
    "objectID": "index.html#estructura-del-sitio",
    "href": "index.html#estructura-del-sitio",
    "title": "Curso Práctico: Neural Networks y Deep Learning",
    "section": "Estructura del Sitio",
    "text": "Estructura del Sitio\n\nSemana 1: Fundamentos y MLP\nSemana 2: Arquitecturas neuronales profundas\nSemana 3: Técnicas Avanzadas y Robustez\n\nExplora cada sección para encontrar los materiales de la semana, los notebooks (renderizados para visualización web) y las slides correspondientes."
  },
  {
    "objectID": "semana_1/notebooks/Nb_1a_Implementando_un_Perceptron_Multicapa_MLP_desde_CERO.html",
    "href": "semana_1/notebooks/Nb_1a_Implementando_un_Perceptron_Multicapa_MLP_desde_CERO.html",
    "title": "Implementando un Perceptrón Multi-capa (MLP) desde CERO usando python",
    "section": "",
    "text": "Open In Colab\n#@title Importar librerías\n#importar librerías necesarias\nimport random\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nfrom matplotlib import pyplot as plt\nfrom sklearn.datasets import make_moons\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\n#@title Funciones complementarias\ndef plot_dataset(X_train, y_train, X_test, y_test):\n    # Tamaño de paso en la grilla de valores\n    # (para la visualización del espacio de características)\n    h = 0.02\n\n    # Definir los límites del gráfico en el eje x e y basados\n    # en los datos de entrenamiento\n    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n\n    # Crear una malla de puntos para cubrir el espacio de características\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n\n    # Creación del lienzo para visualizar los datos\n    fig, ax = plt.subplots(1,1, figsize=(8, 5))\n\n    # Agregar titulo a la grafica\n    ax.set_title(\"Dataset linealmente no separable\")\n\n    # Agregar nombres a cada eje de caracteristica\n    ax.set_xlabel(\"Característica x_1\")\n    ax.set_ylabel(\"Característica x_2\")\n\n    # Puntos de entrenamiento\n    ax.scatter(X_train[y_train == 0, 0], X_train[y_train == 0, 1],\n               c=\"#FF0000\", edgecolors=\"k\", label='Clase de entrenamiento 1')\n    ax.scatter(X_train[y_train == 1, 0], X_train[y_train == 1, 1],\n               c=\"#0000FF\", edgecolors=\"k\", label='Clase de entrenamiento 2')\n\n    # Puntos de prueba\n    ax.scatter(X_test[y_test == 0, 0], X_test[y_test == 0, 1],\n               c=\"#FF0000\", edgecolors=\"k\", alpha=0.6, label='Clase de prueba 1')\n    ax.scatter(X_test[y_test == 1, 0], X_test[y_test == 1, 1],\n               c=\"#0000FF\", edgecolors=\"k\", alpha=0.6, label='Clase de prueba 2')\n\n    # Establecer los límites del gráfico para asegurar que todos los puntos sean visibles\n    ax.set_xlim(xx.min(), xx.max())\n    ax.set_ylim(yy.min(), yy.max())\n\n    # Eliminar las marcas en los ejes x e y para un gráfico más limpio\n    ax.set_xticks(())\n    ax.set_yticks(())\n\n    # Añadir una leyenda para identificar las clases de los\n    # puntos de entrenamiento y prueba\n    ax.legend()\n\n    # mostrar el grafico\n    plt.show()\n\ndef plot_decision_boundary(mlp, X, y, h=0.02):\n    # Crear una malla de puntos para el espacio de características\n    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                         np.arange(y_min, y_max, h))\n\n    # por cada punto de la grilla, hacer una predicción del MLP\n    Z = np.array([mlp.prediccion([np.array([xx.ravel()[i], yy.ravel()[i]])])\n                  for i in range(len(xx.ravel()))])\n\n    # redimensionar para que tenga el mismo shape de la grilla\n    Z = Z.reshape(xx.shape)\n\n    # crear una figura de dos subplots\n    fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n\n    # Graficar los puntos originales\n    ax[0].set_title('Puntos originales')\n    ax[0].scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.RdBu,\n                  edgecolors='k', alpha=0.6)\n\n    # Graficar los puntos de entrenamiento\n    ax[1].set_title('Frontera de decisión generada por el MLP')\n    ax[1].scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', cmap=plt.cm.RdBu)\n    # Graficar la frontera de decisión con un contorno\n    ax[1].contourf(xx, yy, Z, alpha=0.6, cmap=plt.cm.RdBu)\n\n    # mejorar la visualización\n    for i in range(2):\n        ax[i].set_xlim(xx.min(), xx.max())\n        ax[i].set_ylim(yy.min(), yy.max())\n        ax[i].set_xticks(())\n        ax[i].set_yticks(())\n        ax[i].set_xlabel(\"Característica x_1\")\n        ax[i].set_ylabel(\"Característica x_2\")\n\n    plt.show()\n\ndef plot_cost_history(costo_historia):\n    # Grafica el cambio del costo en el entrenamiento\n    plt.figure(figsize=(8, 4))\n    plt.plot(costo_historia, label='Costo')\n    plt.title('Historia del Costo')\n    plt.xlabel('Épocas')\n    plt.ylabel('Costo')\n    plt.legend()\n    plt.grid(True)\n    plt.show()"
  },
  {
    "objectID": "semana_1/notebooks/Nb_1a_Implementando_un_Perceptron_Multicapa_MLP_desde_CERO.html#inicialización",
    "href": "semana_1/notebooks/Nb_1a_Implementando_un_Perceptron_Multicapa_MLP_desde_CERO.html#inicialización",
    "title": "Implementando un Perceptrón Multi-capa (MLP) desde CERO usando python",
    "section": "1. Inicialización",
    "text": "1. Inicialización\nAsignación de atributos e inicialización de pesos y biases\n\nclass PerceptronMulticapa():\n    def __init__(self, params=None):\n        # Asignación de hiperparámetros\n        self.capa_entrada = params['capa_entrada']\n        self.capa_oculta = params['capa_oculta']\n        self.capa_salida = params['capa_salida']\n        self.epochs = params['epochs']\n        self.lr = params['lr']\n        self.relu = (lambda x: x*(x &gt; 0))\n        self.derivada_relu = (lambda x: 1 * (x&gt;0))\n        self.sigmoide = (lambda x: 1/(1 + np.exp(-x)))\n        self.derivada_sigmoide = (lambda x: x*(1-x))\n\n        # inicialización de pesos y bias\n        self.inicializacion()\n\n    def inicializacion(self):\n        # inicialización de pesos y bias aleatoria\n        np.random.seed(42) # fijar una semilla para reproducir resultados\n\n        # Capa Oculta\n        self.pesos_capa_oculta = np.random.rand(self.capa_oculta, self.capa_entrada)\n        self.bias_capa_oculta = np.ones((self.capa_oculta, 1))\n\n        # Capa de salida\n        self.pesos_capa_salida = np.random.rand(self.capa_salida, self.capa_oculta)\n        self.bias_capa_salida = np.ones((self.capa_salida, 1))\n\n\n# Instanciamos nuestro perceptrón multicapa\nmlp =  PerceptronMulticapa(params)\n\n\nprint('Dimensión pesos capa oculta: {}'.format(mlp.pesos_capa_oculta.shape))\nprint('Dimensión biases capa oculta: {}'.format(mlp.bias_capa_oculta.shape))\nprint('Dimensión pesos capa salida: {}'.format(mlp.pesos_capa_salida.shape))\nprint('Dimensión bias capa salida: {}'.format(mlp.bias_capa_salida.shape))\n\nDimensión pesos capa oculta: (50, 2)\nDimensión biases capa oculta: (50, 1)\nDimensión pesos capa salida: (1, 50)\nDimensión bias capa salida: (1, 1)\n\n\n\n# ejemplo pesos capa salida\nmlp.pesos_capa_salida\n\narray([[0.03142919, 0.63641041, 0.31435598, 0.50857069, 0.90756647,\n        0.24929223, 0.41038292, 0.75555114, 0.22879817, 0.07697991,\n        0.28975145, 0.16122129, 0.92969765, 0.80812038, 0.63340376,\n        0.87146059, 0.80367208, 0.18657006, 0.892559  , 0.53934224,\n        0.80744016, 0.8960913 , 0.31800347, 0.11005192, 0.22793516,\n        0.42710779, 0.81801477, 0.86073058, 0.00695213, 0.5107473 ,\n        0.417411  , 0.22210781, 0.11986537, 0.33761517, 0.9429097 ,\n        0.32320293, 0.51879062, 0.70301896, 0.3636296 , 0.97178208,\n        0.96244729, 0.2517823 , 0.49724851, 0.30087831, 0.28484049,\n        0.03688695, 0.60956433, 0.50267902, 0.05147875, 0.27864646]])"
  },
  {
    "objectID": "semana_1/notebooks/Nb_1a_Implementando_un_Perceptron_Multicapa_MLP_desde_CERO.html#propagación-hacia-adelante-forward",
    "href": "semana_1/notebooks/Nb_1a_Implementando_un_Perceptron_Multicapa_MLP_desde_CERO.html#propagación-hacia-adelante-forward",
    "title": "Implementando un Perceptrón Multi-capa (MLP) desde CERO usando python",
    "section": "2. Propagación hacia adelante (forward)",
    "text": "2. Propagación hacia adelante (forward)\nMétodo de propagación hacia adelante\n\ndef forward_pass(self, x):\n    # Realizar la operacion Wx + b de la capa oculta, x = x_0\n    z = np.matmul(self.pesos_capa_oculta, x) + self.bias_capa_oculta\n    # Aplicar función de activación\n    h = self.relu(z) # z = x_1, h = x_2\n\n    # Aplicar la operación Wh + b para generar la salida, y = x_3\n    y = np.matmul(self.pesos_capa_salida, h) + self.bias_capa_salida\n    # Aplicar función de activación softmax para la clasificación\n    y_pred = self.sigmoide(y) # y = x_4\n\n    return z, h, y_pred\n\n\n# Añadimos nuestro nuevo método\nsetattr(PerceptronMulticapa, 'forward_pass', forward_pass)\n\n\n# seleccionamos una muestra del dataset\n# por ser solo uno se redimensiona para que tenga la estructura de entrada propia\nx_i = X_train[0,:].reshape((-1, 1))\nz, h, y_pred = mlp.forward_pass(x_i)\n\n\nprint('Dimensión biases capa oculta: {}'.format(z.shape))\nprint('Dimensión de la capa oculta: {}'.format(h.shape))\nprint('Predicción: {}'.format(y_pred))\nprint('Capa oculta: {}'.format(h))\n\nDimensión biases capa oculta: (50, 1)\nDimensión de la capa oculta: (50, 1)\nPredicción: [[1.]]\nCapa oculta: [[0.72633077]\n [1.01761811]\n [0.99129875]\n [0.64226347]\n [0.91951467]\n [0.58240149]\n [1.22554416]\n [0.98915428]\n [0.88627666]\n [1.03760999]\n [1.17304912]\n [0.95112959]\n [0.83016191]\n [0.85085938]\n [1.20642355]\n [1.1577875 ]\n [0.60864823]\n [1.01505623]\n [1.07377182]\n [1.06886654]\n [0.82949748]\n [0.61426555]\n [0.80843687]\n [0.89119274]\n [1.12821114]\n [1.03116189]\n [0.96713639]\n [0.82449353]\n [0.94790496]\n [0.87459926]\n [1.02976633]\n [1.1607742 ]\n [0.86948377]\n [0.70204454]\n [0.59561443]\n [1.20847428]\n [0.64438828]\n [0.95081357]\n [1.26279179]\n [1.08640592]\n [1.05700326]\n [1.09879949]\n [0.97640557]\n [0.99963981]\n [1.13251031]\n [0.73290002]\n [1.0450389 ]\n [1.0785398 ]\n [1.0125701 ]\n [0.96240177]]"
  },
  {
    "objectID": "semana_1/notebooks/Nb_1a_Implementando_un_Perceptron_Multicapa_MLP_desde_CERO.html#función-para-calcular-el-error",
    "href": "semana_1/notebooks/Nb_1a_Implementando_un_Perceptron_Multicapa_MLP_desde_CERO.html#función-para-calcular-el-error",
    "title": "Implementando un Perceptrón Multi-capa (MLP) desde CERO usando python",
    "section": "3. Función para calcular el error",
    "text": "3. Función para calcular el error\nMétodo que permite conocer el error de una predicción con respecto a la etiqueta real.\n\ndef calcular_perdida_entropia_cruzada(self, y_real, y_pred):\n    epsilon = 1e-12\n    # asegura que los valores de las predicciones esten en un rango\n    # seguro para evitar logaritmos de 0 y 1\n    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n    # calculo de la perdida\n    perdida = -(((1 - y_real) * np.log(1 - y_pred + epsilon)) + (y_real * np.log(y_pred + epsilon)))\n\n    return perdida\n\n\n# Añadimos nuestro nuevo método\nsetattr(PerceptronMulticapa, 'calcular_perdida_entropia_cruzada', calcular_perdida_entropia_cruzada)\n\n\n# Probamos nuestra función de error\ny_real = y_train[0]\nerror = mlp.calcular_perdida_entropia_cruzada(y_real, y_pred)\nprint(f'Error: {error}')\n\nError: [[6.67165212e-11]]"
  },
  {
    "objectID": "semana_1/notebooks/Nb_1a_Implementando_un_Perceptron_Multicapa_MLP_desde_CERO.html#propagación-hacía-atrás-backward",
    "href": "semana_1/notebooks/Nb_1a_Implementando_un_Perceptron_Multicapa_MLP_desde_CERO.html#propagación-hacía-atrás-backward",
    "title": "Implementando un Perceptrón Multi-capa (MLP) desde CERO usando python",
    "section": "4. Propagación hacía atrás (backward)",
    "text": "4. Propagación hacía atrás (backward)\nMétodo para propagar los errores hacía atrás.\n\ndef backward_pass(self, x, z, y_real, h, y_pred):\n    # Propagación de error en la capa de salida\n    # Calculo de error en la capa de salida g_out\n    #error_salida =  (y_pred - y_real) * self.derivada_sigmoide(y_pred)\n    error_salida =  y_pred - y_real\n\n    # gradiente de los pesos respecto a la capa de salida\n    # X_in * g_out = error_salida * h.T\n    # X_in = h es la entrada a la capa de salida\n    self.gradiente_pesos_capa_salida = np.matmul(error_salida, h.T)\n    # gradiente de los bias respecto a la capa de salida\n    self.gradiente_bias_capa_salida = error_salida\n\n    # Propagación de error en la capa oculta\n    # gradiente respecto a la capa oculta\n    # (g_out * W) * relu'(X_in)\n    # X_in en esta capa es la salida de aplicar la primera transformación\n    error_oculta = np.matmul(self.pesos_capa_salida.T, error_salida) * self.derivada_relu(z)\n    # gradientes con respecto a la capa oculta, de nuevo g_out * X_in\n    self.gradiente_pesos_capa_oculta = np.matmul(error_oculta, x.T)\n    self.gradiente_bias_capa_oculta = error_oculta\n\n\n# Añadimos nuestro nuevo método\nsetattr(PerceptronMulticapa, 'backward_pass', backward_pass)\n\n\n# calcular propagación de errores\nmlp.backward_pass(x_i, z, y_real, h, y_pred)\n\n\nprint('Dimensión gradientes capa oculta: {}'.format(mlp.gradiente_pesos_capa_oculta.shape))\nprint('Gradientes capa oculta: {}'.format(mlp.gradiente_pesos_capa_oculta))\n\nDimensión gradientes capa oculta: (50, 2)\nGradientes capa oculta: [[-8.14789923e-13  9.33629314e-13]\n [-1.64987027e-11  1.89050846e-11]\n [-8.14956162e-12  9.33819800e-12]\n [-1.31845056e-11  1.51075026e-11]\n [-2.35283225e-11  2.69599942e-11]\n [-6.46280811e-12  7.40542677e-12]\n [-1.06390243e-11  1.21907558e-11]\n [-1.95873816e-11  2.24442561e-11]\n [-5.93150715e-12  6.79663407e-12]\n [-1.99567547e-12  2.28675032e-12]\n [-7.51169840e-12  8.60730064e-12]\n [-4.17960177e-12  4.78920839e-12]\n [-2.41020651e-11  2.76174187e-11]\n [-2.09502196e-11  2.40058678e-11]\n [-1.64207563e-11  1.88157695e-11]\n [-2.25922909e-11  2.58874398e-11]\n [-2.08348990e-11  2.38737273e-11]\n [-4.83675923e-12  5.54221410e-12]\n [-2.31392593e-11  2.65141851e-11]\n [-1.39822466e-11  1.60215964e-11]\n [-2.09325850e-11  2.39856612e-11]\n [-2.32308329e-11  2.66191149e-11]\n [-8.24412154e-12  9.44654975e-12]\n [-2.85305512e-12  3.26918119e-12]\n [-5.90913412e-12  6.77099787e-12]\n [-1.10726102e-11  1.26875814e-11]\n [-2.12067279e-11  2.42997885e-11]\n [-2.23141195e-11  2.55686963e-11]\n [-1.80231392e-13  2.06518646e-13]\n [-1.32409334e-11  1.51721606e-11]\n [-1.08212247e-11  1.23995306e-11]\n [-5.75806219e-12  6.59789168e-12]\n [-3.10746496e-12  3.56069743e-12]\n [-8.75254746e-12  1.00291310e-11]\n [-2.44445826e-11  2.80098934e-11]\n [-8.37891553e-12  9.60100382e-12]\n [-1.34494535e-11  1.54110939e-11]\n [-1.82255044e-11  2.08837453e-11]\n [-9.42696189e-12  1.08019107e-11]\n [-2.51930882e-11  2.88675707e-11]\n [-2.49510873e-11  2.85902733e-11]\n [-6.52736216e-12  7.47939620e-12]\n [-1.28909822e-11  1.47711680e-11]\n [-7.80015802e-12  8.93783290e-12]\n [-7.38438363e-12  8.46141666e-12]\n [-9.56280359e-13  1.09575653e-12]\n [-1.58027281e-11  1.81076003e-11]\n [-1.30317663e-11  1.49324859e-11]\n [-1.33456744e-12  1.52921783e-12]\n [-7.22380571e-12  8.27741800e-12]]"
  },
  {
    "objectID": "semana_1/notebooks/Nb_1a_Implementando_un_Perceptron_Multicapa_MLP_desde_CERO.html#entrenamiento",
    "href": "semana_1/notebooks/Nb_1a_Implementando_un_Perceptron_Multicapa_MLP_desde_CERO.html#entrenamiento",
    "title": "Implementando un Perceptrón Multi-capa (MLP) desde CERO usando python",
    "section": "5. Entrenamiento",
    "text": "5. Entrenamiento\nMétodo para iterar sobre todo el conjunto de datos y entrenar la red. Antes se deberá generar otro método que haga la respectiva actualización de pesos, una vez ya los gradientes son calculados.\n\ndef actualizar_pesos(self):\n    # actualizar pesos aplicando gradiente descendiente\n    self.pesos_capa_salida -= self.lr * self.gradiente_pesos_capa_salida\n    self.bias_capa_salida -= self.lr * self.gradiente_bias_capa_salida\n    self.pesos_capa_oculta -= self.lr * self.gradiente_pesos_capa_oculta\n    self.bias_capa_oculta -= self.lr * self.gradiente_bias_capa_oculta\n\ndef entrenar(self, X, y):\n    # almacenar el costo de cada iteración\n    self.costo_historia = []\n\n    # iterar sobre el número de épocas\n    for iteracion in tqdm(range(self.epochs), desc='Iteraciones'):\n        # iterar sobre los datos de entrenamiento\n        error_total = 0 # error para la iteración i\n        # iterar sobre todo el conjunto de datos\n        for i, (x_i, y_i) in tqdm(enumerate(zip(X,y)), desc='Datos', leave=False):\n            # asegurar de que la entrada y la salida solo tenga una columna\n            x_i = x_i.reshape(-1, 1)\n            y_i = y_i.reshape(-1, 1)\n            # aplicar propagación hacia adelante\n            z, h, y_pred = self.forward_pass(x_i)\n            # calcular la perdida de entropia cruzada\n            perdida = self.calcular_perdida_entropia_cruzada(y_i, y_pred)\n            error_total += perdida\n            # aplicar propagación hacia atras\n            self.backward_pass(x_i, z,  y_i, h, y_pred)\n            # actualizar pesos y bias usando gradiente descendiente\n            self.actualizar_pesos()\n\n        # almacenar los costos de cada iteración\n        self.costo = error_total / len(X)\n        self.costo_historia.append(self.costo)\n\n    #print(f'costo: {self.costo[0][0]} en la iteración: {iteracion}')\n\n\n# Añadimos nuestros nuevos métodos\nsetattr(PerceptronMulticapa, 'actualizar_pesos', actualizar_pesos)\nsetattr(PerceptronMulticapa, 'entrenar', entrenar)\n\n\n# realizamos el respectivo entrenamiento\nmlp.entrenar(X_train, y_train)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprint(f'Costo final: {mlp.costo}')\n\nCosto final: [[0.44965122]]\n\n\n\n# Visualizar el cambio del costo durante el entrenamiento\nplot_cost_history(np.array(mlp.costo_historia).ravel())"
  },
  {
    "objectID": "semana_1/notebooks/Nb_1a_Implementando_un_Perceptron_Multicapa_MLP_desde_CERO.html#evaluación",
    "href": "semana_1/notebooks/Nb_1a_Implementando_un_Perceptron_Multicapa_MLP_desde_CERO.html#evaluación",
    "title": "Implementando un Perceptrón Multi-capa (MLP) desde CERO usando python",
    "section": "Evaluación",
    "text": "Evaluación\nPara evaluar nuestro modelo con la información de test, creamos primero la función de predicción y seguidamente evaluamos el rendimiento en test.\n\ndef prediccion(self, X):\n    predicciones = []\n    for x_i in X:\n        x_i = x_i.reshape(-1, 1)  # Asegurar que x_i sea una columna\n        z, _, y_pred = self.forward_pass(x_i)\n        predicciones.append(y_pred)\n    return np.array(predicciones).flatten()\n\ndef evaluar(self, X, y, umbral):\n    # generar predicciones\n    y_pred = self.prediccion(X)\n    # convertir a 0 y 1 bajo un umbral\n    y_pred = np.where(y_pred &gt;= umbral, 1, 0)\n    # generar reporte de clasificación y matriz de confusión\n    print(classification_report(y, y_pred))\n    cm = confusion_matrix(y, y_pred)\n\n    # visualizacion de la matriz de confusion\n    ConfusionMatrixDisplay(cm).plot()\n    plt.show()\n\n    return y_pred, cm\n\n\n# Añadimos nuestros nuevos métodos\nsetattr(PerceptronMulticapa, 'prediccion', prediccion)\nsetattr(PerceptronMulticapa, 'evaluar', evaluar)\n\n\n# evaluar y visualizar la matriz de confusion usando sklearn\ny_pred, cm = mlp.evaluar(X_test, y_test, umbral=0.5)\n\n              precision    recall  f1-score   support\n\n           0       0.81      0.81      0.81        26\n           1       0.74      0.74      0.74        19\n\n    accuracy                           0.78        45\n   macro avg       0.77      0.77      0.77        45\nweighted avg       0.78      0.78      0.78        45"
  },
  {
    "objectID": "semana_1/notebooks/Nb_1a_Implementando_un_Perceptron_Multicapa_MLP_desde_CERO.html#interpretabilidad",
    "href": "semana_1/notebooks/Nb_1a_Implementando_un_Perceptron_Multicapa_MLP_desde_CERO.html#interpretabilidad",
    "title": "Implementando un Perceptrón Multi-capa (MLP) desde CERO usando python",
    "section": "7. Interpretabilidad",
    "text": "7. Interpretabilidad\nGráficamos algunos aspectos de interpretabilidad como la frontera de decisión generada.\n\nplot_decision_boundary(mlp, X, y, h=0.02)"
  },
  {
    "objectID": "semana_1/notebooks/Nb_1a_Implementando_un_Perceptron_Multicapa_MLP_desde_CERO.html#clase-python-perceptronmulticapa-completo",
    "href": "semana_1/notebooks/Nb_1a_Implementando_un_Perceptron_Multicapa_MLP_desde_CERO.html#clase-python-perceptronmulticapa-completo",
    "title": "Implementando un Perceptrón Multi-capa (MLP) desde CERO usando python",
    "section": "Clase python PerceptronMulticapa Completo",
    "text": "Clase python PerceptronMulticapa Completo\n\nclass PerceptronMulticapa():\n    def __init__(self, params=None):\n        # Asignación de hiperparámetros\n        self.capa_entrada = params['capa_entrada']\n        self.capa_oculta = params['capa_oculta']\n        self.capa_salida = params['capa_salida']\n        self.epochs = params['epochs']\n        self.lr = params['lr']\n        self.relu = (lambda x: x*(x &gt; 0))\n        self.derivada_relu = (lambda x: 1 * (x&gt;0))\n        self.sigmoide = (lambda x: 1/(1 + np.exp(-x)))\n        self.derivada_sigmoide = (lambda x: x*(1-x))\n\n        # inicialización de pesos y bias\n        self.inicializacion()\n\n    def inicializacion(self):\n        # inicialización de pesos y bias aleatoria\n        np.random.seed(42) # fijar una semilla para reproducir resultados\n\n        # Capa Oculta\n        self.pesos_capa_oculta = np.random.rand(self.capa_oculta, self.capa_entrada)\n        self.bias_capa_oculta = np.ones((self.capa_oculta, 1))\n\n        # Capa de salida\n        self.pesos_capa_salida = np.random.rand(self.capa_salida, self.capa_oculta)\n        self.bias_capa_salida = np.ones((self.capa_salida, 1))\n\n    def forward_pass(self, x):\n        # Realizar la operacion Wx + b de la capa oculta, x = x_0\n        z = np.matmul(self.pesos_capa_oculta, x) + self.bias_capa_oculta\n        # Aplicar función de activación\n        h = self.relu(z) # z = x_1, h = x_2\n\n        # Aplicar la operación Wh + b para generar la salida, y = x_3\n        y = np.matmul(self.pesos_capa_salida, h) + self.bias_capa_salida\n        # Aplicar función de activación softmax para la clasificación\n        y_pred = self.sigmoide(y) # y = x_4\n\n        return z, h, y_pred\n\n    def actualizar_pesos(self):\n        # actualizar pesos aplicando gradiente descendiente\n        self.pesos_capa_salida -= self.lr * self.gradiente_pesos_capa_salida\n        self.bias_capa_salida -= self.lr * self.gradiente_bias_capa_salida\n        self.pesos_capa_oculta -= self.lr * self.gradiente_pesos_capa_oculta\n        self.bias_capa_oculta -= self.lr * self.gradiente_bias_capa_oculta\n\n    def backward_pass(self, x, z, y_real, h, y_pred):\n        # Propagación de error en la capa de salida\n        # Calculo de error en la capa de salida g_out\n        #error_salida =  (y_pred - y_real) * self.derivada_sigmoide(y_pred)\n        error_salida =  y_pred - y_real\n\n        # gradiente de los pesos respecto a la capa de salida\n        # X_in * g_out = error_salida * h.T\n        # X_in = h es la entrada a la capa de salida\n        self.gradiente_pesos_capa_salida = np.matmul(error_salida, h.T)\n        # gradiente de los bias respecto a la capa de salida\n        self.gradiente_bias_capa_salida = error_salida\n\n        # Propagación de error en la capa oculta\n        # gradiente respecto a la capa oculta\n        # (g_out * W) * relu'(X_in)\n        # X_in en esta capa es la salida de aplicar la primera transformación\n        error_oculta = np.matmul(self.pesos_capa_salida.T, error_salida) * self.derivada_relu(z)\n        # gradientes con respecto a la capa oculta, de nuevo g_out * X_in\n        self.gradiente_pesos_capa_oculta = np.matmul(error_oculta, x.T)\n        self.gradiente_bias_capa_oculta = error_oculta\n\n    def entrenar(self, X, y):\n        # almacenar el costo de cada iteración\n        self.costo_historia = []\n\n        # iterar sobre el número de épocas\n        for iteracion in tqdm(range(self.epochs), desc='Iteraciones'):\n            # iterar sobre los datos de entrenamiento\n            error_total = 0 # error para la iteración i\n            # iterar sobre todo el conjunto de datos\n            for i, (x_i, y_i) in tqdm(enumerate(zip(X,y)), desc='Datos', leave=False):\n                # asegurar de que la entrada y la salida solo tenga una columna\n                x_i = x_i.reshape(-1, 1)\n                y_i = y_i.reshape(-1, 1)\n                # aplicar propagación hacia adelante\n                z, h, y_pred = self.forward_pass(x_i)\n                # calcular la perdida de entropia cruzada\n                perdida = self.calcular_perdida_entropia_cruzada(y_i, y_pred)\n                error_total += perdida\n                # aplicar propagación hacia atras\n                self.backward_pass(x_i, z,  y_i, h, y_pred)\n                # actualizar pesos y bias usando gradiente descendiente\n                self.actualizar_pesos()\n\n            # almacenar los costos de cada iteración\n            self.costo = error_total / len(X)\n            self.costo_historia.append(self.costo)\n\n        #print(f'costo: {self.costo[0][0]} en la iteración: {iteracion}')\n\n    def calcular_perdida_entropia_cruzada(self, y_real, y_pred):\n        epsilon = 1e-12\n        # asegura que los valores de las predicciones esten en un rango\n        # seguro para evitar logaritmos de 0 y 1\n        y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n        # calculo de la perdida\n        perdida = -(((1 - y_real) * np.log(1 - y_pred + epsilon)) + (y_real * np.log(y_pred + epsilon)))\n\n        return perdida\n\n    def prediccion(self, X):\n        predicciones = []\n        for x_i in X:\n            x_i = x_i.reshape(-1, 1)  # Asegurar que x_i sea una columna\n            z, _, y_pred = self.forward_pass(x_i)\n            predicciones.append(y_pred)\n        return np.array(predicciones).flatten()\n\n    def evaluar(self, X, y, umbral):\n        # generar predicciones\n        y_pred = self.prediccion(X)\n        # convertir a 0 y 1 bajo un umbral\n        y_pred = np.where(y_pred &gt;= umbral, 1, 0)\n        # generar reporte de clasificación y matriz de confusión\n        print(classification_report(y, y_pred))\n        cm = confusion_matrix(y, y_pred)\n\n        # visualizacion de la matriz de confusion\n        ConfusionMatrixDisplay(cm).plot()\n        plt.show()\n\n        return y_pred, cm"
  },
  {
    "objectID": "semana_1/notebooks/Nb_1c_Implementando_un_Percentron_Multiplicapa_MLP_usando_frameworks_MLFlow.html",
    "href": "semana_1/notebooks/Nb_1c_Implementando_un_Percentron_Multiplicapa_MLP_usando_frameworks_MLFlow.html",
    "title": "Implementado un Perceptrón multi-capa usando frameworks y MLFlow",
    "section": "",
    "text": "Open In Colab\n#@title Importar librerías\n#importar librerías necesarias\nimport json\nimport random\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\n\nimport tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Input\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.datasets import mnist\n\n!pip install mlflow --quiet\n\nimport mlflow\nimport mlflow.sklearn\nimport mlflow.tensorflow\nfrom mlflow.tracking import MlflowClient\n\n\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 26.7/26.7 MB 19.7 MB/s eta 0:00:00\n\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 32.5 MB/s eta 0:00:00\n\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 233.5/233.5 kB 8.5 MB/s eta 0:00:00\n\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 147.8/147.8 kB 5.6 MB/s eta 0:00:00\n\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 114.7/114.7 kB 3.8 MB/s eta 0:00:00\n\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 85.0/85.0 kB 2.3 MB/s eta 0:00:00\n\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 569.1/569.1 kB 10.8 MB/s eta 0:00:00\n\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 203.2/203.2 kB 3.6 MB/s eta 0:00:00\n\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.6/78.6 kB 4.4 MB/s eta 0:00:00\n#@title Configurando MLFlow\n# configurar que el servidor de trackin sea localhost con una BD sqlite como el almacenamiento para almacenar el proceso de tracking\n\nlocal_registry = \"sqlite:///mlruns.db\"\nprint(f\"Ejecutando registro en modo local={local_registry}\")\nmlflow.set_tracking_uri(local_registry)\n\nEjecutando registro en modo local=sqlite:///mlruns.db\n#@title Funciones complementarias\ndef plot_samples_dataset(X, y):\n    # Convertir las etiquetas a enteros\n    y = y.astype(int)\n\n    # Crear la grilla de 4x4\n    fig, axes = plt.subplots(4, 4, figsize=(6, 6))\n    fig.suptitle('Grilla de imágenes del dataset MNIST')\n\n    # Iterar para mostrar las primeras 16 imágenes con sus etiquetas\n    for i, ax in enumerate(axes.flat):\n        img = X.iloc[i].values.reshape(28, 28)\n        label = y[i]\n        ax.imshow(img, cmap='gray')\n        ax.set_title(f'Label: {label}')\n        ax.axis('off')\n\n    plt.show()\n\ndef plot_curva_aprendizaje(mlp):\n    plt.figure(figsize=(8, 5))\n    plt.plot(mlp.loss_curve_, marker='o')\n    plt.title('Pérdida durante el entrenamiento del MLP por iteración')\n    plt.xlabel('Iteración')\n    plt.ylabel('Pérdida (Loss)')\n    plt.grid()\n    plt.show()\n\ndef plot_matriz_confusion(cm, nombre):\n    # Visualizar la matriz de confusión usando Seaborn\n    plt.figure(figsize=(10, 7))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=range(10), yticklabels=range(10))\n    plt.xlabel('Etiqueta predicha')\n    plt.ylabel('Etiqueta real')\n    plt.title('Matriz de Confusión para el MLP en el dataset MNIST')\n    plt.show()\n    plt.savefig(f\"{nombre}.png\")\n\ndef encontrar_dim_imagen(n_neurons):\n    \"\"\"\n    Encuentra la mejor forma cuadrada (filas, columnas) para una cantidad dada de neuronas.\n    \"\"\"\n    side_length = int(np.sqrt(n_neurons))  # Calcular la raíz cuadrada del número de neuronas\n    if side_length * side_length == n_neurons:\n        return (side_length, side_length)  # Si es un cuadrado perfecto\n    else:\n        # Si no es un cuadrado perfecto, buscamos la mejor aproximación (filas, columnas)\n        for i in range(side_length, 0, -1):\n            if n_neurons % i == 0:\n                return (i, n_neurons // i)  # Devolver filas y columnas\n    return (n_neurons, 1)  # Si no encuentra, retornar en forma de vector (n_neurons, 1)\n\ndef visualizacion_pesos_mlp(mlp):\n    # Definir la figura con 3 filas y 5 columnas\n    fig, axes = plt.subplots(3, 5, figsize=(15, 9))\n\n    # Asignar las dimensiones para visualizar cada capa\n    layer_shapes = [encontrar_dim_imagen(layer.shape[0]) for layer in mlp.coefs_]\n\n    # Recorrer cada capa de coeficientes del MLP\n    for layer_index, (layer_coefs, ax_row) in enumerate(zip(mlp.coefs_, axes)):\n        # Seleccionar aleatoriamente 5 neuronas de la capa actual\n        num_neurons = layer_coefs.shape[1]\n        random_neurons = random.sample(range(num_neurons), 5)\n\n        # Obtener la forma de visualización para esta capa\n        layer_shape = layer_shapes[layer_index]\n\n        vmin, vmax = layer_coefs.min(), layer_coefs.max()\n\n        # Visualizar las neuronas seleccionadas\n        for neuron_index, ax in zip(random_neurons, ax_row):\n            # Seleccionar los pesos de la neurona específica y reestructurarlos en una matriz 2D\n            neuron_weights = layer_coefs[:, neuron_index].reshape(layer_shape)\n            # Dibujar la imagen de los pesos de la neurona\n            ax.matshow(neuron_weights, cmap=plt.cm.gray, vmin=0.5 * vmin, vmax=0.5 * vmax)\n            ax.set_xticks([])\n            ax.set_yticks([])\n            ax.set_title(f'Capa {layer_index+1}, Neurona {neuron_index}')\n\n    plt.suptitle('Visualización de Pesos de las Neuronas en las Capas Ocultas')\n    plt.tight_layout()\n    plt.show()\n\ndef plot_loss_historia_keras(history):\n    # Graficar el histórico de pérdida durante el entrenamiento\n    plt.plot(history.history['loss'], label='Pérdida de Entrenamiento')\n    plt.plot(history.history['val_loss'], label='Pérdida de Validación')\n    plt.title('Pérdida durante el Entrenamiento')\n    plt.xlabel('Época')\n    plt.ylabel('Pérdida')\n    plt.legend()\n    plt.show()\n\ndef plot_acc_historia_keras(history):\n    # Graficar la precisión durante el entrenamiento\n    plt.plot(history.history['accuracy'], label='Precisión de Entrenamiento')\n    plt.plot(history.history['val_accuracy'], label='Precisión de Validación')\n    plt.title('Precisión durante el Entrenamiento')\n    plt.xlabel('Época')\n    plt.ylabel('Precisión')\n    plt.legend()\n    plt.show()\n\ndef visualizacion_pesos_mlp_keras(model):\n    # Obtener los pesos del modelo (par de listas [pesos, biases] para cada capa)\n    weights = model.get_weights()\n\n    # Extraer solo los pesos de cada capa oculta, ignorando los bias\n    layer_weights = [weights[i] for i in range(0, len(weights), 2)]  # Solo los pesos, no los sesgos\n\n    # Definir la figura con 3 filas (una por cada capa) y 5 columnas (5 neuronas al azar)\n    fig, axes = plt.subplots(len(layer_weights), 5, figsize=(15, 9))\n\n    # Calcular las formas de cada capa de manera dinámica\n    layer_shapes = [encontrar_dim_imagen(layer.shape[0]) for layer in layer_weights]\n\n    # Recorrer cada capa y sus pesos\n    for layer_index, (layer_coefs, ax_row) in enumerate(zip(layer_weights, axes)):\n        # Seleccionar aleatoriamente 5 neuronas de la capa actual\n        num_neurons = layer_coefs.shape[1]\n        random_neurons = random.sample(range(num_neurons), 5)\n\n        # Obtener la forma de visualización para esta capa\n        layer_shape = layer_shapes[layer_index]\n        vmin, vmax = layer_coefs.min(), layer_coefs.max()\n\n\n        # Visualizar las neuronas seleccionadas\n        for neuron_index, ax in zip(random_neurons, ax_row):\n            # Seleccionar los pesos de la neurona específica y reestructurarlos en una matriz 2D\n            neuron_weights = layer_coefs[:, neuron_index].reshape(layer_shape)\n            # Dibujar la imagen de los pesos de la neurona\n            ax.matshow(neuron_weights, cmap=plt.cm.gray, vmin=0.5 * vmin, vmax=0.5 * vmax)\n            ax.set_xticks([])\n            ax.set_yticks([])\n            ax.set_title(f'Capa {layer_index+1}, Neurona {neuron_index}')\n\n    plt.suptitle('Visualización de Pesos de las Neuronas en las Capas Ocultas de Keras')\n    plt.tight_layout()\n    plt.show()"
  },
  {
    "objectID": "semana_1/notebooks/Nb_1c_Implementando_un_Percentron_Multiplicapa_MLP_usando_frameworks_MLFlow.html#evaluación-completa",
    "href": "semana_1/notebooks/Nb_1c_Implementando_un_Percentron_Multiplicapa_MLP_usando_frameworks_MLFlow.html#evaluación-completa",
    "title": "Implementado un Perceptrón multi-capa usando frameworks y MLFlow",
    "section": "Evaluación completa",
    "text": "Evaluación completa\nRealizaremos una evaluación completa revisando el rendimiento en ambos conjuntos, seguidamente generaremos el reporte de clasificación y la matriz de confusión.\n\nprint(f\"Training set score: {mlp.score(X_train, y_train):.3f}\")\nprint(f\"Test set score: {mlp.score(X_test, y_test):.3f}\")\n\nTraining set score: 1.000\nTest set score: 0.982\n\n\n\n# re abrir un run anterior para registrar más datos\nmlflow.start_run(run_id=run_id)\n\n# Realizar predicciones\ny_pred = mlp.predict(X_test)\n\n# Imprimir el reporte de métricas\nprint(\"Reporte de Clasificación del MLP en MNIST:\\n\")\nreport = classification_report(y_test, y_pred)\nprint(report)\n\n# registrar artefacto\nwith open(\"classification_report.json\", \"w\") as f:\n    json.dump(report, f)\nmlflow.log_artifact(\"classification_report.json\")\n\n# Generar la matriz de confusión\ncm = confusion_matrix(y_test, y_pred)\n\n# visualizar la matriz de confusión\nplot_matriz_confusion(cm, nombre='confusion_matrix')\n# Guardar la visualización como imagen y registrarla en MLflow\nmlflow.log_artifact(\"confusion_matrix.png\")\n\n# Finalizar el `run` si ya no se va a registrar nada más\nmlflow.end_run()\n\nReporte de Clasificación del MLP en MNIST:\n\n              precision    recall  f1-score   support\n\n           0       0.99      0.99      0.99      2058\n           1       0.99      0.99      0.99      2364\n           2       0.98      0.98      0.98      2133\n           3       0.98      0.98      0.98      2176\n           4       0.98      0.98      0.98      1936\n           5       0.98      0.98      0.98      1915\n           6       0.98      0.99      0.99      2088\n           7       0.98      0.98      0.98      2248\n           8       0.98      0.97      0.97      1992\n           9       0.98      0.97      0.98      2090\n\n    accuracy                           0.98     21000\n   macro avg       0.98      0.98      0.98     21000\nweighted avg       0.98      0.98      0.98     21000\n\n\n\n\n\n\n\n\n\n\n&lt;Figure size 640x480 with 0 Axes&gt;\n\n\n\nEjecutar MLFlow UI\n\n# Ejecutar tracking UI en background\nget_ipython().system_raw(\"mlflow ui --backend-store-uri sqlite:///mlruns.db --port 5000 &\")\n\n\n# Crear un tunel remoto usando ngrok.com\n!pip install -U pyngrok --quiet\nfrom pyngrok import ngrok\n\n# Terminate open tunnels if exist\nngrok.kill()\n\n# Colocar el token\n# Coloque su authtoken obtenido de https://dashboard.ngrok.com/auth\nNGROK_AUTH_TOKEN = \"2oR7ctXTRQ7kJl8csoQXXoxsb6V_72fsChgD1kFQN5MkVr7U3\"\nngrok.set_auth_token(NGROK_AUTH_TOKEN)\n\n# Abrir el tunel http en el puerto 5000 para http://localhost:5000\npublic_url = ngrok.connect(\"http://localhost:5000\", proto='http')\nprint(\"MLflow Tracking UI:\", public_url)\n\nMLflow Tracking UI: NgrokTunnel: \"https://3ec3-34-125-33-68.ngrok-free.app\" -&gt; \"http://localhost:5000\""
  },
  {
    "objectID": "semana_1/notebooks/Nb_1c_Implementando_un_Percentron_Multiplicapa_MLP_usando_frameworks_MLFlow.html#visualización-de-pesos",
    "href": "semana_1/notebooks/Nb_1c_Implementando_un_Percentron_Multiplicapa_MLP_usando_frameworks_MLFlow.html#visualización-de-pesos",
    "title": "Implementado un Perceptrón multi-capa usando frameworks y MLFlow",
    "section": "Visualización de pesos",
    "text": "Visualización de pesos\n\nvisualizacion_pesos_mlp(mlp)\n\n\n\n\n\n\n\n\n\nTutoriales relacionados\n\nAnálisis de la variación del parametro de regularización alpha\nComparación de las diferentes estrategias de aprendizaje"
  },
  {
    "objectID": "semana_1/notebooks/Nb_1c_Implementando_un_Percentron_Multiplicapa_MLP_usando_frameworks_MLFlow.html#evaluación-completa-1",
    "href": "semana_1/notebooks/Nb_1c_Implementando_un_Percentron_Multiplicapa_MLP_usando_frameworks_MLFlow.html#evaluación-completa-1",
    "title": "Implementado un Perceptrón multi-capa usando frameworks y MLFlow",
    "section": "Evaluación completa",
    "text": "Evaluación completa\n\ny_test_categorical = to_categorical(y_test)\n\nscore = mlp_keras.evaluate(X_test.values.astype(float), y_test_categorical, batch_size=128)\n\nscore\n\n\n165/165 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step - accuracy: 0.9481 - loss: 0.1761\n\n\n\n\n[0.17650671303272247, 0.9479047656059265]\n\n\n\n# Realizar predicciones en el conjunto de prueba\ny_pred = mlp_keras.predict(X_test.values.astype(float))\n\n# Convertir las predicciones en etiquetas (la clase con mayor probabilidad)\ny_pred_classes = np.argmax(y_pred, axis=1)\ny_true = y_test.values.astype(int)  # Las etiquetas reales del conjunto de prueba\n\n\n657/657 ━━━━━━━━━━━━━━━━━━━━ 4s 6ms/step\n\n\n\n\n\n# Generar el reporte de clasificación\nprint(\"Reporte de Clasificación para el MLP en MNIST:\\n\")\nprint(classification_report(y_true, y_pred_classes))\n\n# Crear la matriz de confusión\ncm = confusion_matrix(y_true, y_pred_classes)\n\n# Visualizar la matriz de confusión usando Seaborn\nplot_matriz_confusion(cm)\n\nReporte de Clasificación para el MLP en MNIST:\n\n              precision    recall  f1-score   support\n\n           0       0.96      0.97      0.97      2058\n           1       0.96      0.98      0.97      2364\n           2       0.96      0.93      0.95      2133\n           3       0.93      0.93      0.93      2176\n           4       0.94      0.96      0.95      1936\n           5       0.95      0.93      0.94      1915\n           6       0.96      0.97      0.96      2088\n           7       0.95      0.95      0.95      2248\n           8       0.95      0.92      0.93      1992\n           9       0.93      0.93      0.93      2090\n\n    accuracy                           0.95     21000\n   macro avg       0.95      0.95      0.95     21000\nweighted avg       0.95      0.95      0.95     21000"
  },
  {
    "objectID": "semana_1/notebooks/Nb_1c_Implementando_un_Percentron_Multiplicapa_MLP_usando_frameworks_MLFlow.html#visualización-de-pesos-1",
    "href": "semana_1/notebooks/Nb_1c_Implementando_un_Percentron_Multiplicapa_MLP_usando_frameworks_MLFlow.html#visualización-de-pesos-1",
    "title": "Implementado un Perceptrón multi-capa usando frameworks y MLFlow",
    "section": "Visualización de pesos",
    "text": "Visualización de pesos\n\nvisualizacion_pesos_mlp_keras(mlp_keras)"
  },
  {
    "objectID": "semana_1/notebooks/Nb_1c_Implementando_un_Percentron_Multiplicapa_MLP_usando_frameworks_MLFlow.html#actividad-extra-clase",
    "href": "semana_1/notebooks/Nb_1c_Implementando_un_Percentron_Multiplicapa_MLP_usando_frameworks_MLFlow.html#actividad-extra-clase",
    "title": "Implementado un Perceptrón multi-capa usando frameworks y MLFlow",
    "section": "Actividad extra clase",
    "text": "Actividad extra clase\nUsando la siguiente documentación: https://mlflow.org/docs/latest/deep-learning/tensorflow/guide/index.html realizar un seguimiento y registro del MLP construido en keras/tensorflow."
  },
  {
    "objectID": "semana_2/index.html",
    "href": "semana_2/index.html",
    "title": "Semana 2: Arquitecturas de Redes Neuronales",
    "section": "",
    "text": "Expandimos nuestro conocimiento explorando diversas arquitecturas de redes neuronales y sus aplicaciones.\nTemas Clave:\n\nDiversas arquitecturas de redes neuronales (DNN, CNN, RNN).\nAplicaciones y ventajas de cada arquitectura.\nIntroducción a arquitecturas avanzadas (Transformers, GANs, Redes de Grafos).\n\nEnfoque Práctico: Aprenderás a identificar y seleccionar la arquitectura más adecuada para diferentes tipos de problemas. Implementarás modelos DNN, CNN y RNN en proyectos prácticos para experimentar con su desempeño.\nMateriales de la Semana:\n\nSlides de la Semana 2 (Próximamente)\nNotebook: Implementando una CNN usando Keras\nNotebook: Resolviendo desafíos con RNNs usando Keras"
  },
  {
    "objectID": "semana_2/notebooks/Nb_2b_Resolviendo_desafios_con_RNNs_usando_keras.html",
    "href": "semana_2/notebooks/Nb_2b_Resolviendo_desafios_con_RNNs_usando_keras.html",
    "title": "Resolviendo diversidad de tareas con RNNs",
    "section": "",
    "text": "Open In Colab\n#@title Importar librerías\n#importar librerías necesarias\nimport os\nimport random\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nimport tensorflow_datasets as tfds\nimport tensorflow as tf\n#@title Funciones complementarias\n\ndef plot_graphs(history, metric):\n  plt.plot(history.history[metric])\n  plt.plot(history.history['val_'+metric], '')\n  plt.xlabel(\"Epochs\")\n  plt.ylabel(metric)\n  plt.legend([metric, 'val_'+metric])\n\ndef plot_variables(df, date_time):\n    plot_cols = ['T (degC)', 'p (mbar)', 'rho (g/m**3)']\n    plot_features = df[plot_cols]\n    plot_features.index = date_time\n    _ = plot_features.plot(subplots=True)\n\n    plot_features = df[plot_cols][:480]\n    plot_features.index = date_time[:480]\n    _ = plot_features.plot(subplots=True)\n\n\n\ndef read_dataset_clima():\n\n    zip_path = tf.keras.utils.get_file(\n        origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip',\n        fname='jena_climate_2009_2016.csv.zip',\n        extract=True)\n    csv_path, _ = os.path.splitext(zip_path)\n\n    df = pd.read_csv(csv_path)\n    # Slice [start:stop:step], starting from index 5 take every 6th record.\n    df = df[5::6]\n\n    date_time = pd.to_datetime(df.pop('Date Time'), format='%d.%m.%Y %H:%M:%S')\n\n    return df, date_time\n\ndef split_data(df):\n    column_indices = {name: i for i, name in enumerate(df.columns)}\n\n    n = len(df)\n    train_df = df[0:int(n*0.7)]\n    val_df = df[int(n*0.7):int(n*0.9)]\n    test_df = df[int(n*0.9):]\n\n    num_features = df.shape[1]\n\n    return train_df, val_df, test_df, num_features, column_indices\n\ndef normalizacion_datos(train_df, val_df, test_df):\n    train_mean = train_df.mean()\n    train_std = train_df.std()\n\n    train_df = (train_df - train_mean) / train_std\n    val_df = (val_df - train_mean) / train_std\n    test_df = (test_df - train_mean) / train_std\n\n    return train_df, val_df, test_df\n\n\nclass WindowGenerator():\n  def __init__(self, input_width, label_width, shift,\n               train_df, val_df, test_df,\n               label_columns=None):\n    # Store the raw data.\n    self.train_df = train_df\n    self.val_df = val_df\n    self.test_df = test_df\n\n    # Work out the label column indices.\n    self.label_columns = label_columns\n    if label_columns is not None:\n      self.label_columns_indices = {name: i for i, name in\n                                    enumerate(label_columns)}\n    self.column_indices = {name: i for i, name in\n                           enumerate(train_df.columns)}\n\n    # Work out the window parameters.\n    self.input_width = input_width\n    self.label_width = label_width\n    self.shift = shift\n\n    self.total_window_size = input_width + shift\n\n    self.input_slice = slice(0, input_width)\n    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n\n    self.label_start = self.total_window_size - self.label_width\n    self.labels_slice = slice(self.label_start, None)\n    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n\n  def __repr__(self):\n    return '\\n'.join([\n        f'Total window size: {self.total_window_size}',\n        f'Input indices: {self.input_indices}',\n        f'Label indices: {self.label_indices}',\n        f'Label column name(s): {self.label_columns}'])\n\n\ndef split_window(self, features):\n  inputs = features[:, self.input_slice, :]\n  labels = features[:, self.labels_slice, :]\n  if self.label_columns is not None:\n    labels = tf.stack(\n        [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n        axis=-1)\n\n  # Slicing doesn't preserve static shape information, so set the shapes\n  # manually. This way the `tf.data.Datasets` are easier to inspect.\n  inputs.set_shape([None, self.input_width, None])\n  labels.set_shape([None, self.label_width, None])\n\n  return inputs, labels\n\ndef plot(self, model=None, plot_col='T (degC)', max_subplots=3):\n  inputs, labels = self.example\n  plt.figure(figsize=(12, 8))\n  plot_col_index = self.column_indices[plot_col]\n  max_n = min(max_subplots, len(inputs))\n  for n in range(max_n):\n    plt.subplot(max_n, 1, n+1)\n    plt.ylabel(f'{plot_col} [normed]')\n    plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n             label='Inputs', marker='.', zorder=-10)\n\n    if self.label_columns:\n      label_col_index = self.label_columns_indices.get(plot_col, None)\n    else:\n      label_col_index = plot_col_index\n\n    if label_col_index is None:\n      continue\n\n    plt.scatter(self.label_indices, labels[n, :, label_col_index],\n                edgecolors='k', label='Labels', c='#2ca02c', s=64)\n    if model is not None:\n      predictions = model(inputs)\n      plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n                  marker='X', edgecolors='k', label='Predictions',\n                  c='#ff7f0e', s=64)\n\n    if n == 0:\n      plt.legend()\n\n  plt.xlabel('Time [h]')\n\ndef make_dataset(self, data):\n  data = np.array(data, dtype=np.float32)\n  ds = tf.keras.utils.timeseries_dataset_from_array(\n      data=data,\n      targets=None,\n      sequence_length=self.total_window_size,\n      sequence_stride=1,\n      shuffle=True,\n      batch_size=32,)\n\n  ds = ds.map(self.split_window)\n\n  return ds\n\n\n@property\ndef train(self):\n  return self.make_dataset(self.train_df)\n\n@property\ndef val(self):\n  return self.make_dataset(self.val_df)\n\n@property\ndef test(self):\n  return self.make_dataset(self.test_df)\n\n@property\ndef example(self):\n  \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n  result = getattr(self, '_example', None)\n  if result is None:\n    # No example batch was found, so get one from the `.train` dataset\n    result = next(iter(self.train))\n    # And cache it for next time\n    self._example = result\n  return result\n\n\n\nWindowGenerator.plot = plot\nWindowGenerator.split_window = split_window\nWindowGenerator.make_dataset = make_dataset\nWindowGenerator.train = train\nWindowGenerator.val = val\nWindowGenerator.test = test\nWindowGenerator.example = example"
  },
  {
    "objectID": "semana_2/notebooks/Nb_2b_Resolviendo_desafios_con_RNNs_usando_keras.html#clasificación-de-texto-usando-rnns-relación-muchas-entradas-a-una-salida",
    "href": "semana_2/notebooks/Nb_2b_Resolviendo_desafios_con_RNNs_usando_keras.html#clasificación-de-texto-usando-rnns-relación-muchas-entradas-a-una-salida",
    "title": "Resolviendo diversidad de tareas con RNNs",
    "section": "Clasificación de texto usando RNNs (Relación muchas entradas a una salida)",
    "text": "Clasificación de texto usando RNNs (Relación muchas entradas a una salida)\nEn este escenario se reciben multiples entradas pero solo se genera una salida. Aquí podemos abordar el ejemplo más común que es la clasificación de texto.\n\nDescargar el dataset de reviews de peliculas usando Tensorflow.\nEl gran conjunto de datos de críticas de películas de IMDB es un conjunto de datos de clasificación binaria: todas las críticas tienen un sentimiento positivo o negativo.\n\ndataset, info = tfds.load('imdb_reviews', with_info=True,\n                          as_supervised=True)\ntrain_dataset, test_dataset = dataset['train'], dataset['test']\n\nDownloading and preparing dataset 80.23 MiB (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0...\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDataset imdb_reviews downloaded and prepared to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.\n\n\n\n# contar cuantas muestras tiene train_dataset y test_dataset\nprint(info.splits)\n\n{Split('train'): &lt;SplitInfo num_examples=25000, num_shards=1&gt;, Split('test'): &lt;SplitInfo num_examples=25000, num_shards=1&gt;, Split('unsupervised'): &lt;SplitInfo num_examples=50000, num_shards=1&gt;}\n\n\n\n# extraer una muestra del conjunto de entrenamiento\ntrain_example, train_label = next(iter(train_dataset.batch(1)))\n\nprint('Para la etiqueta: {} se tiene el texto: {}'.format(train_label, train_example.numpy()))\n\nPara la etiqueta: [0] se tiene el texto: [b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\"]\n\n\nLas siguientes lineas son para optimizar los conjuntos y que el entrenamiento sea más acelerado.\n\nBUFFER_SIZE = 10000\nBATCH_SIZE = 32\n\n# optimización para train\ntrain_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n\n# optimización para test\ntest_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n\n\n# muestras para el conjunto de test\nfor ejemplo, label in test_dataset.take(1):\n  print('textos: ', ejemplo.numpy()[:3])\n  print()\n  print('labels: ', label.numpy()[:3])\n\ntextos:  [b\"There are films that make careers. For George Romero, it was NIGHT OF THE LIVING DEAD; for Kevin Smith, CLERKS; for Robert Rodriguez, EL MARIACHI. Add to that list Onur Tukel's absolutely amazing DING-A-LING-LESS. Flawless film-making, and as assured and as professional as any of the aforementioned movies. I haven't laughed this hard since I saw THE FULL MONTY. (And, even then, I don't think I laughed quite this hard... So to speak.) Tukel's talent is considerable: DING-A-LING-LESS is so chock full of double entendres that one would have to sit down with a copy of this script and do a line-by-line examination of it to fully appreciate the, uh, breadth and width of it. Every shot is beautifully composed (a clear sign of a sure-handed director), and the performances all around are solid (there's none of the over-the-top scenery chewing one might've expected from a film like this). DING-A-LING-LESS is a film whose time has come.\"\n b\"A blackly comic tale of a down-trodden priest, Nazarin showcases the economy that Luis Bunuel was able to achieve in being able to tell a deeply humanist fable with a minimum of fuss. As an output from his Mexican era of film making, it was an invaluable talent to possess, with little money and extremely tight schedules. Nazarin, however, surpasses many of Bunuel's previous Mexican films in terms of the acting (Francisco Rabal is excellent), narrative and theme.&lt;br /&gt;&lt;br /&gt;The theme, interestingly, is something that was explored again in Viridiana, made three years later in Spain. It concerns the individual's struggle for humanity and altruism amongst a society that rejects any notion of virtue. Father Nazarin, however, is portrayed more sympathetically than Sister Viridiana. Whereas the latter seems to choose charity because she wishes to atone for her (perceived) sins, Nazarin's whole existence and reason for being seems to be to help others, whether they (or we) like it or not. The film's last scenes, in which he casts doubt on his behaviour and, in a split second, has to choose between the life he has been leading or the conventional life that is expected of a priest, are so emotional because they concern his moral integrity and we are never quite sure whether it remains intact or not.&lt;br /&gt;&lt;br /&gt;This is a remarkable film and I would urge anyone interested in classic cinema to seek it out. It is one of Bunuel's most moving films, and encapsulates many of his obsessions: frustrated desire, mad love, religious hypocrisy etc. In my view 'Nazarin' is second only to 'The Exterminating Angel', in terms of his Mexican movies, and is certainly near the top of the list of Bunuel's total filmic output.\"\n b'Scary Movie 1-4, Epic Movie, Date Movie, Meet the Spartans, Not another Teen Movie and Another Gay Movie. Making \"Superhero Movie\" the eleventh in a series that single handily ruined the parody genre. Now I\\'ll admit it I have a soft spot for classics such as Airplane and The Naked Gun but you know you\\'ve milked a franchise so bad when you can see the gags a mile off. In fact the only thing that might really temp you into going to see this disaster is the incredibly funny but massive sell-out Leslie Neilson.&lt;br /&gt;&lt;br /&gt;You can tell he needs the money, wither that or he intends to go down with the ship like a good Capitan would. In no way is he bringing down this genre but hell he\\'s not helping it. But if I feel sorry for anybody in this film its decent actor Drake Bell who is put through an immense amount of embarrassment. The people who are put through the largest amount of torture by far however is the audience forced to sit through 90 minutes of laughless bile no funnier than herpes.&lt;br /&gt;&lt;br /&gt;After spoofing disaster films in Airplane!, police shows in The Naked Gun, and Hollywood horrors in Scary Movie 3 and 4, producer David Zucker sets his satirical sights on the superhero genre with this anarchic comedy lampooning everything from Spider-Man to X-Men and Superman Returns.&lt;br /&gt;&lt;br /&gt;Shortly after being bitten by a genetically altered dragonfly, high-school outcast Rick Riker (Drake Bell) begins to experience a startling transformation. Now Rick\\'s skin is as strong as steel, and he possesses the strength of ten men. Determined to use his newfound powers to fight crime, Rick creates a special costume and assumes the identity of The Dragonfly -- a fearless crime fighter dedicated to keeping the streets safe for law-abiding citizens.&lt;br /&gt;&lt;br /&gt;But every superhero needs a nemesis, and after Lou Landers (Christopher McDonald) is caught in the middle of an experiment gone horribly awry, he develops the power to leech the life force out of anyone he meets and becomes the villainous Hourglass. Intent on achieving immortality, the Hourglass attempts to gather as much life force as possible as the noble Dragonfly sets out to take down his archenemy and realize his destiny as a true hero. Craig Mazin writes and directs this low-flying spoof.&lt;br /&gt;&lt;br /&gt;featuring Tracy Morgan, Pamela Anderson, Leslie Nielsen, Marion Ross, Jeffrey Tambor, and Regina Hall.&lt;br /&gt;&lt;br /&gt;Hell Superhero Movie may earn some merit in the fact that it\\'s a hell of a lot better than Meet the Spartans and Epic Movie. But with great responsibility comes one of the worst outings of 2008 to date. Laughless but a little less irritating than Meet the Spartans. And in the same sense much more forgettable than meet the Spartans. But maybe that\\'s a good reason. There are still some of us trying to scrape away the stain that was Meet the Spartans from our memory.&lt;br /&gt;&lt;br /&gt;My final verdict? Avoid, unless you\\'re one of thoses people who enjoy such car crash cinema. As bad as Date Movie and Scary Movie 2 but not quite as bad as Meet the Spartans or Epic Movie. Super Villain.']\n\nlabels:  [1 1 0]\n\n\n\n\nPre-procesamiento y modelado.\n\n\n\nbidirectional.png\n\n\nExplicación del modelo:\nEste modelo se puede construir como un tf.keras.Sequential.\n\nLa primera capa (amarilla) es el codificador, que convierte el texto en una secuencia de índices de tokens.\nDespués del codificador hay una capa de embedding (verde). Una capa de embedding almacena un vector por palabra. Cuando se llama, convierte las secuencias de índices de palabras en secuencias de vectores. Estos vectores son entrenables. Después del entrenamiento (con suficientes datos), las palabras con significados similares a menudo tienen vectores similares.\nUna red neuronal recurrente (RNN) procesa la entrada secuencial iterando a través de los elementos. Las RNN pasan las salidas de un instante de tiempo a su entrada en el siguiente instante de tiempo.\nLa capa tf.keras.layers.Bidirectional también se puede usar con una capa RNN. Esto propaga la entrada hacia adelante y hacia atrás a través de la capa RNN y luego concatena la salida final.\n\nLa principal ventaja de una RNN bidireccional es que la señal desde el comienzo de la entrada no necesita ser procesada a lo largo de cada instante de tiempo para afectar la salida.\nLa principal desventaja de una RNN bidireccional es que no se pueden transmitir predicciones de manera eficiente a medida que se agregan palabras al final.\n\nDespués de que la RNN ha convertido la secuencia en un solo vector, las dos capas Dense realizan un procesamiento final y convierten esta representación vectorial en un solo valor como salida de clasificación.\n\n\nCapa Codificador (Text Vectorization)\nEl texto sin procesar cargado por tfds necesita ser procesado antes de que pueda ser utilizado en un modelo. La forma más sencilla de procesar texto para el entrenamiento es utilizando la capa TextVectorization.\nExplicación:\nLa capa TextVectorization es una herramienta en TensorFlow que transforma texto sin procesar en una representación numérica que los modelos de aprendizaje automático pueden entender. Convierte las palabras en vectores, lo que facilita el entrenamiento del modelo. Esto incluye tareas como:\n\nTokenización: Dividir el texto en palabras o subpalabras.\nNormalización: Convertir todo el texto a minúsculas, eliminar caracteres especiales, etc.\nVectorización: Asignar un índice o valor numérico a cada palabra o token, lo que permite representarlo como una matriz numérica.\n\n\nVOCAB_SIZE = 1000\nencoder = tf.keras.layers.TextVectorization(\n    max_tokens=VOCAB_SIZE)\n\n# Crea la capa y pasa el texto del conjunto de datos al método .adapt de la capa\nencoder.adapt(train_dataset.map(lambda text, label: text))\n\nEl método .adapt se utiliza para “entrenar” la capa en el conjunto de datos de texto. Esto significa que la capa analizará el texto y aprenderá el vocabulario, así como otras características (como la frecuencia de las palabras) que serán útiles para la vectorización\n\n# revisar los primeros 20 elementos del vocabulario creado\nvocab = np.array(encoder.get_vocabulary())\nvocab[:20]\n\narray(['', '[UNK]', 'the', 'and', 'a', 'of', 'to', 'is', 'in', 'it', 'i',\n       'this', 'that', 'br', 'was', 'as', 'for', 'with', 'movie', 'but'],\n      dtype='&lt;U14')\n\n\nUna vez que el vocabulario está establecido, la capa puede codificar el texto en índices. Los tensores de índices se rellenan con ceros hasta la secuencia más larga en el batch (a menos que establezcas una longitud de salida fija).\n\nencoded_ejemplo = encoder(ejemplo)[:3].numpy()\nencoded_ejemplo\n\narray([[ 48,  24,  95, ...,   0,   0,   0],\n       [  4,   1, 723, ...,   0,   0,   0],\n       [633,  18,   1, ...,  18,   1,   1]])\n\n\n\n# Visualizamos algunas imágenes\nfor n in range(3):\n  print(\"Original: \", ejemplo[n].numpy())\n  print(\"Round-trip: \", \" \".join(vocab[encoded_ejemplo[n]]))\n  print()\n\nOriginal:  b\"There are films that make careers. For George Romero, it was NIGHT OF THE LIVING DEAD; for Kevin Smith, CLERKS; for Robert Rodriguez, EL MARIACHI. Add to that list Onur Tukel's absolutely amazing DING-A-LING-LESS. Flawless film-making, and as assured and as professional as any of the aforementioned movies. I haven't laughed this hard since I saw THE FULL MONTY. (And, even then, I don't think I laughed quite this hard... So to speak.) Tukel's talent is considerable: DING-A-LING-LESS is so chock full of double entendres that one would have to sit down with a copy of this script and do a line-by-line examination of it to fully appreciate the, uh, breadth and width of it. Every shot is beautifully composed (a clear sign of a sure-handed director), and the performances all around are solid (there's none of the over-the-top scenery chewing one might've expected from a film like this). DING-A-LING-LESS is a film whose time has come.\"\nRound-trip:  there are films that make [UNK] for george [UNK] it was night of the living dead for [UNK] [UNK] [UNK] for robert [UNK] [UNK] [UNK] add to that [UNK] [UNK] [UNK] absolutely amazing [UNK] [UNK] [UNK] and as [UNK] and as [UNK] as any of the [UNK] movies i havent [UNK] this hard since i saw the full [UNK] and even then i dont think i [UNK] quite this hard so to [UNK] [UNK] talent is [UNK] [UNK] is so [UNK] full of [UNK] [UNK] that one would have to sit down with a [UNK] of this script and do a [UNK] [UNK] of it to [UNK] [UNK] the [UNK] [UNK] and [UNK] of it every shot is [UNK] [UNK] a clear [UNK] of a [UNK] director and the performances all around are [UNK] theres none of the [UNK] [UNK] [UNK] one [UNK] expected from a film like this [UNK] is a film whose time has come                                                                                                                                                                                                                                                                                                                                                                                        \n\nOriginal:  b\"A blackly comic tale of a down-trodden priest, Nazarin showcases the economy that Luis Bunuel was able to achieve in being able to tell a deeply humanist fable with a minimum of fuss. As an output from his Mexican era of film making, it was an invaluable talent to possess, with little money and extremely tight schedules. Nazarin, however, surpasses many of Bunuel's previous Mexican films in terms of the acting (Francisco Rabal is excellent), narrative and theme.&lt;br /&gt;&lt;br /&gt;The theme, interestingly, is something that was explored again in Viridiana, made three years later in Spain. It concerns the individual's struggle for humanity and altruism amongst a society that rejects any notion of virtue. Father Nazarin, however, is portrayed more sympathetically than Sister Viridiana. Whereas the latter seems to choose charity because she wishes to atone for her (perceived) sins, Nazarin's whole existence and reason for being seems to be to help others, whether they (or we) like it or not. The film's last scenes, in which he casts doubt on his behaviour and, in a split second, has to choose between the life he has been leading or the conventional life that is expected of a priest, are so emotional because they concern his moral integrity and we are never quite sure whether it remains intact or not.&lt;br /&gt;&lt;br /&gt;This is a remarkable film and I would urge anyone interested in classic cinema to seek it out. It is one of Bunuel's most moving films, and encapsulates many of his obsessions: frustrated desire, mad love, religious hypocrisy etc. In my view 'Nazarin' is second only to 'The Exterminating Angel', in terms of his Mexican movies, and is certainly near the top of the list of Bunuel's total filmic output.\"\nRound-trip:  a [UNK] comic tale of a [UNK] [UNK] [UNK] [UNK] the [UNK] that [UNK] [UNK] was able to [UNK] in being able to tell a [UNK] [UNK] [UNK] with a [UNK] of [UNK] as an [UNK] from his [UNK] [UNK] of film making it was an [UNK] talent to [UNK] with little money and extremely [UNK] [UNK] [UNK] however [UNK] many of [UNK] previous [UNK] films in [UNK] of the acting [UNK] [UNK] is excellent [UNK] and [UNK] br the theme [UNK] is something that was [UNK] again in [UNK] made three years later in [UNK] it [UNK] the [UNK] [UNK] for [UNK] and [UNK] [UNK] a society that [UNK] any [UNK] of [UNK] father [UNK] however is portrayed more [UNK] than sister [UNK] [UNK] the [UNK] seems to [UNK] [UNK] because she [UNK] to [UNK] for her [UNK] [UNK] [UNK] whole [UNK] and reason for being seems to be to help others whether they or we like it or not the films last scenes in which he [UNK] doubt on his [UNK] and in a [UNK] second has to [UNK] between the life he has been leading or the [UNK] life that is expected of a [UNK] are so emotional because they [UNK] his [UNK] [UNK] and we are never quite sure whether it [UNK] [UNK] or [UNK] br this is a [UNK] film and i would [UNK] anyone interested in classic cinema to [UNK] it out it is one of [UNK] most moving films and [UNK] many of his [UNK] [UNK] [UNK] [UNK] love [UNK] [UNK] etc in my view [UNK] is second only to the [UNK] [UNK] in [UNK] of his [UNK] movies and is certainly near the top of the [UNK] of [UNK] total [UNK] [UNK]                                                                                                                                                                                                                                                   \n\nOriginal:  b'Scary Movie 1-4, Epic Movie, Date Movie, Meet the Spartans, Not another Teen Movie and Another Gay Movie. Making \"Superhero Movie\" the eleventh in a series that single handily ruined the parody genre. Now I\\'ll admit it I have a soft spot for classics such as Airplane and The Naked Gun but you know you\\'ve milked a franchise so bad when you can see the gags a mile off. In fact the only thing that might really temp you into going to see this disaster is the incredibly funny but massive sell-out Leslie Neilson.&lt;br /&gt;&lt;br /&gt;You can tell he needs the money, wither that or he intends to go down with the ship like a good Capitan would. In no way is he bringing down this genre but hell he\\'s not helping it. But if I feel sorry for anybody in this film its decent actor Drake Bell who is put through an immense amount of embarrassment. The people who are put through the largest amount of torture by far however is the audience forced to sit through 90 minutes of laughless bile no funnier than herpes.&lt;br /&gt;&lt;br /&gt;After spoofing disaster films in Airplane!, police shows in The Naked Gun, and Hollywood horrors in Scary Movie 3 and 4, producer David Zucker sets his satirical sights on the superhero genre with this anarchic comedy lampooning everything from Spider-Man to X-Men and Superman Returns.&lt;br /&gt;&lt;br /&gt;Shortly after being bitten by a genetically altered dragonfly, high-school outcast Rick Riker (Drake Bell) begins to experience a startling transformation. Now Rick\\'s skin is as strong as steel, and he possesses the strength of ten men. Determined to use his newfound powers to fight crime, Rick creates a special costume and assumes the identity of The Dragonfly -- a fearless crime fighter dedicated to keeping the streets safe for law-abiding citizens.&lt;br /&gt;&lt;br /&gt;But every superhero needs a nemesis, and after Lou Landers (Christopher McDonald) is caught in the middle of an experiment gone horribly awry, he develops the power to leech the life force out of anyone he meets and becomes the villainous Hourglass. Intent on achieving immortality, the Hourglass attempts to gather as much life force as possible as the noble Dragonfly sets out to take down his archenemy and realize his destiny as a true hero. Craig Mazin writes and directs this low-flying spoof.&lt;br /&gt;&lt;br /&gt;featuring Tracy Morgan, Pamela Anderson, Leslie Nielsen, Marion Ross, Jeffrey Tambor, and Regina Hall.&lt;br /&gt;&lt;br /&gt;Hell Superhero Movie may earn some merit in the fact that it\\'s a hell of a lot better than Meet the Spartans and Epic Movie. But with great responsibility comes one of the worst outings of 2008 to date. Laughless but a little less irritating than Meet the Spartans. And in the same sense much more forgettable than meet the Spartans. But maybe that\\'s a good reason. There are still some of us trying to scrape away the stain that was Meet the Spartans from our memory.&lt;br /&gt;&lt;br /&gt;My final verdict? Avoid, unless you\\'re one of thoses people who enjoy such car crash cinema. As bad as Date Movie and Scary Movie 2 but not quite as bad as Meet the Spartans or Epic Movie. Super Villain.'\nRound-trip:  scary movie [UNK] [UNK] movie [UNK] movie meet the [UNK] not another [UNK] movie and another [UNK] movie making [UNK] movie the [UNK] in a series that single [UNK] [UNK] the [UNK] genre now ill admit it i have a [UNK] [UNK] for [UNK] such as [UNK] and the [UNK] [UNK] but you know youve [UNK] a [UNK] so bad when you can see the [UNK] a [UNK] off in fact the only thing that might really [UNK] you into going to see this [UNK] is the incredibly funny but [UNK] [UNK] [UNK] [UNK] br you can tell he needs the money [UNK] that or he [UNK] to go down with the [UNK] like a good [UNK] would in no way is he [UNK] down this genre but hell hes not [UNK] it but if i feel sorry for [UNK] in this film its decent actor [UNK] [UNK] who is put through an [UNK] [UNK] of [UNK] the people who are put through the [UNK] [UNK] of [UNK] by far however is the audience forced to sit through [UNK] minutes of [UNK] [UNK] no [UNK] than [UNK] br after [UNK] [UNK] films in [UNK] police shows in the [UNK] [UNK] and hollywood [UNK] in scary movie 3 and 4 [UNK] david [UNK] sets his [UNK] [UNK] on the [UNK] genre with this [UNK] comedy [UNK] everything from [UNK] to [UNK] and [UNK] [UNK] br [UNK] after being [UNK] by a [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] begins to experience a [UNK] [UNK] now [UNK] [UNK] is as strong as [UNK] and he [UNK] the [UNK] of ten men [UNK] to use his [UNK] [UNK] to fight crime [UNK] [UNK] a special [UNK] and [UNK] the [UNK] of the [UNK] a [UNK] crime [UNK] [UNK] to [UNK] the [UNK] [UNK] for [UNK] [UNK] br but every [UNK] needs a [UNK] and after [UNK] [UNK] [UNK] [UNK] is [UNK] in the middle of an [UNK] gone [UNK] [UNK] he [UNK] the power to [UNK] the life [UNK] out of anyone he meets and becomes the [UNK] [UNK] [UNK] on [UNK] [UNK] the [UNK] attempts to [UNK] as much life [UNK] as possible as the [UNK] [UNK] sets out to take down his [UNK] and realize his [UNK] as a true hero [UNK] [UNK] [UNK] and [UNK] this [UNK] [UNK] br [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] and [UNK] [UNK] br hell [UNK] movie may [UNK] some [UNK] in the fact that its a hell of a lot better than meet the [UNK] and [UNK] movie but with great [UNK] comes one of the worst [UNK] of [UNK] to [UNK] [UNK] but a little less [UNK] than meet the [UNK] and in the same sense much more [UNK] than meet the [UNK] but maybe thats a good reason there are still some of us trying to [UNK] away the [UNK] that was meet the [UNK] from our [UNK] br my final [UNK] avoid unless youre one of [UNK] people who enjoy such car [UNK] cinema as bad as [UNK] movie and scary movie 2 but not quite as bad as meet the [UNK] or [UNK] movie [UNK] [UNK]\n\n\n\n\n\nCreación del modelo usando keras\n\n'''model = tf.keras.Sequential([\n    encoder,\n    tf.keras.layers.Embedding(\n        input_dim=len(encoder.get_vocabulary()),\n        output_dim=64,\n        # Se ignora los valores en 0\n        mask_zero=True),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64), merge_mode='concat'),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dense(1)\n])'''\n\ndef rnn():\n    # Ahora utilizamos la API funcional de Keras\n    inputs = tf.keras.layers.Input(shape=(1,), dtype=tf.string)  # El input será una cadena de texto\n    x = encoder(inputs)  # Aplicamos el encoder\n\n    x = tf.keras.layers.Embedding(input_dim=len(encoder.get_vocabulary()), output_dim=64, mask_zero=True)(x)  # Capa de Embedding\n\n    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=False), merge_mode='concat')(x)  # Capa LSTM Bidireccional\n\n    x = tf.keras.layers.Dense(64, activation='relu')(x)  # Capa densa\n    outputs = tf.keras.layers.Dense(1)(x)  # Capa de salida\n\n    # Definimos el modelo\n    model = tf.keras.Model(inputs, outputs)\n\n    return model\n\n# crear la red RNN\nmodel = rnn()\n\n# Compilamos el modelo\nmodel.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              optimizer=tf.keras.optimizers.Adam(1e-4),\n              metrics=['accuracy'])\n\n# Verificamos la estructura del modelo\nmodel.summary()\n\nModel: \"functional_2\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃ Layer (type)              ┃ Output Shape           ┃        Param # ┃ Connected to           ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_2             │ (None, 1)              │              0 │ -                      │\n│ (InputLayer)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ text_vectorization        │ (None, None)           │              0 │ input_layer_2[0][0]    │\n│ (TextVectorization)       │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_4 (Embedding)   │ (None, None, 64)       │         64,000 │ text_vectorization[2]… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ not_equal_2 (NotEqual)    │ (None, None)           │              0 │ text_vectorization[2]… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ bidirectional_4           │ (None, 128)            │         66,048 │ embedding_4[0][0],     │\n│ (Bidirectional)           │                        │                │ not_equal_2[0][0]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_8 (Dense)           │ (None, 64)             │          8,256 │ bidirectional_4[0][0]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_9 (Dense)           │ (None, 1)              │             65 │ dense_8[0][0]          │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n\n\n\n Total params: 138,369 (540.50 KB)\n\n\n\n Trainable params: 138,369 (540.50 KB)\n\n\n\n Non-trainable params: 0 (0.00 B)\n\n\n\n\ntf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=True)\n\n\n\n\n\n\n\n\n\n# hacer una prueba sin usar padding\n# El texto crudo que quieres predecir\nsample_text = ('The movie was cool. The animation and the graphics were out of this world.')\n\n# No es necesario hacer la vectorización manual aquí, simplemente pasa el texto crudo al modelo\npredictions = model.predict(tf.constant([sample_text]))\n\n# Imprime la predicción\nprint(predictions[0])\n\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 279ms/step\n\n[-0.00120403]\n\n\n\n\n\n# prueba ahora usando padding\n# debe dar el mismo resultado\npadding = \"the \" * 2000\npredictions = model.predict(tf.constant([sample_text, padding]))\nprint(predictions[0])\n\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 367ms/step\n\n[-0.00120403]\n\n\n\n\n\n\nEntrenamiento y evaluación del modelo\n\nhistory = model.fit(train_dataset, epochs=10,\n                    validation_data=test_dataset,\n                    validation_steps=30)\n\n\nEpoch 1/10\n\n782/782 ━━━━━━━━━━━━━━━━━━━━ 41s 49ms/step - accuracy: 0.5446 - loss: 0.6621 - val_accuracy: 0.7406 - val_loss: 0.4787\n\nEpoch 2/10\n\n782/782 ━━━━━━━━━━━━━━━━━━━━ 38s 49ms/step - accuracy: 0.8113 - loss: 0.4087 - val_accuracy: 0.8531 - val_loss: 0.3368\n\nEpoch 3/10\n\n782/782 ━━━━━━━━━━━━━━━━━━━━ 41s 48ms/step - accuracy: 0.8475 - loss: 0.3460 - val_accuracy: 0.8583 - val_loss: 0.3476\n\nEpoch 4/10\n\n782/782 ━━━━━━━━━━━━━━━━━━━━ 41s 48ms/step - accuracy: 0.8518 - loss: 0.3369 - val_accuracy: 0.8385 - val_loss: 0.3222\n\nEpoch 5/10\n\n782/782 ━━━━━━━━━━━━━━━━━━━━ 38s 48ms/step - accuracy: 0.8585 - loss: 0.3212 - val_accuracy: 0.8448 - val_loss: 0.3103\n\nEpoch 6/10\n\n782/782 ━━━━━━━━━━━━━━━━━━━━ 42s 50ms/step - accuracy: 0.8657 - loss: 0.3102 - val_accuracy: 0.8833 - val_loss: 0.3025\n\nEpoch 7/10\n\n782/782 ━━━━━━━━━━━━━━━━━━━━ 37s 47ms/step - accuracy: 0.8650 - loss: 0.3053 - val_accuracy: 0.8417 - val_loss: 0.3308\n\nEpoch 8/10\n\n782/782 ━━━━━━━━━━━━━━━━━━━━ 38s 48ms/step - accuracy: 0.8643 - loss: 0.3065 - val_accuracy: 0.8573 - val_loss: 0.3422\n\nEpoch 9/10\n\n782/782 ━━━━━━━━━━━━━━━━━━━━ 41s 48ms/step - accuracy: 0.8723 - loss: 0.2969 - val_accuracy: 0.8604 - val_loss: 0.3092\n\nEpoch 10/10\n\n782/782 ━━━━━━━━━━━━━━━━━━━━ 39s 50ms/step - accuracy: 0.8674 - loss: 0.3016 - val_accuracy: 0.8583 - val_loss: 0.3209\n\n\n\n\n\ntest_loss, test_acc = model.evaluate(test_dataset)\n\nprint('Test Loss:', test_loss)\nprint('Test Accuracy:', test_acc)\n\n\n782/782 ━━━━━━━━━━━━━━━━━━━━ 18s 23ms/step - accuracy: 0.8611 - loss: 0.3154\n\nTest Loss: 0.3137839138507843\n\nTest Accuracy: 0.8598799705505371\n\n\n\n\n\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplot_graphs(history, 'accuracy')\nplt.ylim(None, 1)\nplt.subplot(1, 2, 2)\nplot_graphs(history, 'loss')\nplt.ylim(0, None)\n\n\n\n\n\n\n\n\n\n# realizar una predicción des pues de entrenar\nsample_text = ('The movie was cool. The animation and the graphics were out of this world.')\npredictions = model.predict(tf.constant([sample_text]))\nprint(predictions)\n\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n[[1.2081792]]\n\n\n\n\nCómo podríamos agregar más capas LSTM para aumentar la complejidad del modelo?\n\n\n\nlayered_bidirectional.png\n\n\nLas capas recurrentes de Keras tienen dos modos disponibles que son controlados por el argumento del constructor return_sequences:\n\nSi es False devuelve sólo la última salida para cada secuencia de entrada (un tensor 2D de forma (batch_size, output_features)). Este es el valor por defecto, utilizado en el modelo anterior.\nSi es True se devuelven las secuencias completas de salidas sucesivas para cada paso de tiempo (un tensor 3D de forma (batch_size, timesteps, output_features)).\n\n# model = tf.keras.Sequential([\n    encoder,\n    tf.keras.layers.Embedding(len(encoder.get_vocabulary()), 64, mask_zero=True),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(1)\n])"
  },
  {
    "objectID": "semana_2/notebooks/Nb_2b_Resolviendo_desafios_con_RNNs_usando_keras.html#leer-datos",
    "href": "semana_2/notebooks/Nb_2b_Resolviendo_desafios_con_RNNs_usando_keras.html#leer-datos",
    "title": "Resolviendo diversidad de tareas con RNNs",
    "section": "Leer datos",
    "text": "Leer datos\n\ndf, date_time = read_dataset_clima()\n\n\ndf\n\n\n    \n\n\n\n\n\n\np (mbar)\nT (degC)\nTpot (K)\nTdew (degC)\nrh (%)\nVPmax (mbar)\nVPact (mbar)\nVPdef (mbar)\nsh (g/kg)\nH2OC (mmol/mol)\nrho (g/m**3)\nwv (m/s)\nmax. wv (m/s)\nwd (deg)\n\n\n\n\n5\n996.50\n-8.05\n265.38\n-8.78\n94.40\n3.33\n3.14\n0.19\n1.96\n3.15\n1307.86\n0.21\n0.63\n192.7\n\n\n11\n996.62\n-8.88\n264.54\n-9.77\n93.20\n3.12\n2.90\n0.21\n1.81\n2.91\n1312.25\n0.25\n0.63\n190.3\n\n\n17\n996.84\n-8.81\n264.59\n-9.66\n93.50\n3.13\n2.93\n0.20\n1.83\n2.94\n1312.18\n0.18\n0.63\n167.2\n\n\n23\n996.99\n-9.05\n264.34\n-10.02\n92.60\n3.07\n2.85\n0.23\n1.78\n2.85\n1313.61\n0.10\n0.38\n240.0\n\n\n29\n997.46\n-9.63\n263.72\n-10.65\n92.20\n2.94\n2.71\n0.23\n1.69\n2.71\n1317.19\n0.40\n0.88\n157.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n420521\n1002.18\n-0.98\n272.01\n-5.36\n72.00\n5.69\n4.09\n1.59\n2.54\n4.08\n1280.70\n0.87\n1.36\n190.6\n\n\n420527\n1001.40\n-1.40\n271.66\n-6.84\n66.29\n5.51\n3.65\n1.86\n2.27\n3.65\n1281.87\n1.02\n1.92\n225.4\n\n\n420533\n1001.19\n-2.75\n270.32\n-6.90\n72.90\n4.99\n3.64\n1.35\n2.26\n3.63\n1288.02\n0.71\n1.56\n158.7\n\n\n420539\n1000.65\n-2.89\n270.22\n-7.15\n72.30\n4.93\n3.57\n1.37\n2.22\n3.57\n1288.03\n0.35\n0.68\n216.7\n\n\n420545\n1000.11\n-3.93\n269.23\n-8.09\n72.60\n4.56\n3.31\n1.25\n2.06\n3.31\n1292.41\n0.56\n1.00\n202.6\n\n\n\n\n70091 rows × 14 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\ndate_time\n\n\n\n\n\n\n\n\nDate Time\n\n\n\n\n5\n2009-01-01 01:00:00\n\n\n11\n2009-01-01 02:00:00\n\n\n17\n2009-01-01 03:00:00\n\n\n23\n2009-01-01 04:00:00\n\n\n29\n2009-01-01 05:00:00\n\n\n...\n...\n\n\n420521\n2016-12-31 19:10:00\n\n\n420527\n2016-12-31 20:10:00\n\n\n420533\n2016-12-31 21:10:00\n\n\n420539\n2016-12-31 22:10:00\n\n\n420545\n2016-12-31 23:10:00\n\n\n\n\n70091 rows × 1 columns\ndtype: datetime64[ns]\n\n\n\nplot_variables(df, date_time)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntrain_df, val_df, test_df, num_features, column_indices = split_data(df)\ntrain_df.shape, val_df.shape, test_df.shape\n\n((49063, 14), (14018, 14), (7010, 14))\n\n\n\ntrain_df.head()\n\n\n    \n\n\n\n\n\n\np (mbar)\nT (degC)\nTpot (K)\nTdew (degC)\nrh (%)\nVPmax (mbar)\nVPact (mbar)\nVPdef (mbar)\nsh (g/kg)\nH2OC (mmol/mol)\nrho (g/m**3)\nwv (m/s)\nmax. wv (m/s)\nwd (deg)\n\n\n\n\n5\n996.50\n-8.05\n265.38\n-8.78\n94.4\n3.33\n3.14\n0.19\n1.96\n3.15\n1307.86\n0.21\n0.63\n192.7\n\n\n11\n996.62\n-8.88\n264.54\n-9.77\n93.2\n3.12\n2.90\n0.21\n1.81\n2.91\n1312.25\n0.25\n0.63\n190.3\n\n\n17\n996.84\n-8.81\n264.59\n-9.66\n93.5\n3.13\n2.93\n0.20\n1.83\n2.94\n1312.18\n0.18\n0.63\n167.2\n\n\n23\n996.99\n-9.05\n264.34\n-10.02\n92.6\n3.07\n2.85\n0.23\n1.78\n2.85\n1313.61\n0.10\n0.38\n240.0\n\n\n29\n997.46\n-9.63\n263.72\n-10.65\n92.2\n2.94\n2.71\n0.23\n1.69\n2.71\n1317.19\n0.40\n0.88\n157.0\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n    \n  \n\n\n\ntrain_df, val_df, test_df = normalizacion_datos(train_df, val_df, test_df)\ntrain_df.describe()\n\n\n    \n\n\n\n\n\n\np (mbar)\nT (degC)\nTpot (K)\nTdew (degC)\nrh (%)\nVPmax (mbar)\nVPact (mbar)\nVPdef (mbar)\nsh (g/kg)\nH2OC (mmol/mol)\nrho (g/m**3)\nwv (m/s)\nmax. wv (m/s)\nwd (deg)\n\n\n\n\ncount\n4.906300e+04\n4.906300e+04\n4.906300e+04\n4.906300e+04\n4.906300e+04\n49063.000000\n4.906300e+04\n49063.000000\n4.906300e+04\n4.906300e+04\n4.906300e+04\n4.906300e+04\n4.906300e+04\n4.906300e+04\n\n\nmean\n2.027515e-16\n-1.946415e-16\n9.685730e-16\n1.853728e-17\n-6.719765e-16\n0.000000\n-2.270817e-16\n0.000000\n-1.506154e-16\n1.807385e-16\n-2.321795e-15\n1.540912e-16\n-1.616219e-16\n-2.178131e-16\n\n\nstd\n1.000000e+00\n1.000000e+00\n1.000000e+00\n1.000000e+00\n1.000000e+00\n1.000000\n1.000000e+00\n1.000000\n1.000000e+00\n1.000000e+00\n1.000000e+00\n1.000000e+00\n1.000000e+00\n1.000000e+00\n\n\nmin\n-9.045695e+00\n-3.682079e+00\n-3.707266e+00\n-4.216645e+00\n-3.746587e+00\n-1.609554\n-2.030996e+00\n-0.829861\n-2.022853e+00\n-2.031986e+00\n-3.846513e+00\n-1.403684e+00\n-1.535423e+00\n-1.977937e+00\n\n\n25%\n-6.093840e-01\n-7.069026e-01\n-6.939982e-01\n-6.697392e-01\n-6.581569e-01\n-0.750526\n-7.786971e-01\n-0.657581\n-7.762466e-01\n-7.761335e-01\n-7.116941e-01\n-7.390786e-01\n-7.595612e-01\n-6.326198e-01\n\n\n50%\n5.467421e-02\n9.450477e-03\n1.318575e-02\n5.168967e-02\n1.989686e-01\n-0.222892\n-1.561120e-01\n-0.383594\n-1.548152e-01\n-1.540757e-01\n-7.847992e-02\n-2.308512e-01\n-2.250786e-01\n2.674928e-01\n\n\n75%\n6.548575e-01\n7.200265e-01\n7.123465e-01\n7.530390e-01\n8.150841e-01\n0.533469\n6.684569e-01\n0.268164\n6.650251e-01\n6.651626e-01\n6.442168e-01\n4.793641e-01\n5.206108e-01\n6.932912e-01\n\n\nmax\n2.913378e+00\n3.066661e+00\n3.041354e+00\n2.647686e+00\n1.455361e+00\n5.846190\n4.489514e+00\n7.842254\n4.550843e+00\n4.524268e+00\n4.310438e+00\n7.724863e+00\n8.593884e+00\n2.131645e+00"
  },
  {
    "objectID": "semana_2/notebooks/Nb_2b_Resolviendo_desafios_con_RNNs_usando_keras.html#creación-de-ventanas",
    "href": "semana_2/notebooks/Nb_2b_Resolviendo_desafios_con_RNNs_usando_keras.html#creación-de-ventanas",
    "title": "Resolviendo diversidad de tareas con RNNs",
    "section": "Creación de ventanas",
    "text": "Creación de ventanas\nEjemplo para un problema que dado las últimas 6 mediciones de temperatura va a predecir la siguiente hora de temperatura.\n\n\n\nsplit_window.png\n\n\n\nEjemplo creación dataset ventanas\n\n# Crear un array de 15 minutos y 3 características (features), con valores consecutivos para facilitar el entendimiento\ndatae = np.arange(10 * 3).reshape(10, 3)\n\n# Crear un DataFrame para mostrar los datos de manera más clara\ndfe = pd.DataFrame(datae, columns=['Feature_1', 'Feature_2', 'Target'])\ndfe.index.name = 'Minuto'\n\n# Mostrar el DataFrame\ndfe\n\n\n    \n\n\n\n\n\n\nFeature_1\nFeature_2\nTarget\n\n\nMinuto\n\n\n\n\n\n\n\n0\n0\n1\n2\n\n\n1\n3\n4\n5\n\n\n2\n6\n7\n8\n\n\n3\n9\n10\n11\n\n\n4\n12\n13\n14\n\n\n5\n15\n16\n17\n\n\n6\n18\n19\n20\n\n\n7\n21\n22\n23\n\n\n8\n24\n25\n26\n\n\n9\n27\n28\n29\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\n# La variable a predecir es la última columna (columna final)\ntargets = datae[2:, -1]  # Los targets son el valor de la columna final (variable a predecir) desplazados por 2 pasos\ntargets\n\narray([ 8, 11, 14, 17, 20, 23, 26, 29])\n\n\n\n# Crear el dataset de series temporales\nds = tf.keras.utils.timeseries_dataset_from_array(\n    data=datae[:-1],  # Todas las filas menos la última, porque no hay target para la última fila\n    targets=targets,  # Los valores a predecir son la columna final de la siguiente fila\n    sequence_length=2,  # Usamos secuencias de 6 minutos\n    sequence_stride=1,  # Stride de 1 para obtener todas las posibles ventanas\n    shuffle=False,  # Barajamos las secuencias\n    batch_size=2  # Agrupamos en lotes de 2 secuencias\n)\n\n\n# Mostrar los primeros 5 lotes de inputs y labels, con un formato mejorado\nfor batch_num, batch in enumerate(ds.take(5), 1):\n    inputs, labels = batch\n    print(f\"Batch {batch_num}:\")\n    print(f\"Inputs shape: {inputs.shape}\")\n    print(\"Inputs:\")\n\n    # Imprimir cada secuencia de inputs con su respectiva etiqueta al final\n    for i, (input_sequence, label) in enumerate(zip(inputs.numpy(), labels.numpy()), 1):\n        print(f\"  Sequence {i}:\")\n        print(f\" {input_sequence} -&gt; Target: {label}\")\n\n    print(\"\\n\" + \"-\"*50 + \"\\n\")\n\nBatch 1:\nInputs shape: (2, 2, 3)\nInputs:\n  Sequence 1:\n [[0 1 2]\n [3 4 5]] -&gt; Target: 8\n  Sequence 2:\n [[3 4 5]\n [6 7 8]] -&gt; Target: 11\n\n--------------------------------------------------\n\nBatch 2:\nInputs shape: (2, 2, 3)\nInputs:\n  Sequence 1:\n [[ 6  7  8]\n [ 9 10 11]] -&gt; Target: 14\n  Sequence 2:\n [[ 9 10 11]\n [12 13 14]] -&gt; Target: 17\n\n--------------------------------------------------\n\nBatch 3:\nInputs shape: (2, 2, 3)\nInputs:\n  Sequence 1:\n [[12 13 14]\n [15 16 17]] -&gt; Target: 20\n  Sequence 2:\n [[15 16 17]\n [18 19 20]] -&gt; Target: 23\n\n--------------------------------------------------\n\nBatch 4:\nInputs shape: (2, 2, 3)\nInputs:\n  Sequence 1:\n [[18 19 20]\n [21 22 23]] -&gt; Target: 26\n  Sequence 2:\n [[21 22 23]\n [24 25 26]] -&gt; Target: 29\n\n--------------------------------------------------\n\n\n\n\n\nRetomando\n\nMAX_EPOCHS = 20\n\ndef compile_and_fit(model, window, patience=2):\n  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n                                                    patience=patience,\n                                                    mode='min')\n\n  model.compile(loss=tf.keras.losses.MeanSquaredError(),\n                optimizer=tf.keras.optimizers.Adam(),\n                metrics=[tf.keras.metrics.MeanAbsoluteError()])\n\n  history = model.fit(window.train, epochs=MAX_EPOCHS,\n                      validation_data=window.val,\n                      callbacks=[early_stopping])\n  return history\n\n\nWIDTH_TEMP = 6\nwindow = WindowGenerator(\n    input_width=WIDTH_TEMP,\n    label_width=1,\n    shift=1,\n    train_df = train_df,\n    val_df = val_df,\n    test_df=test_df,\n    label_columns=['T (degC)'])\n\nwindow\n\nTotal window size: 7\nInput indices: [0 1 2 3 4 5]\nLabel indices: [6]\nLabel column name(s): ['T (degC)']\n\n\n\n# Stack three slices, the length of the total window.\nexample_window = tf.stack([np.array(train_df[:window.total_window_size]),\n                           np.array(train_df[100:100+window.total_window_size]),\n                           np.array(train_df[200:200+window.total_window_size])])\n\nexample_inputs, example_labels = window.split_window(example_window)\n\nprint('All shapes are: (batch, time, features)')\nprint(f'Window shape: {example_window.shape}')\nprint(f'Inputs shape: {example_inputs.shape}')\nprint(f'Labels shape: {example_labels.shape}')\n\nAll shapes are: (batch, time, features)\nWindow shape: (3, 7, 14)\nInputs shape: (3, 6, 14)\nLabels shape: (3, 1, 1)\n\n\n\n# graficar los datos en las ventanas\nwindow.plot()\n\n\n\n\n\n\n\n\n\nlstm_model = tf.keras.models.Sequential([\n    # Shape [batch, time, features] =&gt; [batch, time, lstm_units]\n    tf.keras.layers.LSTM(32, return_sequences=True),\n    # Shape =&gt; [batch, time, features]\n    tf.keras.layers.Dense(units=1)\n])\n\n\nprint('Input shape:', window.example[0].shape)\nprint('Output shape:', lstm_model(window.example[0]).shape)\n\nInput shape: (32, 6, 14)\nOutput shape: (32, 6, 1)\n\n\n\nhistory = compile_and_fit(lstm_model, window)\n\nval_performance = {}\nperformance = {}\nval_performance['LSTM'] = lstm_model.evaluate(window.val, return_dict=True)\nperformance['LSTM'] = lstm_model.evaluate(window.test, verbose=0, return_dict=True)\n\n\nEpoch 1/20\n\n1534/1534 ━━━━━━━━━━━━━━━━━━━━ 13s 8ms/step - loss: 0.1702 - mean_absolute_error: 0.2857 - val_loss: 0.0806 - val_mean_absolute_error: 0.2000\n\nEpoch 2/20\n\n1534/1534 ━━━━━━━━━━━━━━━━━━━━ 19s 7ms/step - loss: 0.0796 - mean_absolute_error: 0.1978 - val_loss: 0.0805 - val_mean_absolute_error: 0.2008\n\nEpoch 3/20\n\n1534/1534 ━━━━━━━━━━━━━━━━━━━━ 10s 6ms/step - loss: 0.0759 - mean_absolute_error: 0.1912 - val_loss: 0.0750 - val_mean_absolute_error: 0.1902\n\nEpoch 4/20\n\n1534/1534 ━━━━━━━━━━━━━━━━━━━━ 13s 9ms/step - loss: 0.0727 - mean_absolute_error: 0.1861 - val_loss: 0.0742 - val_mean_absolute_error: 0.1871\n\nEpoch 5/20\n\n1534/1534 ━━━━━━━━━━━━━━━━━━━━ 18s 7ms/step - loss: 0.0720 - mean_absolute_error: 0.1845 - val_loss: 0.0732 - val_mean_absolute_error: 0.1869\n\nEpoch 6/20\n\n1534/1534 ━━━━━━━━━━━━━━━━━━━━ 12s 8ms/step - loss: 0.0705 - mean_absolute_error: 0.1822 - val_loss: 0.0728 - val_mean_absolute_error: 0.1857\n\nEpoch 7/20\n\n1534/1534 ━━━━━━━━━━━━━━━━━━━━ 21s 8ms/step - loss: 0.0698 - mean_absolute_error: 0.1810 - val_loss: 0.0732 - val_mean_absolute_error: 0.1864\n\nEpoch 8/20\n\n1534/1534 ━━━━━━━━━━━━━━━━━━━━ 11s 7ms/step - loss: 0.0693 - mean_absolute_error: 0.1804 - val_loss: 0.0721 - val_mean_absolute_error: 0.1836\n\nEpoch 9/20\n\n1534/1534 ━━━━━━━━━━━━━━━━━━━━ 20s 7ms/step - loss: 0.0690 - mean_absolute_error: 0.1797 - val_loss: 0.0725 - val_mean_absolute_error: 0.1850\n\nEpoch 10/20\n\n1534/1534 ━━━━━━━━━━━━━━━━━━━━ 19s 6ms/step - loss: 0.0687 - mean_absolute_error: 0.1794 - val_loss: 0.0728 - val_mean_absolute_error: 0.1851\n\n438/438 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - loss: 0.0729 - mean_absolute_error: 0.1852\n\n\n\n\n\nperformance\n\n{'LSTM': {'loss': 0.0691012442111969,\n  'mean_absolute_error': 0.18326018750667572}}\n\n\n\nval_performance\n\n{'LSTM': {'loss': 0.07278452813625336,\n  'mean_absolute_error': 0.1851218044757843}}"
  },
  {
    "objectID": "semana_3/notebooks/Nb_3a_Introduccion_transfer_learning_finetuning.html",
    "href": "semana_3/notebooks/Nb_3a_Introduccion_transfer_learning_finetuning.html",
    "title": "Introducción a pre-trained models, transfer learning and fine tuning",
    "section": "",
    "text": "Open In Colab\nEn este notebook encontrarás material introductorio para entender los conceptos de modelos preentrenados, transferencia de aprendizaje y ajuste fino. Y cómo estos, empleados de forman correcta, pueden aumentar el rendimiento de tus modelos."
  },
  {
    "objectID": "semana_3/notebooks/Nb_3a_Introduccion_transfer_learning_finetuning.html#transfer-learning-y-fine-tuning-en-tareas-de-visión-por-computadora",
    "href": "semana_3/notebooks/Nb_3a_Introduccion_transfer_learning_finetuning.html#transfer-learning-y-fine-tuning-en-tareas-de-visión-por-computadora",
    "title": "Introducción a pre-trained models, transfer learning and fine tuning",
    "section": "Transfer Learning y fine tuning en tareas de Visión por Computadora",
    "text": "Transfer Learning y fine tuning en tareas de Visión por Computadora\nModelos preentrenados\nEn esta sección, utilizaremos el modelo pre-entrenado VGG16, el cual es una red convolucional que es usada para reconocimiento de imágenes. Este modelo fue entrenado con ImageNet, por lo cual es un modelo bastante robusto.\n\nObjetivo:\n\nEl objetivo será cargar dicho modelo pre-entrenado y utilizarlo sobre el dataset MNIST, el cual contiene 70.000 imagenes de digitos escritos a mano. Así, poder clasificar dichos números con nuestro modelo entrenado previamente.\n\n\n#@title Importar librerías\n# Importamos las librerias a utilizar\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nfrom tensorflow.keras import layers, models, optimizers, callbacks\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.utils import to_categorical\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import backend as K\n\nfrom gensim.models import KeyedVectors\n\n\n%matplotlib inline\n\n\n#@title Definir funciones complementarias\ndef plot_graphs(history, metric):\n  plt.plot(history.history[metric])\n  plt.plot(history.history['val_'+metric], '')\n  plt.xlabel(\"Epochs\")\n  plt.ylabel(metric)\n  plt.legend([metric, 'val_'+metric])\n\ndef cosine_similarity(vec_a, vec_b):\n  \"\"\"Compute cosine similarity between vec_a and vec_b\"\"\"\n  return np.dot(vec_a, vec_b) / (np.linalg.norm(vec_a) * np.linalg.norm(vec_b))\n\n\n# Cargamos el dataset MNIST\n(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\nprint(\"Train shape: \", train_images.shape)\nprint(\"Test shape: \", test_images.shape)\n\nTrain shape:  (60000, 28, 28)\nTest shape:  (10000, 28, 28)\n\n\n\n# dibujamos ciertos ejemplos de entrenamiento\nplt.figure(figsize=(10, 4))\nfor i in range(10):\n    plt.subplot(2, 5, i + 1)\n    plt.grid(False)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(train_images[i], cmap=plt.cm.gray)\n    plt.xlabel(train_labels[i])\nplt.show()\n\n\n\n\n\n\n\n\n\n# Redimensionamos las imagenes a 32x32 (el minimo tamaño que soporta vgg16)\ntrain_images = tf.image.grayscale_to_rgb(tf.expand_dims(train_images, axis=-1))\ntest_images = tf.image.grayscale_to_rgb(tf.expand_dims(test_images, axis=-1))\n# Agregamos 3 canales de color (RGB) debido a que la red tambien lo necesita\ntrain_images = tf.image.resize(train_images, [32, 32])\ntest_images = tf.image.resize(test_images, [32, 32])\n# Normalizamos las imagenes entre [0, 1] para que el aprendizaje sea mas suave\ntrain_images = train_images / 255.0\ntest_images = test_images / 255.0\nprint(\"Train shape: \", train_images.shape)\nprint(\"Test shape: \", test_images.shape)\n\nTrain shape:  (60000, 32, 32, 3)\nTest shape:  (10000, 32, 32, 3)\n\n\n\n# Convertimos las etiquetas a formato one-hot encoding\ntrain_labels_ohc = to_categorical(train_labels, 10)\ntest_labels_ohc = to_categorical(test_labels, 10)\nprint(train_labels_ohc[:,1])\n\n[0. 0. 0. ... 0. 0. 0.]\n\n\n\n# Cargamos el modelo VGG16 preentrenado, excluyendo las capas superiores (top=False)\n# Recuerde que las capas superiores son las que definen el tipo de problema a solucionar\n# Como nuestro problema es de 10 categorias (10 digitos), agregaremos nuestras propias capas superiores\nvgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\nvgg16_base.summary()\n\nModel: \"vgg16\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer (InputLayer)             │ (None, 32, 32, 3)           │               0 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ block1_conv1 (Conv2D)                │ (None, 32, 32, 64)          │           1,792 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ block1_conv2 (Conv2D)                │ (None, 32, 32, 64)          │          36,928 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ block1_pool (MaxPooling2D)           │ (None, 16, 16, 64)          │               0 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ block2_conv1 (Conv2D)                │ (None, 16, 16, 128)         │          73,856 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ block2_conv2 (Conv2D)                │ (None, 16, 16, 128)         │         147,584 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ block2_pool (MaxPooling2D)           │ (None, 8, 8, 128)           │               0 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ block3_conv1 (Conv2D)                │ (None, 8, 8, 256)           │         295,168 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ block3_conv2 (Conv2D)                │ (None, 8, 8, 256)           │         590,080 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ block3_conv3 (Conv2D)                │ (None, 8, 8, 256)           │         590,080 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ block3_pool (MaxPooling2D)           │ (None, 4, 4, 256)           │               0 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ block4_conv1 (Conv2D)                │ (None, 4, 4, 512)           │       1,180,160 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ block4_conv2 (Conv2D)                │ (None, 4, 4, 512)           │       2,359,808 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ block4_conv3 (Conv2D)                │ (None, 4, 4, 512)           │       2,359,808 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ block4_pool (MaxPooling2D)           │ (None, 2, 2, 512)           │               0 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ block5_conv1 (Conv2D)                │ (None, 2, 2, 512)           │       2,359,808 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ block5_conv2 (Conv2D)                │ (None, 2, 2, 512)           │       2,359,808 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ block5_conv3 (Conv2D)                │ (None, 2, 2, 512)           │       2,359,808 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ block5_pool (MaxPooling2D)           │ (None, 1, 1, 512)           │               0 │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n\n\n\n Total params: 14,714,688 (56.13 MB)\n\n\n\n Trainable params: 14,714,688 (56.13 MB)\n\n\n\n Non-trainable params: 0 (0.00 B)\n\n\n\n\n# Ahora congelamos los pesos del modelo, pues solo queremos agrega una nueva capa\n# con 10 neuronas, donde cada una representará el digito que queremos predecir\nvgg16_base.trainable = False\nmodel = models.Sequential([\n    vgg16_base,\n    layers.Flatten(),\n    layers.Dropout(0.5),\n    layers.Dense(10, activation='softmax')  # 10 clases de salida\n])\n\n\n# Compilamos y entrenamos los pesos de nuestra última capa\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = model.fit(train_images, train_labels_ohc, epochs=5,\n                    batch_size=64, validation_data=(test_images, test_labels_ohc))\n\n\nEpoch 1/5\n\n938/938 ━━━━━━━━━━━━━━━━━━━━ 23s 16ms/step - accuracy: 0.5699 - loss: 1.3459 - val_accuracy: 0.8679 - val_loss: 0.5477\n\nEpoch 2/5\n\n938/938 ━━━━━━━━━━━━━━━━━━━━ 30s 10ms/step - accuracy: 0.8064 - loss: 0.6443 - val_accuracy: 0.8992 - val_loss: 0.4113\n\nEpoch 3/5\n\n938/938 ━━━━━━━━━━━━━━━━━━━━ 10s 10ms/step - accuracy: 0.8276 - loss: 0.5497 - val_accuracy: 0.9120 - val_loss: 0.3532\n\nEpoch 4/5\n\n938/938 ━━━━━━━━━━━━━━━━━━━━ 10s 11ms/step - accuracy: 0.8366 - loss: 0.5071 - val_accuracy: 0.9121 - val_loss: 0.3253\n\nEpoch 5/5\n\n938/938 ━━━━━━━━━━━━━━━━━━━━ 12s 13ms/step - accuracy: 0.8482 - loss: 0.4773 - val_accuracy: 0.9237 - val_loss: 0.3011\n\n\n\n\n\n# Medimos la precisión del modelo en el conjunto de prueba\ntest_loss, test_acc = model.evaluate(test_images, test_labels_ohc)\n\nprint(f\"Precisión en el conjunto de prueba: {test_acc}\")\n\n\n313/313 ━━━━━━━━━━━━━━━━━━━━ 3s 7ms/step - accuracy: 0.9149 - loss: 0.3224\n\nPrecisión en el conjunto de prueba: 0.9236999750137329\n\n\n\n\n\n# Mostramos el modelo\nmodel.summary()\n\nModel: \"sequential\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ vgg16 (Functional)                   │ (None, 1, 1, 512)           │      14,714,688 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten (Flatten)                    │ (None, 512)                 │               0 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (Dropout)                    │ (None, 512)                 │               0 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (Dense)                        │ (None, 10)                  │           5,130 │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n\n\n\n Total params: 14,730,080 (56.19 MB)\n\n\n\n Trainable params: 5,130 (20.04 KB)\n\n\n\n Non-trainable params: 14,714,688 (56.13 MB)\n\n\n\n Optimizer params: 10,262 (40.09 KB)\n\n\n\n\n# Dibujamos ciertas imágenes con sus predicciones\nplt.figure(figsize=(10, 4))\nfor i in range(10):\n    plt.subplot(2, 5, i + 1)\n    plt.grid(False)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(test_images[i], cmap=plt.cm.gray)\n    pred = np.argmax(model.predict(np.expand_dims(test_images[i], axis=0), verbose=False))\n    plt.xlabel(f\"Pred: {pred}\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\nObservaciones:\n\nNote que al cargar un modelo pre-entrenado, logramos tener unos pesos que ya saben encontrar ciertos tipos de características dentro de las imágenes. Es por ello que cuando entrenamos nuestra capa superior (10 neuronas), solo hacen falta 5 épocas para alcanzar un accuracy del 92.14% en el conjunto de prueba.\nCabe resaltar que utilizamos un modelo pre-entrenado y agregamos una capa superior para adaptarlo a nuestro problema. Esto se podría considerar transfer learning tambien.\n\nModelos preentrenados\nPara dejar mas claro el concepto de transfer learning lo que haremos es coger el mismo modelo definido anteriormente, solo que esta vez si entrenaremos los pesos del modelo pre-entrenado, para así alcanzar un mejor rendimiento.\n\n# Reiniciar el backend para que las ejecuciones anteriores no interfieran\nK.clear_session()\n\n\n# Definimos el modelo, especificando que queremos entrenar el modelo VGG16\nvgg16_base.trainable = True\nmodel_2 = models.Sequential([\n    vgg16_base,\n    layers.Flatten(),\n    layers.Dropout(0.5),\n    layers.Dense(10, activation='softmax')  # 10 clases de salida\n])\n\n\n# Compilamos y entrenamos los pesos de nuestra última capa\n\nmodel_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = model_2.fit(train_images, train_labels_ohc, epochs=5,\n                    batch_size=64, validation_data=(test_images, test_labels_ohc))\n\n\nEpoch 1/5\n\n938/938 ━━━━━━━━━━━━━━━━━━━━ 62s 53ms/step - accuracy: 0.1045 - loss: 2.3221 - val_accuracy: 0.1135 - val_loss: 2.3011\n\nEpoch 2/5\n\n938/938 ━━━━━━━━━━━━━━━━━━━━ 63s 42ms/step - accuracy: 0.1117 - loss: 2.3013 - val_accuracy: 0.1135 - val_loss: 2.3011\n\nEpoch 3/5\n\n938/938 ━━━━━━━━━━━━━━━━━━━━ 41s 42ms/step - accuracy: 0.1110 - loss: 2.3015 - val_accuracy: 0.1135 - val_loss: 2.3011\n\nEpoch 4/5\n\n938/938 ━━━━━━━━━━━━━━━━━━━━ 41s 43ms/step - accuracy: 0.1111 - loss: 2.3017 - val_accuracy: 0.1135 - val_loss: 2.3010\n\nEpoch 5/5\n\n938/938 ━━━━━━━━━━━━━━━━━━━━ 42s 45ms/step - accuracy: 0.1114 - loss: 2.3014 - val_accuracy: 0.1135 - val_loss: 2.3010\n\n\n\n\n\n# Medimos la precisión del modelo 2 en el conjunto de prueba\ntest_loss, test_acc = model_2.evaluate(test_images, test_labels_ohc)\n\nprint(f\"Precisión en el conjunto de prueba: {test_acc}\")\n\n\n313/313 ━━━━━━━━━━━━━━━━━━━━ 3s 6ms/step - accuracy: 0.1160 - loss: 2.3009\n\nPrecisión en el conjunto de prueba: 0.11349999904632568\n\n\n\n\n\n# Imprimamos la estructura del modelo 2\nmodel_2.summary()\n\nModel: \"sequential\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ vgg16 (Functional)                   │ (None, 1, 1, 512)           │      14,714,688 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten (Flatten)                    │ (None, 512)                 │               0 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (Dropout)                    │ (None, 512)                 │               0 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (Dense)                        │ (None, 10)                  │           5,130 │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n\n\n\n Total params: 44,159,456 (168.45 MB)\n\n\n\n Trainable params: 14,719,818 (56.15 MB)\n\n\n\n Non-trainable params: 0 (0.00 B)\n\n\n\n Optimizer params: 29,439,638 (112.30 MB)\n\n\n\n\n\nObservaciones:\n\nAntes de hablar del mal rendimiento del modelo (un 9.7% de accuracy en el conjunto de prueba). Hay que hablar de que ahora demoró mas entrenandose. Esto se debe a que ahora, se ajustaron todos los parámeros posibles, no como en el modelo anterior que solo ajustamos los parámetros de la capa superior.\nUna de las razones por las cuales se obtuvo un accuracy muy bajo, es debido a que empezamos a ajustar el modelo pre-entrenado, pero pasamos de tener 512 neuronas como salida del modelo pre-entrenado, a solo tener 10. Entonces ese error se propagó y ajsuto erróneamente los pesos ya entrenados. Lo cual llevó a que el modelo no mejorara.\nPara mitigar este error, utilizaremos fine tunning ajustando mas la capa superior. Así podremos tener un mejor rendimiento de nuestro modelo de transfer learning\n\nFine tunning\n\nPara el ajuste fino, lo que haremos es lo siguiente:\n\nCongelaremos las primeras capas del modelo pre-entrenado\nAgregaremos unas capas superiores al modelo.\nEntrenaremos el modelo así.\nDespués, descongelaremos capas superiores del modelo pre-entrenado y hacemos ese ajuste fino (entrenamos) para aumentar el acierto del modelo.\n\n\n\n# Reiniciar el backend para que las ejecuciones anteriores no interfieran\nK.clear_session()\n\n\nvgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n\nfor layer in vgg16_base.layers[:15]:  # Congelar las primeras 15 capas\n    layer.trainable = False\n\n# Agregamos mas neuronas después de nuestro modelo pre-entrenado, para hacer un ajuste mas fino\nmodel_3 = models.Sequential([\n    vgg16_base,\n    layers.Flatten(),\n    layers.Dense(512, activation='relu'),  # Incrementamos el número de unidades para mayor capacidad de representación\n    layers.Dropout(0.5),                   # Aumentamos el Dropout para evitar el sobreajuste\n    layers.Dense(10, activation='softmax') # Capa final con 10 clases\n])\n\n\n# compilamos el modelo y definimos una parada temprana para mitigar el sobreajuste\nmodel_3.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\nearly_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\n\n# Entrenamos nuestro modelo\nhistory = model_3.fit(train_images, train_labels_ohc, batch_size=64,\n                      epochs=20,\n                      validation_data=(test_images, test_labels_ohc),\n                      callbacks=[early_stopping])\n\n\nEpoch 1/20\n\n938/938 ━━━━━━━━━━━━━━━━━━━━ 22s 20ms/step - accuracy: 0.9012 - loss: 0.3114 - val_accuracy: 0.9808 - val_loss: 0.0569\n\nEpoch 2/20\n\n938/938 ━━━━━━━━━━━━━━━━━━━━ 17s 18ms/step - accuracy: 0.9852 - loss: 0.0505 - val_accuracy: 0.9728 - val_loss: 0.0906\n\nEpoch 3/20\n\n938/938 ━━━━━━━━━━━━━━━━━━━━ 20s 18ms/step - accuracy: 0.9894 - loss: 0.0353 - val_accuracy: 0.9902 - val_loss: 0.0321\n\nEpoch 4/20\n\n938/938 ━━━━━━━━━━━━━━━━━━━━ 19s 17ms/step - accuracy: 0.9910 - loss: 0.0302 - val_accuracy: 0.9902 - val_loss: 0.0332\n\nEpoch 5/20\n\n938/938 ━━━━━━━━━━━━━━━━━━━━ 21s 17ms/step - accuracy: 0.9925 - loss: 0.0255 - val_accuracy: 0.9874 - val_loss: 0.0449\n\nEpoch 6/20\n\n938/938 ━━━━━━━━━━━━━━━━━━━━ 15s 16ms/step - accuracy: 0.9936 - loss: 0.0217 - val_accuracy: 0.9911 - val_loss: 0.0281\n\nEpoch 7/20\n\n938/938 ━━━━━━━━━━━━━━━━━━━━ 20s 16ms/step - accuracy: 0.9946 - loss: 0.0190 - val_accuracy: 0.9896 - val_loss: 0.0363\n\nEpoch 8/20\n\n938/938 ━━━━━━━━━━━━━━━━━━━━ 15s 16ms/step - accuracy: 0.9940 - loss: 0.0200 - val_accuracy: 0.9902 - val_loss: 0.0370\n\nEpoch 9/20\n\n938/938 ━━━━━━━━━━━━━━━━━━━━ 21s 17ms/step - accuracy: 0.9944 - loss: 0.0195 - val_accuracy: 0.9921 - val_loss: 0.0256\n\nEpoch 10/20\n\n938/938 ━━━━━━━━━━━━━━━━━━━━ 17s 18ms/step - accuracy: 0.9956 - loss: 0.0147 - val_accuracy: 0.9905 - val_loss: 0.0364\n\nEpoch 11/20\n\n938/938 ━━━━━━━━━━━━━━━━━━━━ 19s 16ms/step - accuracy: 0.9955 - loss: 0.0141 - val_accuracy: 0.9912 - val_loss: 0.0325\n\nEpoch 12/20\n\n938/938 ━━━━━━━━━━━━━━━━━━━━ 21s 16ms/step - accuracy: 0.9961 - loss: 0.0131 - val_accuracy: 0.9900 - val_loss: 0.0378\n\nEpoch 13/20\n\n938/938 ━━━━━━━━━━━━━━━━━━━━ 17s 18ms/step - accuracy: 0.9959 - loss: 0.0134 - val_accuracy: 0.9917 - val_loss: 0.0350\n\nEpoch 14/20\n\n938/938 ━━━━━━━━━━━━━━━━━━━━ 20s 18ms/step - accuracy: 0.9969 - loss: 0.0110 - val_accuracy: 0.9920 - val_loss: 0.0294\n\n\n\n\n\n# Evaluamos el accuracy del modelo en los datos de prueba\ntest_loss, test_acc = model_3.evaluate(test_images, test_labels_ohc)\nprint(f\"Precisión después del fine-tuning avanzado: {test_acc}\")\n\n\n313/313 ━━━━━━━━━━━━━━━━━━━━ 3s 7ms/step - accuracy: 0.9882 - loss: 0.0374\n\nPrecisión después del fine-tuning avanzado: 0.9921000003814697"
  },
  {
    "objectID": "semana_3/notebooks/Nb_3a_Introduccion_transfer_learning_finetuning.html#transfer-learning-y-fine-tuning-en-tareas-de-nlp",
    "href": "semana_3/notebooks/Nb_3a_Introduccion_transfer_learning_finetuning.html#transfer-learning-y-fine-tuning-en-tareas-de-nlp",
    "title": "Introducción a pre-trained models, transfer learning and fine tuning",
    "section": "Transfer learning y fine tuning en tareas de NLP",
    "text": "Transfer learning y fine tuning en tareas de NLP\n\n#@title Descargar vectores embebidos en inglés y español\n\n# Descargar los vectores FastText de inglés y español\n!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz\n!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.es.300.vec.gz\n\n# Descomprimir los archivos\n!gunzip cc.en.300.vec.gz\n!gunzip cc.es.300.vec.gz\n\n--2024-10-18 13:11:42--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz\nResolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.163.189.96, 3.163.189.108, 3.163.189.51, ...\nConnecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.163.189.96|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1325960915 (1.2G) [binary/octet-stream]\nSaving to: ‘cc.en.300.vec.gz’\n\ncc.en.300.vec.gz    100%[===================&gt;]   1.23G  85.8MB/s    in 8.9s    \n\n2024-10-18 13:11:51 (142 MB/s) - ‘cc.en.300.vec.gz’ saved [1325960915/1325960915]\n\n--2024-10-18 13:11:51--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.es.300.vec.gz\nResolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.163.189.96, 3.163.189.108, 3.163.189.51, ...\nConnecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.163.189.96|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1285580896 (1.2G) [binary/octet-stream]\nSaving to: ‘cc.es.300.vec.gz’\n\ncc.es.300.vec.gz    100%[===================&gt;]   1.20G  28.5MB/s    in 45s     \n\n2024-10-18 13:12:36 (27.3 MB/s) - ‘cc.es.300.vec.gz’ saved [1285580896/1285580896]\n\n\n\n\n# Cargar los embeddings preentrenados de FastText (esto puede tardar un poco)\nembedding_en = KeyedVectors.load_word2vec_format('cc.en.300.vec', binary=False)\n\n# Probar cargando una palabra\nprint(embedding_en['hello'])\n\n[ 1.576e-01  4.380e-02 -4.500e-03  6.660e-02  7.700e-02  4.900e-03\n  8.200e-03  6.500e-03  9.300e-03  3.540e-02 -2.310e-02 -4.920e-02\n -8.330e-02  1.560e-02  2.549e-01  3.450e-02 -1.070e-02 -7.800e-02\n -7.080e-02  7.620e-02 -6.100e-02  4.490e-02 -7.300e-02  1.310e-02\n  3.150e-02 -3.100e-02  1.660e-02  1.740e-02 -7.360e-02  1.182e-01\n -1.213e-01 -4.090e-02  2.940e-02  4.840e-02 -1.340e-02 -1.750e-02\n  7.510e-02  9.970e-02 -4.000e-02  4.100e-03 -7.220e-02 -4.430e-02\n -1.200e-03  7.570e-02  3.980e-02  3.230e-02  1.960e-02  4.680e-02\n -1.460e-02  1.130e-01  3.150e-02 -1.023e-01  1.581e-01 -2.760e-02\n -3.400e-02 -1.770e-02 -6.000e-04  1.108e-01 -1.650e-02 -3.100e-03\n -4.230e-02  1.114e-01 -5.310e-02  4.910e-02  9.100e-02  6.570e-02\n -3.710e-02  3.820e-02  7.250e-02 -5.320e-02  3.060e-02 -5.770e-02\n -8.070e-02 -9.060e-02 -8.050e-02 -6.030e-02 -9.730e-02  4.830e-02\n  6.800e-02 -2.600e-03 -8.600e-03 -5.100e-03  3.160e-02  6.670e-02\n  3.000e-04 -8.350e-02  4.450e-02  3.600e-02 -2.070e-02 -6.210e-02\n -9.080e-02 -4.880e-02  1.328e-01  1.260e-02  4.610e-02 -5.540e-02\n  2.300e-03  4.920e-02  3.360e-02  6.640e-02 -8.930e-02 -5.370e-02\n  1.322e-01 -9.100e-03  3.300e-03 -4.370e-02  7.520e-02 -4.370e-02\n -3.930e-02  4.900e-02  8.060e-02 -3.940e-02 -7.600e-02  7.170e-02\n -1.890e-02 -4.210e-02  3.300e-03 -2.140e-02 -1.301e-01  1.370e-02\n -5.150e-02  3.870e-02  4.930e-02 -6.180e-02 -3.400e-02  3.520e-02\n  2.590e-02 -1.028e-01  6.010e-02 -7.140e-02 -2.240e-02 -1.034e-01\n -6.350e-02  1.200e-03 -8.400e-03 -7.100e-02 -1.390e-02  9.300e-02\n -7.620e-02 -1.800e-01  4.980e-02  5.600e-02  4.370e-02  1.690e-02\n -3.520e-02  5.500e-03 -1.517e-01  8.300e-03  1.339e-01  1.184e-01\n -2.550e-02 -5.900e-02 -1.155e-01 -9.120e-02 -3.260e-02  9.600e-03\n  7.080e-02 -1.196e-01 -2.450e-02  4.670e-02 -1.058e-01  8.400e-03\n -3.590e-02 -7.120e-02  1.491e-01 -9.410e-02  3.880e-02  4.800e-02\n  2.000e-02  5.700e-02 -5.090e-02 -1.550e-02 -3.210e-02  6.400e-02\n  4.460e-02 -5.420e-02  2.390e-02  3.990e-02  4.950e-02 -8.130e-02\n  8.680e-02  2.790e-02  2.230e-02  6.880e-02  5.800e-02  1.240e-02\n  9.180e-02  1.700e-02 -2.210e-02 -5.550e-02  3.200e-03 -8.950e-02\n -6.000e-04 -4.810e-02 -4.110e-02 -3.470e-02 -4.230e-02  1.011e-01\n  4.350e-02  6.750e-02 -7.330e-02  2.330e-02  3.770e-02  9.000e-03\n -8.250e-02 -9.680e-02  5.900e-03  2.620e-02 -2.230e-02  7.390e-02\n -1.900e-03 -9.780e-02 -5.380e-02 -4.770e-02 -1.300e-02  8.000e-04\n  2.900e-02 -3.100e-03 -9.290e-02  6.740e-02 -1.855e-01  4.010e-02\n -5.630e-02  6.190e-02  8.940e-02 -6.910e-02 -3.220e-02 -1.354e-01\n -7.460e-02  1.015e-01 -2.700e-03  6.070e-02  2.430e-02 -1.519e-01\n -2.940e-02 -4.200e-03  5.160e-02  1.860e-01 -2.560e-02  8.120e-02\n  3.200e-03 -3.360e-02  3.900e-02 -7.380e-02  1.146e-01 -1.000e-04\n -3.690e-02  9.310e-02 -2.930e-02  5.210e-02  8.000e-03 -2.930e-02\n  1.312e-01 -8.320e-02 -3.400e-02  1.213e-01  3.510e-02  4.200e-03\n  5.030e-02  2.060e-02  7.900e-02 -4.950e-02  2.540e-02 -2.960e-02\n -2.650e-02  5.430e-02 -5.530e-02  1.070e-02 -3.000e-02 -6.050e-02\n  8.540e-02 -6.660e-02 -6.780e-02  3.520e-02  6.200e-02  4.810e-02\n -3.450e-02 -2.870e-02 -5.910e-02 -5.100e-03 -9.740e-02  1.900e-03\n -9.060e-02  1.480e-02 -9.780e-02  3.960e-02  2.830e-02 -9.280e-02\n -8.200e-03 -4.570e-02  1.123e-01  8.600e-02 -1.475e-01  8.330e-02\n  9.950e-02 -3.670e-02  6.850e-02  8.070e-02 -4.500e-02 -3.110e-02]\n\n\n\nMismo ejercicio Clasificación de texto usando RNN\n\ndataset, info = tfds.load('imdb_reviews', with_info=True,\n                          as_supervised=True)\ntrain_dataset, test_dataset = dataset['train'], dataset['test']\n\nDownloading and preparing dataset 80.23 MiB (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0...\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDataset imdb_reviews downloaded and prepared to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.\n\n\n\nBUFFER_SIZE = 10000\nBATCH_SIZE = 32\n\n# optimización para train\ntrain_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n\n# optimización para test\ntest_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n\n\nVOCAB_SIZE = 1000\nencoder = tf.keras.layers.TextVectorization(\n    max_tokens=VOCAB_SIZE)\n\n# Crea la capa y pasa el texto del conjunto de datos al método .adapt de la capa\nencoder.adapt(train_dataset.map(lambda text, label: text))\n\n\n# Obtener el vocabulario del encoder\nvocab = encoder.get_vocabulary()\n\nprint(vocab[:10])\n\n# Dimensiones de los embeddings preentrenados\nembedding_dim = 300  # Dimensión de los embeddings de FastText\n\n# Crear una matriz de embeddings aleatoria (en caso de que alguna palabra no esté en FastText)\nembedding_matrix = np.random.uniform(-0.25, 0.25, (len(vocab), embedding_dim))\n\n# Llenar la matriz con los vectores de FastText para las palabras del vocabulario\nfor i, word in enumerate(vocab):\n    if word in embedding_en:\n        embedding_matrix[i] = embedding_en[word]\n    else:\n        # Dejar la fila con los valores aleatorios (o también puedes poner ceros)\n        embedding_matrix[i] = np.random.uniform(-0.25, 0.25, embedding_dim)\n\n['', '[UNK]', 'the', 'and', 'a', 'of', 'to', 'is', 'in', 'it']\n\n\n\nembedding_matrix.shape\n\n(1000, 300)\n\n\n\ndef rnn(pretrained_vector_matrix):\n    # Ahora utilizamos la API funcional de Keras\n    inputs = tf.keras.layers.Input(shape=(1,), dtype=tf.string)  # El input será una cadena de texto\n    x = encoder(inputs)  # Aplicamos el encoder\n\n    x = tf.keras.layers.Embedding(\n        input_dim=len(encoder.get_vocabulary()),  # Tamaño del vocabulario\n        output_dim=pretrained_vector_matrix.shape[1],  # Dimensión de los embeddings (300)\n        embeddings_initializer=tf.keras.initializers.Constant(pretrained_vector_matrix),\n        trainable=True,  # Congelar los embeddings\n        mask_zero=True)(x)  # Capa de Embedding\n\n    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=False), merge_mode='concat')(x)  # Capa LSTM Bidireccional\n\n    x = tf.keras.layers.Dense(64, activation='relu')(x)  # Capa densa\n    outputs = tf.keras.layers.Dense(1)(x)  # Capa de salida\n\n    # Definimos el modelo\n    model = tf.keras.Model(inputs, outputs)\n\n    return model\n\n# crear la red RNN\nmodel = rnn(embedding_matrix)\n\n# Compilamos el modelo\nmodel.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              optimizer=tf.keras.optimizers.Adam(1e-4),\n              metrics=['accuracy'])\n\n# Verificamos la estructura del modelo\nmodel.summary()\n\nModel: \"functional_1\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃ Layer (type)              ┃ Output Shape           ┃        Param # ┃ Connected to           ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_1             │ (None, 1)              │              0 │ -                      │\n│ (InputLayer)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ text_vectorization        │ (None, None)           │              0 │ input_layer_1[0][0]    │\n│ (TextVectorization)       │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_1 (Embedding)   │ (None, None, 300)      │        300,000 │ text_vectorization[1]… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ not_equal_1 (NotEqual)    │ (None, None)           │              0 │ text_vectorization[1]… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ bidirectional_1           │ (None, 128)            │        186,880 │ embedding_1[0][0],     │\n│ (Bidirectional)           │                        │                │ not_equal_1[0][0]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_2 (Dense)           │ (None, 64)             │          8,256 │ bidirectional_1[0][0]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_3 (Dense)           │ (None, 1)              │             65 │ dense_2[0][0]          │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n\n\n\n Total params: 495,201 (1.89 MB)\n\n\n\n Trainable params: 495,201 (1.89 MB)\n\n\n\n Non-trainable params: 0 (0.00 B)\n\n\n\n\n# hacer una prueba sin usar padding\n# El texto crudo que quieres predecir\nsample_text = ('The movie was cool. The animation and the graphics were out of this world.')\n\n# No es necesario hacer la vectorización manual aquí, simplemente pasa el texto crudo al modelo\npredictions = model.predict(tf.constant([sample_text]))\n\n# Imprime la predicción\nprint(predictions[0])\n\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 379ms/step\n\n[-0.06903996]\n\n\n\n\n\nhistory = model.fit(train_dataset, epochs=10,\n                    validation_data=test_dataset,\n                    validation_steps=30)\n\n\nEpoch 1/10\n\n782/782 ━━━━━━━━━━━━━━━━━━━━ 43s 52ms/step - accuracy: 0.5433 - loss: 0.6593 - val_accuracy: 0.8250 - val_loss: 0.4475\n\nEpoch 2/10\n\n782/782 ━━━━━━━━━━━━━━━━━━━━ 42s 54ms/step - accuracy: 0.8240 - loss: 0.3888 - val_accuracy: 0.8573 - val_loss: 0.3350\n\nEpoch 3/10\n\n782/782 ━━━━━━━━━━━━━━━━━━━━ 80s 52ms/step - accuracy: 0.8420 - loss: 0.3497 - val_accuracy: 0.8635 - val_loss: 0.3453\n\nEpoch 4/10\n\n782/782 ━━━━━━━━━━━━━━━━━━━━ 40s 50ms/step - accuracy: 0.8608 - loss: 0.3217 - val_accuracy: 0.8365 - val_loss: 0.3172\n\nEpoch 5/10\n\n782/782 ━━━━━━━━━━━━━━━━━━━━ 39s 50ms/step - accuracy: 0.8639 - loss: 0.3106 - val_accuracy: 0.8656 - val_loss: 0.3094\n\nEpoch 6/10\n\n782/782 ━━━━━━━━━━━━━━━━━━━━ 40s 50ms/step - accuracy: 0.8689 - loss: 0.2969 - val_accuracy: 0.8844 - val_loss: 0.2817\n\nEpoch 7/10\n\n782/782 ━━━━━━━━━━━━━━━━━━━━ 39s 50ms/step - accuracy: 0.8743 - loss: 0.2935 - val_accuracy: 0.8615 - val_loss: 0.3293\n\nEpoch 8/10\n\n782/782 ━━━━━━━━━━━━━━━━━━━━ 41s 50ms/step - accuracy: 0.8788 - loss: 0.2812 - val_accuracy: 0.8427 - val_loss: 0.3435\n\nEpoch 9/10\n\n782/782 ━━━━━━━━━━━━━━━━━━━━ 39s 50ms/step - accuracy: 0.8821 - loss: 0.2770 - val_accuracy: 0.8396 - val_loss: 0.3193\n\nEpoch 10/10\n\n782/782 ━━━━━━━━━━━━━━━━━━━━ 42s 51ms/step - accuracy: 0.8780 - loss: 0.2756 - val_accuracy: 0.8656 - val_loss: 0.3164\n\n\n\n\n\ntest_loss, test_acc = model.evaluate(test_dataset)\n\nprint('Test Loss:', test_loss)\nprint('Test Accuracy:', test_acc)\n\n\n782/782 ━━━━━━━━━━━━━━━━━━━━ 19s 24ms/step - accuracy: 0.8578 - loss: 0.3114\n\nTest Loss: 0.311646044254303\n\nTest Accuracy: 0.8579199910163879\n\n\n\n\n\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplot_graphs(history, 'accuracy')\nplt.ylim(None, 1)\nplt.subplot(1, 2, 2)\nplot_graphs(history, 'loss')\nplt.ylim(0, None)"
  },
  {
    "objectID": "semana_3/notebooks/Nb_3a_Introduccion_transfer_learning_finetuning.html#conclusiones",
    "href": "semana_3/notebooks/Nb_3a_Introduccion_transfer_learning_finetuning.html#conclusiones",
    "title": "Introducción a pre-trained models, transfer learning and fine tuning",
    "section": "Conclusiones",
    "text": "Conclusiones\n\nNote que al agregarle al modelo mas capas superiores, logramos mitigar el problema que presentamos en nuestro modelo 2, logrando un accuracy del 99.30% en nuestro datos de prueba.\nComo conlusión, cuando hagamos uso de modelo pre-entrenados. Tenemos que hacer uso de todas las herramientas que disponemos, como lo son el transfer learning y el fine tunning, una caracteristica muy importante que siempre hay que aplicar.\nEn el modelo de NLP se logró una ligera mejora, sin embargo es necesario hacer más cambios en los parámetros para llegar a mejores resultados."
  }
]