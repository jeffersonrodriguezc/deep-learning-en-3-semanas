{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffersonrodriguezc/deep-learning-en-3-semanas/blob/main/semana_2/notebooks/Nb_2c_Traduccion_usando_transformers_keras_sindetalles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a934948f7030"
      },
      "source": [
        "# Explicando la Mejora de los Transformers sobre las RNNs\n",
        "> Última actualización 20/02/2026\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jeffersonrodriguezc/deep-learning-en-3-semanas/blob/main/semana_2/notebooks/Nb_2c_Traduccion_usando_transformers_keras_sindetalles.ipynb)"
      ],
      "metadata": {
        "id": "CeeIrQPf-6PP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Importar librerías\n",
        "#importar librerías necesarias\n",
        "import os\n",
        "import logging\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_text\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "cIwMRCTY_0A2",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Funciones complementarias\n",
        "def plot_similaridad_positional_encodings(pos_encoding):\n",
        "  # normalización de los vectores a 1\n",
        "  pos_encoding/=tf.norm(pos_encoding, axis=1, keepdims=True)\n",
        "  # seleccionamos el vector de la posición 1000\n",
        "  p = pos_encoding[1000]\n",
        "  # cálculo de la similitud del producto punto\n",
        "  dots = tf.einsum('pd,d -> p', pos_encoding, p)\n",
        "\n",
        "  # visualización de la relación de los vectores con sus palabras\n",
        "  # vecinas, por definición tendran mucha similaridad.\n",
        "  plt.subplot(2,1,1)\n",
        "  plt.plot(dots)\n",
        "  plt.ylim([0,1])\n",
        "  plt.plot([950, 950, float('nan'), 1050, 1050],\n",
        "          [0,1,float('nan'),0,1], color='k', label='Zoom')\n",
        "  plt.legend()\n",
        "  plt.subplot(2,1,2)\n",
        "  plt.plot(dots)\n",
        "  plt.xlim([950, 1050])\n",
        "  plt.ylim([0,1])\n",
        "\n",
        "def plot_distribucion_longitudes_tokens(all_lengths):\n",
        "  plt.hist(all_lengths, np.linspace(0, 500, 101))\n",
        "  plt.ylim(plt.ylim())\n",
        "  max_length = max(all_lengths)\n",
        "  plt.plot([max_length, max_length], plt.ylim())\n",
        "  plt.title(f'Número máximo de tokens por muestra: {max_length}');\n",
        "\n",
        "def plot_positional_encodings(pos_encoding):\n",
        "  # Gráficar las dimensiones\n",
        "  plt.pcolormesh(pos_encoding.numpy().T, cmap='RdBu')\n",
        "  plt.ylabel('Profundidad')\n",
        "  plt.xlabel('Posición')\n",
        "  plt.colorbar()\n",
        "  plt.show()\n",
        "\n",
        "def plot_lr_planificador(learning_rate):\n",
        "  plt.plot(learning_rate(tf.range(40000, dtype=tf.float32)))\n",
        "  plt.ylabel('Learning Rate');\n",
        "  plt.xlabel('Paso de entrenamiento');\n",
        "\n",
        "def plot_attention_head(in_tokens, translated_tokens, attention):\n",
        "  # Saltar el token start.\n",
        "  translated_tokens = translated_tokens[1:]\n",
        "\n",
        "  ax = plt.gca()\n",
        "  ax.matshow(attention)\n",
        "  ax.set_xticks(range(len(in_tokens)))\n",
        "  ax.set_yticks(range(len(translated_tokens)))\n",
        "\n",
        "  labels = [label.decode('utf-8') for label in in_tokens.numpy()]\n",
        "  ax.set_xticklabels(\n",
        "      labels, rotation=90)\n",
        "\n",
        "  labels = [label.decode('utf-8') for label in translated_tokens.numpy()]\n",
        "  ax.set_yticklabels(labels)\n",
        "\n",
        "def plot_attention_weights(sentence, translated_tokens, attention_heads):\n",
        "  in_tokens = tf.convert_to_tensor([sentence])\n",
        "  in_tokens = tokenizers.pt.tokenize(in_tokens).to_tensor()\n",
        "  in_tokens = tokenizers.pt.lookup(in_tokens)[0]\n",
        "\n",
        "  fig = plt.figure(figsize=(12, 15))\n",
        "\n",
        "  for h, head in enumerate(attention_heads):\n",
        "    ax = fig.add_subplot(2, 4, h+1)\n",
        "\n",
        "    plot_attention_head(in_tokens, translated_tokens, head)\n",
        "\n",
        "    ax.set_xlabel(f'Head {h+1}')\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "def plot_traduccion(sentence, tokens, ground_truth):\n",
        "  print(f'{\"Input:\":15s}: {sentence}')\n",
        "  print(f'{\"Predicción\":15s}: {tokens.numpy().decode(\"utf-8\")}')\n",
        "  print(f'{\"Ground truth\":15s}: {ground_truth}')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "FFVjo9Gm2gJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Los Transformers: Una Nueva Era en el Procesamiento de Secuencias**\n",
        "\n",
        "Las Redes Neuronales Recurrentes (RNNs) han sido una herramienta fundamental para el procesamiento de datos secuenciales, como el lenguaje natural. Sin embargo, los Transformers, propuestos en el artículo [\"Attention is all you need\"](https://arxiv.org/abs/1706.03762), han revolucionado este campo, ofreciendo ventajas significativas sobre las RNNs. **Los Transformers son redes neuronales profundas que reemplazan las CNNs y las RNNs. Estos introducen la auto-atención (self-attention) permite a los Transformers transmitir información fácilmente a través de las secuencias de entrada.**\n",
        "\n",
        "**¿Por qué los Transformers son importantes?**\n",
        "\n",
        "* **Paralelización:** A diferencia de las RNNs, los Transformers pueden procesar todos los elementos de una secuencia en paralelo, lo que permite un entrenamiento mucho más rápido en hardware moderno como GPUs y TPUs.\n",
        "* **Captura de dependencias temporales de larga duración:** Los Transformers utilizan mecanismos de atención que permiten a cada posición de la secuencia prestar atención a todas las demás posiciones, facilitando el aprendizaje de relaciones entre elementos distantes. Las RNNs tienen dificultades para esto debido a la necesidad de procesar la secuencia paso a paso.\n",
        "* **Flexibilidad:** Los Transformers no hacen suposiciones sobre las relaciones temporales o espaciales en los datos, lo que los hace aplicables a una variedad de tareas más allá del lenguaje, como el procesamiento de imágenes o el análisis de juegos.\n",
        "\n",
        "En este notebook, exploraremos en profundidad los componentes clave de los Transformers y compararemos su funcionamiento con el de las RNNs, destacando las razones de su superioridad."
      ],
      "metadata": {
        "id": "eETmXXBB2G6u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparativa RNNs vs Transformers\n",
        "\n",
        "<table>\n",
        "<tr>\n",
        "  <th><a href=https://www.tensorflow.org/text/tutorials/nmt_with_attention>RNN+Modelo de Atención</a></th>\n",
        "  <th>Transformer de 1 capa</th>\n",
        "</tr>\n",
        "<tr>\n",
        "  <td>\n",
        "   <img width=411 src=\"https://www.tensorflow.org/images/tutorials/transformer/RNN+attention-words.png\"/>\n",
        "  </td>\n",
        "  <td>\n",
        "   <img width=400 src=\"https://www.tensorflow.org/images/tutorials/transformer/Transformer-1layer-words.png\"/>\n",
        "  </td>\n",
        "</tr>\n",
        "</table>"
      ],
      "metadata": {
        "id": "TCJRgom08EZF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Esquema de trabajo\n",
        "\n",
        "Con lo anterior en mente, y una vez visto un poco las diferencias entre RNNs y Transformers, vamos a abordar los siguientes contenidos de manera detallada:\n",
        "\n",
        "1.  Prepararás los datos.\n",
        "2.  Implementarás los componentes necesarios:\n",
        "    * Embeddings posicionales.\n",
        "    * Capas de atención.\n",
        "    * El codificador y el decodificador.\n",
        "3.  Construirás y entrenarás el Transformer.\n",
        "4.  Generarás traducciones.\n",
        "5.  Exportarás el modelo."
      ],
      "metadata": {
        "id": "WualjbvYJXwu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carga y Preprocesamiento de Datos\n",
        "\n",
        "Cargaremos un conjunto de datos de traducción Portugués-Inglés y utilizaremos un tokenizador para preparar el texto para el modelo. Este conjunto de datos contiene aproximadamente 52.000 ejemplos de entrenamiento, 1.200 de validación y 1.800 de prueba.\n"
      ],
      "metadata": {
        "id": "kbK5FBuf94MX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Cargamos el dataset\n",
        "dataset_name = 'tatoeba/tatoeba_pt'\n",
        "dataset, info = tfds.load(dataset_name, with_info=True)\n",
        "\n",
        "# 2. Función de mapeo para obtener la tupla (pt, en)\n",
        "# Usamos las llaves definidas en tu Builder: source_sentence y target_sentence\n",
        "def map_to_tuple(example):\n",
        "    return example['source_sentence'], example['target_sentence']\n",
        "\n",
        "# 3. Aplicamos el mapeo a todo el conjunto disponible\n",
        "all_examples = dataset['train'].map(map_to_tuple)\n",
        "\n",
        "# 4. División manual: 90% entrenamiento, 10% validación\n",
        "num_examples = info.splits['train'].num_examples\n",
        "train_size = int(0.9 * num_examples)\n",
        "\n",
        "train_examples = all_examples.take(train_size)\n",
        "val_examples = all_examples.skip(train_size)\n",
        "\n",
        "# 5. Verificación de los resultados\n",
        "print(f\"Total de ejemplos en Tatoeba: {num_examples}\")\n",
        "print(f\"Ejemplos asignados a train_examples: {train_size}\")\n",
        "print(f\"Ejemplos asignados a val_examples: {num_examples - train_size}\")"
      ],
      "metadata": {
        "id": "xxlVW7hbB737"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar algunos ejemplos de parejas de oraciones\n",
        "for pt_examples, en_examples in train_examples.batch(3).take(1):\n",
        "  print('-> Ejemplos en portugués:')\n",
        "  for pt in pt_examples.numpy():\n",
        "    print(pt.decode('utf-8'))\n",
        "  print()\n",
        "\n",
        "  print('-> Traducción al inglés:')\n",
        "  for en in en_examples.numpy():\n",
        "    print(en.decode('utf-8'))"
      ],
      "metadata": {
        "id": "ZaI_YeZ0Di-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tokenizadores\n",
        "\n",
        "En nuestro ejemplo vamos a usar los tokenizadores construidos en el tutorial [subword tokenizer](https://www.tensorflow.org/text/guide/subwords_tokenizer). Ese tutorial optimiza dos objetos `text.BertTokenizer` (uno para inglés, otro para portugués) para **este conjunto de datos** y los exporta en formato `saved_model` de TensorFlow."
      ],
      "metadata": {
        "id": "25QbzCva94PJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'ted_hrlr_translate_pt_en_converter'\n",
        "tf.keras.utils.get_file(\n",
        "    f'{model_name}.zip',\n",
        "    f'https://storage.googleapis.com/download.tensorflow.org/models/{model_name}.zip',\n",
        "    cache_dir='.', cache_subdir='', extract=True\n",
        ")"
      ],
      "metadata": {
        "id": "j88qLI23x0ye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cargar los tokenizadores\n",
        "tokenizers = tf.saved_model.load(f'{model_name}_extracted/{model_name}')"
      ],
      "metadata": {
        "id": "FgQ-tfwOyVN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ambos tokenizadores tienen los mismo métodos\n",
        "[item for item in dir(tokenizers.en) if not item.startswith('_')]"
      ],
      "metadata": {
        "id": "VANitacnyW-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# por ejemplo revisemos los vocab\n",
        "tokenizers.en.vocab.shape, tokenizers.pt.vocab.shape"
      ],
      "metadata": {
        "id": "FJZnE68ygWgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El método `tokenize` convierte un grupo de oraciones en un grupo de identificadores de tokens de una misma longitud (padding). Este método separa los signos de puntuación, las minúsculas y normaliza el texto de entrada antes de la tokenización. Esta normalización no es visible aquí porque los datos de entrada ya están normalizados."
      ],
      "metadata": {
        "id": "3COsDlP-yO6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('-> Esto es un grupo de cadenas:')\n",
        "for en in en_examples.numpy():\n",
        "  print(en.decode('utf-8'))"
      ],
      "metadata": {
        "id": "baED8YNLyRst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded = tokenizers.en.tokenize(en_examples)\n",
        "\n",
        "print('-> Este es el grupo de cedena de ID de tokens (sin padding)')\n",
        "for row in encoded.to_list():\n",
        "  print(row)"
      ],
      "metadata": {
        "id": "PfAT229E3P6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El método `detokenize` convierte los ID de token de nuevo en texto legible normal:"
      ],
      "metadata": {
        "id": "IlDMzvtW94SK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "round_trip = tokenizers.en.detokenize(encoded)\n",
        "\n",
        "print('-> Correspondiente texto:')\n",
        "for line in round_trip.numpy():\n",
        "  print(line.decode('utf-8'))"
      ],
      "metadata": {
        "id": "NOhbgM76GN-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El método `lookup` convierte de token-IDs a token-texto:"
      ],
      "metadata": {
        "id": "nLDNbodN94Vr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('-> Este es el texto dividido en tokens:')\n",
        "tokens = tokenizers.en.lookup(encoded)\n",
        "tokens"
      ],
      "metadata": {
        "id": "tygERCI8GuDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ten en cuenta que el texto tokenizado incluye los tokens `'[START]'` y `'[END]'`."
      ],
      "metadata": {
        "id": "3Oyv1zAuHSb6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Yb35sTJcZq9"
      },
      "source": [
        "#### Configuración del pipeline de datos usando `tf.data`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZHsns5obJhN"
      },
      "source": [
        "La siguiente función toma batches de texto como entrada y los convierte a un formato adecuado para el entrenamiento.\n",
        "\n",
        "1.  Los tokeniza en lotes de diferentes dimensiones (ragged).\n",
        "2.  Recorta cada uno para que no tenga más de `MAX_TOKENS`.\n",
        "3.  Divide los tokens objetivo (inglés) en entradas y etiquetas. Estos se desplazan un paso de modo que en cada ubicación de entrada, la `etiqueta` es el ID del siguiente token.\n",
        "4.  Convierte los `RaggedTensor` en `Tensor` densos con padding.\n",
        "5.  Devuelve un par `(entradas, etiquetas)`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6shgzEck3FiV"
      },
      "outputs": [],
      "source": [
        "MAX_TOKENS=64\n",
        "def prepare_batch(pt, en):\n",
        "    pt = tokenizers.pt.tokenize(pt) # la sálida tiene diferentes longitudes\n",
        "    pt = pt[:, :MAX_TOKENS]    # Truncar al max # de tokens\n",
        "    pt = pt.to_tensor()  # Convertir a un tensor denso con padding\n",
        "\n",
        "    en = tokenizers.en.tokenize(en)\n",
        "    en = en[:, :(MAX_TOKENS+1)] # para poder hacer el shift\n",
        "    en_inputs = en[:, :-1].to_tensor()  # Elimina los tokens [END]\n",
        "    en_labels = en[:, 1:].to_tensor()   # Eliminar los tokens [START]\n",
        "\n",
        "    return (pt, en_inputs), en_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAroQ6xelzdx"
      },
      "source": [
        "La siguiente función convierte un conjunto de datos de ejemplos de texto en datos de lotes para el entrenamiento.\n",
        "\n",
        "1.  Tokeniza el texto y filtra las secuencias que son demasiado largas.\n",
        "2.  El método `cache` asegura que ese trabajo solo se ejecute una vez.\n",
        "3.  Luego, `shuffle` y preparar el batch.\n",
        "4.  Finalmente, `prefetch` ejecuta el conjunto de datos en paralelo con el modelo para asegurar que los datos estén disponibles cuando se necesiten. Consulta [Mejorar rendimiento con `tf.data`](https://www.tensorflow.org/guide/data_performance.ipynb) para más detalles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcRp7VcQ5m6g"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = 10000\n",
        "BATCH_SIZE = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUN_jLBTwNxk"
      },
      "outputs": [],
      "source": [
        "def make_batches(ds):\n",
        "  return (\n",
        "      ds\n",
        "      .shuffle(BUFFER_SIZE)\n",
        "      .batch(BATCH_SIZE)\n",
        "      .map(prepare_batch, tf.data.AUTOTUNE)\n",
        "      .prefetch(buffer_size=tf.data.AUTOTUNE))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itSWqk-ivrRg"
      },
      "source": [
        "#### Probar nuestro pipeline de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSswr5TKvoNM"
      },
      "outputs": [],
      "source": [
        "# Crear los conjuntos de entrenamiento y validación\n",
        "train_batches = make_batches(train_examples)\n",
        "val_batches = make_batches(val_examples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSufllC7wooA"
      },
      "source": [
        "Como se verían las entradas y sálidas en nuestro pipeline de datos?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJdJttsF751"
      },
      "source": [
        "<table>\n",
        "<tr>\n",
        "  <th>Inputs en la parte inferior, labels en la parte superior.</th>\n",
        "</tr>\n",
        "<tr>\n",
        "  <td>\n",
        "   <img width=400 src=\"https://www.tensorflow.org/images/tutorials/transformer/Transformer-1layer-words.png\"/>\n",
        "  </td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsF751JJdJt"
      },
      "source": [
        "Esta configuración se llama \"**teacher forcing**\" porque, independientemente de la salida del modelo en cada paso de tiempo, recibe el valor verdadero como entrada para el siguiente paso de tiempo. Esta es una forma simple y eficiente de entrenar un modelo de generación de texto. Es eficiente porque no necesitas ejecutar el modelo secuencialmente; las salidas en las diferentes ubicaciones de la secuencia se pueden calcular en paralelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAw2XjRwLFWr"
      },
      "outputs": [],
      "source": [
        "# visualizar un ejemplo de nuestros datos para entrenar\n",
        "for (pt, en), en_labels in train_batches.take(1):\n",
        "  break\n",
        "\n",
        "print(pt.shape)\n",
        "print(en.shape)\n",
        "print(en_labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tzo3JKaqx46g"
      },
      "source": [
        "Las etiquetas `en` y `en_labels` son las mismas, sólo que desplazadas en 1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apFeC-WWxzR4"
      },
      "outputs": [],
      "source": [
        "print(en[0][:10])\n",
        "print(en_labels[0][:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e7hKcxn6-zd"
      },
      "source": [
        "### Definir los componentes del Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVE5j6JlcAps"
      },
      "source": [
        "Dentro de un Transformer pasan muchas cosas. Las cosas importantes que hay que recordar son:\n",
        "\n",
        "*   Sigue el mismo patrón general que un modelo estándar secuencia-a-secuencia con un codificador y un decodificador.\n",
        "*   Si trabajas paso a paso, todo tendrá sentido."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0R4bYJ0DiFR"
      },
      "source": [
        "<table>\n",
        "<tr>\n",
        "  <th colspan=1>Diagrama original del Transformer</th>\n",
        "  <th colspan=1>Representación de un Transformer de 4 capas</th>\n",
        "</tr>\n",
        "<tr>\n",
        "  <td>\n",
        "   <img width=400 src=\"https://www.tensorflow.org/images/tutorials/transformer/transformer.png\"/>\n",
        "  </td>\n",
        "  <td>\n",
        "   <img width=307 src=\"https://www.tensorflow.org/images/tutorials/transformer/Transformer-4layer-compact.png\"/>\n",
        "  </td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YS75Y-9-lkzn"
      },
      "source": [
        "#### La capa para la codificación de la posición"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26l90xiq3Nis"
      },
      "source": [
        "Las entradas tanto del codificador como del descodificador utilizan la misma lógica de incrustación y codificación posicional\n",
        "\n",
        "<table>\n",
        "<tr>\n",
        "  <th colspan=1>The embedding and positional encoding layer</th>\n",
        "<tr>\n",
        "<tr>\n",
        "  <td>\n",
        "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/PositionalEmbedding.png\"/>\n",
        "  </td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "279u2DiDlmdS"
      },
      "source": [
        "Dada una secuencia de tokens, tanto los tokens de entrada (portugués) como los tokens objetivo (inglés) deben convertirse en vectores utilizando una capa `tf.keras.layers.Embedding`.\n",
        "\n",
        "Las capas de atención utilizadas en todo el modelo ven su entrada como un conjunto de vectores, sin ningún orden. Dado que el modelo no contiene ninguna capa recurrente o convolucional, necesita alguna forma de identificar el orden de las palabras; de lo contrario, vería la secuencia de entrada como una instancia de [bolsa de palabras](https://developers.google.com/machine-learning/glossary#bag-of-words), `cómo estás`, `cómo tú estás`, `tú cómo estás`, y así sucesivamente, son indistinguibles.\n",
        "\n",
        "Por lo tanto, el Transformer agrega una \"Codificación Posicional\" a los vectores de embedding. Utiliza un conjunto de senos y cosenos en diferentes frecuencias (a lo largo de la secuencia). Por definición, los elementos cercanos tendrán codificaciones posicionales similares."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gcCNZP7lzdy"
      },
      "source": [
        "El paper original usa la siguiente formúla para la codificación posicional:\n",
        "\n",
        "$$\\Large{PE_{(pos, 2i)} = \\sin(pos / 10000^{2i / d_{model}})} $$\n",
        "$$\\Large{PE_{(pos, 2i+1)} = \\cos(pos / 10000^{2i / d_{model}})} $$\n",
        "\n",
        "Nota: El código a continuación lo implementa, pero en lugar de intercalar los senos y cosenos, los vectores de senos y cosenos simplemente se concatenan. Permutar los canales de esta manera es funcionalmente equivalente, y un poco más fácil de implementar y mostrar en las gráficas siguientes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Rz82wEs5biZ"
      },
      "outputs": [],
      "source": [
        "def positional_encoding(length, depth):\n",
        "  depth = depth/2 # mitad de las dimensiones para cada función\n",
        "\n",
        "  positions = np.arange(length)[:, np.newaxis]     # shape = (seq, 1)\n",
        "  depths = np.arange(depth)[np.newaxis, :]/depth   # shape = (1, depth)\n",
        "\n",
        "  angle_rates = 1 / (10000**depths)         # (1, depth)\n",
        "  angle_rads = positions * angle_rates      # (pos, depth)\n",
        "\n",
        "  pos_encoding = np.concatenate(\n",
        "      [np.sin(angle_rads), np.cos(angle_rads)],\n",
        "      axis=-1)\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ra1IcbzFhnmF"
      },
      "source": [
        "La función de codificación de posición es una pila de senos y cosenos que vibran a distintas frecuencias según su ubicación a lo largo de la profundidad del vector de incrustación. Vibran a través del eje de posición."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# para el ejemplo de la frase: El gato esta en la alfombra\n",
        "# en este caso se concatenaron las funciones\n",
        "positional_encoding(length=6, depth=4)"
      ],
      "metadata": {
        "id": "l-5crNrNhDh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKf4Ky2dhg0L"
      },
      "outputs": [],
      "source": [
        "pos_encoding = positional_encoding(length=2048, depth=512)\n",
        "\n",
        "# Revisar la dimensión\n",
        "print(pos_encoding.shape)\n",
        "\n",
        "plot_positional_encodings(pos_encoding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUknPLlVm99o"
      },
      "source": [
        "Ahora creemos la capa: `PositionEmbedding`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "838tmM1cm9cB"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbedding(tf.keras.layers.Layer):\n",
        "  def __init__(self, vocab_size, d_model):\n",
        "    super().__init__()\n",
        "    self.d_model = d_model\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True)\n",
        "    self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
        "\n",
        "  def compute_mask(self, *args, **kwargs):\n",
        "    return self.embedding.compute_mask(*args, **kwargs)\n",
        "\n",
        "  def call(self, x):\n",
        "    length = tf.shape(x)[1]\n",
        "    x = self.embedding(x)\n",
        "    # Este factor establece la escala relativa de la incrustación y la codificación_positonal.\n",
        "    # Es decir asegurar que tengan escalas similares\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    # Se suma las posiciones a los embeddings de los tokens\n",
        "    x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfz-EaCEDfUJ"
      },
      "outputs": [],
      "source": [
        "embed_pt = PositionalEmbedding(vocab_size=tokenizers.pt.get_vocab_size().numpy(), d_model=512)\n",
        "embed_en = PositionalEmbedding(vocab_size=tokenizers.en.get_vocab_size().numpy(), d_model=512)\n",
        "\n",
        "pt_emb = embed_pt(pt)\n",
        "en_emb = embed_en(en)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pt_emb"
      ],
      "metadata": {
        "id": "JR7ycV-Um8KM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mE9cEBWCMKOP"
      },
      "source": [
        "#### Capas de Adición y normalización\n",
        "\n",
        "<table>\n",
        "<tr>\n",
        "  <th colspan=2>Add y normalize</th>\n",
        "<tr>\n",
        "<tr>\n",
        "  <td>\n",
        "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/Add+Norm.png\"/>\n",
        "  </td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfz3WjFLTEk_"
      },
      "source": [
        "Estos bloques de \"Add & Norm\" se encuentran distribuidos a lo largo de todo el modelo Transformer. Cada uno combina una conexión residual y pasa el resultado a través de una capa de `LayerNormalization`.\n",
        "\n",
        "La manera más sencilla de organizar el código es estructurándolo alrededor de estos bloques residuales. En las siguientes secciones, definiremos clases de capas personalizadas para cada uno de ellos.\n",
        "\n",
        "Los bloques residuales \"Add & Norm\" se incluyen para que el entrenamiento sea eficiente. La conexión residual proporciona una ruta directa para el gradiente (y asegura que los vectores sean **actualizados** por las capas de atención en lugar de ser **reemplazados**), mientras que la normalización mantiene una escala razonable para las salidas.\n",
        "\n",
        "**Nota**: Las implementaciones que se muestran a continuación utilizan la capa `Add` para asegurar que las máscaras de Keras se propaguen correctamente (el operador `+` no lo hace).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJAJ2_VlPXrZ"
      },
      "source": [
        "#### Bases de la capa de atención"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tMGOGki35KI"
      },
      "source": [
        "Las capas de atención se utilizan a lo largo de todo el modelo Transformer. Todas ellas son idénticas, excepto por cómo se configura la atención. Cada una contiene una capa `layers.MultiHeadAttention`, una capa `layers.LayerNormalization` y una capa `layers.Add`.\n",
        "\n",
        "\n",
        "<table>\n",
        "<tr>\n",
        "  <th colspan=2>Capa de atención básica</th>\n",
        "<tr>\n",
        "<tr>\n",
        "  <td>\n",
        "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/BaseAttention.png\"/>\n",
        "  </td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6chjIrOVSYp"
      },
      "source": [
        "Para implementar estas capas de atención, comenzaremos con una clase base simple que sólo contenga definidos los componentes. Cada caso de uso se implementará como una subclase (framework)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VLa5QcdPpv5"
      },
      "outputs": [],
      "source": [
        "class BaseAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    self.add = tf.keras.layers.Add()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7QcPJvmv6ix"
      },
      "source": [
        "##### **Capa de atención cruzada**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8VJZqds37QC"
      },
      "source": [
        "En el centro literal del Transformer está la capa de atención cruzada. Esta capa conecta el codificador y el decodificador. Esta capa es el uso más directo de la atención en el modelo, realiza la misma tarea que el bloque de atención en el [Tutorial NMT con atención](https://www.tensorflow.org/text/tutorials/nmt_with_attention).\n",
        "\n",
        "<table>\n",
        "<tr>\n",
        "  <th colspan=1>Atención cruzada</th>\n",
        "<tr>\n",
        "<tr>\n",
        "  <td>\n",
        "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/CrossAttention.png\"/>\n",
        "  </td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhscgMUNUFWP"
      },
      "source": [
        "Para implementar esto, pasas la secuencia objetivo `x` como la `query` (consulta) y la secuencia de `context` (contexto) como la `key/value` (clave/valor) al llamar a la capa `mha`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfHVbJUWv8qp"
      },
      "outputs": [],
      "source": [
        "class CrossAttention(BaseAttention):\n",
        "  def call(self, x, context):\n",
        "    attn_output, attn_scores = self.mha(\n",
        "        query=x,\n",
        "        key=context,\n",
        "        value=context,\n",
        "        return_attention_scores=True)\n",
        "\n",
        "    # Almacenar los scores de atención para\n",
        "    # visualizarlos más adelante\n",
        "    self.last_attn_scores = attn_scores\n",
        "\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCQsj7ljKv-4"
      },
      "source": [
        "Ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qw1FJV5qRk79"
      },
      "outputs": [],
      "source": [
        "sample_ca = CrossAttention(num_heads=2, key_dim=512)\n",
        "\n",
        "print(pt_emb.shape)\n",
        "print(en_emb.shape)\n",
        "# cada token de la frase en inglés\n",
        "# será operados con todos los tokens de\n",
        "# la oración en portugués, esto pasa así\n",
        "# solo en entrenamiento\n",
        "print(sample_ca(en_emb, pt_emb).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6qrQxSpv34R"
      },
      "source": [
        "##### **Capa global de auto-atención**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-LbLRTkaTh5"
      },
      "source": [
        "Esta capa se encarga de procesar la secuencia contextual y de propagar la información a lo largo de la misma:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlYBQX3E388Y"
      },
      "source": [
        "<table>\n",
        "<tr>\n",
        "  <th colspan=1>La capa global de auto-atención</th>\n",
        "<tr>\n",
        "<tr>\n",
        "  <td>\n",
        "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/SelfAttention.png\"/>\n",
        "  </td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNqoTpn1wB3i"
      },
      "outputs": [],
      "source": [
        "class GlobalSelfAttention(BaseAttention):\n",
        "  def call(self, x):\n",
        "    attn_output = self.mha(\n",
        "        query=x,\n",
        "        value=x,\n",
        "        key=x)\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPn2D07-Jcmj"
      },
      "outputs": [],
      "source": [
        "sample_gsa = GlobalSelfAttention(num_heads=2, key_dim=512)\n",
        "\n",
        "print(pt_emb.shape)\n",
        "print(sample_gsa(pt_emb).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yq4NtLymD99-"
      },
      "source": [
        "##### **Capa de auto-atención causal**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VufkgF7caLze"
      },
      "source": [
        "Esta capa realiza un trabajo similar al de la capa de autoatención global, para la secuencia de salida:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KMEDiP63-hQ"
      },
      "source": [
        "<table>\n",
        "<tr>\n",
        "  <th colspan=1>Capa causal de auto-atención</th>\n",
        "<tr>\n",
        "<tr>\n",
        "  <td>\n",
        "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/CausalSelfAttention.png\"/>\n",
        "  </td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AtF1HYFEOYf"
      },
      "source": [
        "Esto debe tratarse de forma diferente a la capa de autoatención global del codificador.  \n",
        "\n",
        "Los transformers son un modelo «autorregresivo»: Generan el texto un token a la vez y devuelven esa salida a la entrada. Para que esto sea _eficiente_, estos modelos garantizan que la salida de cada elemento de la secuencia solo dependa de los elementos anteriores de la secuencia; los modelos son «causales»."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLYfIa8eiYgk"
      },
      "source": [
        "Para construir una capa de auto-atención causal, necesitas usar una máscara apropiada al calcular las puntuaciones de atención y sumar los `value`s de atención.\n",
        "\n",
        "Esto se gestiona automáticamente si pasas `use_causal_mask = True` a la capa `MultiHeadAttention` cuando la llamas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MMQ-AfKD99_"
      },
      "outputs": [],
      "source": [
        "class CausalSelfAttention(BaseAttention):\n",
        "  def call(self, x):\n",
        "    attn_output = self.mha(\n",
        "        query=x,\n",
        "        value=x,\n",
        "        key=x,\n",
        "        use_causal_mask = True)\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQBhYEZ2jfrX"
      },
      "source": [
        "Ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4dQuzvlD99_"
      },
      "outputs": [],
      "source": [
        "sample_csa = CausalSelfAttention(num_heads=2, key_dim=512)\n",
        "\n",
        "print(en_emb.shape)\n",
        "print(sample_csa(en_emb).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-IPCEkajleb"
      },
      "source": [
        "La salida de los primeros elementos de la secuencia no depende de los elementos posteriores, por lo que no debería importar si recorta los elementos antes o después de aplicar la capa:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwKlheQ-WVxl"
      },
      "outputs": [],
      "source": [
        "# ejemplo donde la sálida debe ser cercana a cero\n",
        "# ya que no deberia influir información posterior\n",
        "out1 = sample_csa(embed_en(en[:, :3]))\n",
        "out2 = sample_csa(embed_en(en))[:, :3]\n",
        "\n",
        "tf.reduce_max(abs(out1 - out2)).numpy()\n",
        "# nota omitir el warning por ahora"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLjScSWQv9M5"
      },
      "source": [
        "#### La red feed forward (MLP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pz0HBopX_VdU"
      },
      "source": [
        "El Transformer también incluye esta red neuronal feed-forward *point-wise* tanto en el codificador como en el decodificador:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDHMWoZ94AUU"
      },
      "source": [
        "<table>\n",
        "<tr>\n",
        "  <th colspan=1>La red feed forward (MLP)</th>\n",
        "<tr>\n",
        "<tr>\n",
        "  <td>\n",
        "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/FeedForward.png\"/>\n",
        "  </td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Yb-IV0Nlzd0"
      },
      "source": [
        "La red consiste en dos capas lineales (`tf.keras.layers.Dense`) con una función de activación ReLU entre ellas, y una capa de dropout. Al igual que con las capas de atención, el código aquí también incluye la conexión residual y la normalización:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAYLeu0uwXYK"
      },
      "outputs": [],
      "source": [
        "class FeedForward(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, dff, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.seq = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),\n",
        "      tf.keras.layers.Dense(d_model),\n",
        "      tf.keras.layers.Dropout(dropout_rate)\n",
        "    ])\n",
        "    self.add = tf.keras.layers.Add()\n",
        "    self.layer_norm = tf.keras.layers.LayerNormalization()\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.add([x, self.seq(x)])\n",
        "    x = self.layer_norm(x)\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQBlOVQU_hUt"
      },
      "source": [
        "Prueba:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-Y8Yqi1_hUt"
      },
      "outputs": [],
      "source": [
        "sample_ffn = FeedForward(512, 2048)\n",
        "\n",
        "print(en_emb.shape)\n",
        "print(sample_ffn(en_emb).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFv-FNYUmvpn"
      },
      "source": [
        "#### La capa encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zk-DAL2xv4PZ"
      },
      "source": [
        "El codificador contiene una pila de `N` capas de codificador. Donde cada `EncoderLayer` contiene una capa `GlobalSelfAttention` y una capa `FeedForward`:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgPaE3f44Cgh"
      },
      "source": [
        "<table>\n",
        "<tr>\n",
        "  <th colspan=1>La capa encoder</th>\n",
        "<tr>\n",
        "<tr>\n",
        "  <td>\n",
        "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/EncoderLayer.png\"/>\n",
        "  </td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kRUT__Ly9HH"
      },
      "source": [
        "Aquí la estructura de la capa `EncoderLayer`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncyS-Ms3i2x_"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self,*, d_model, num_heads, dff, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.self_attention = GlobalSelfAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate)\n",
        "\n",
        "    self.ffn = FeedForward(d_model, dff)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.self_attention(x)\n",
        "    x = self.ffn(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeXHMUlb6q6F"
      },
      "source": [
        "Prueba:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzZRXdO0mI48"
      },
      "outputs": [],
      "source": [
        "sample_encoder_layer = EncoderLayer(d_model=512, num_heads=8, dff=2048)\n",
        "\n",
        "print(pt_emb.shape)\n",
        "print(sample_encoder_layer(pt_emb).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE1H51Ajm0q1"
      },
      "source": [
        "#### El módulo Encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fym9ah11ykMd"
      },
      "source": [
        "Construyamos el encoder, agregandole la parte de embedings y la codificación posicional."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXI2B-Ad4ETO"
      },
      "source": [
        "<table>\n",
        "<tr>\n",
        "  <th colspan=1>El encoder</th>\n",
        "<tr>\n",
        "<tr>\n",
        "  <td>\n",
        "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/Encoder.png\"/>\n",
        "  </td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DA6sVo5rlzd3"
      },
      "source": [
        "El codificador consiste en:\n",
        "\n",
        "- Una capa `PositionalEmbedding` en la entrada.\n",
        "- Una pila de capas `EncoderLayer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpEox7gJ8FCI"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, *, num_layers, d_model, num_heads,\n",
        "               dff, vocab_size, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.pos_embedding = PositionalEmbedding(\n",
        "        vocab_size=vocab_size, d_model=d_model)\n",
        "\n",
        "    self.enc_layers = [\n",
        "        EncoderLayer(d_model=d_model,\n",
        "                     num_heads=num_heads,\n",
        "                     dff=dff,\n",
        "                     dropout_rate=dropout_rate)\n",
        "        for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "  def call(self, x):\n",
        "    # `x` es token-IDs shape: (batch, seq_len)\n",
        "    x = self.pos_embedding(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
        "\n",
        "    # añadir dropout.\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x)\n",
        "\n",
        "    return x  # Shape `(batch_size, seq_len, d_model)`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "texobMBHLBEU"
      },
      "source": [
        "Probar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDPXTvYgJH8s"
      },
      "outputs": [],
      "source": [
        "# Instanciar el Encoder.\n",
        "sample_encoder = Encoder(num_layers=4,\n",
        "                         d_model=512,\n",
        "                         num_heads=8,\n",
        "                         dff=2048,\n",
        "                         vocab_size=8500)\n",
        "# Fijar training en false\n",
        "sample_encoder_output = sample_encoder(pt, training=False)\n",
        "\n",
        "# Dimensiones\n",
        "print(pt.shape)\n",
        "print(sample_encoder_output.shape)  # Shape `(batch_size, input_seq_len, d_model)`.\n",
        "# ignorar los warnings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LO_48Owmx_o"
      },
      "source": [
        "#### La capa decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGxm57u6E4g2"
      },
      "source": [
        "El decodificador es ligeramente más compleja, con cada `DecoderLayer` conteniendo una capa `CausalSelfAttention`, una capa `CrossAttention` y una capa `FeedForward`:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZYER7rC4FmI"
      },
      "source": [
        "<table>\n",
        "<tr>\n",
        "  <th colspan=1>La capa decoder</th>\n",
        "<tr>\n",
        "<tr>\n",
        "  <td>\n",
        "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/DecoderLayer.png\"/>\n",
        "  </td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9SoX0-vd1hue"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self,\n",
        "               *,\n",
        "               d_model,\n",
        "               num_heads,\n",
        "               dff,\n",
        "               dropout_rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.causal_self_attention = CausalSelfAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate)\n",
        "\n",
        "    self.cross_attention = CrossAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate)\n",
        "\n",
        "    self.ffn = FeedForward(d_model, dff)\n",
        "\n",
        "  def call(self, x, context):\n",
        "    x = self.causal_self_attention(x=x)\n",
        "    x = self.cross_attention(x=x, context=context)\n",
        "\n",
        "    # Solo para efectos de visualización posterior\n",
        "    self.last_attn_scores = self.cross_attention.last_attn_scores\n",
        "\n",
        "    x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6T3RSR_6nJX"
      },
      "source": [
        "Probar la capa del decoder:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ne2Bqx8k71l0"
      },
      "outputs": [],
      "source": [
        "sample_decoder_layer = DecoderLayer(d_model=512, num_heads=8, dff=2048)\n",
        "\n",
        "sample_decoder_layer_output = sample_decoder_layer(\n",
        "    x=en_emb, context=pt_emb)\n",
        "\n",
        "print(en_emb.shape)\n",
        "print(pt_emb.shape)\n",
        "print(sample_decoder_layer_output.shape)  # `(batch_size, seq_len, d_model)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-uO6ls8m2O5"
      },
      "source": [
        "#### El módulo decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgj3c0TVF3Pb"
      },
      "source": [
        "De forma similar al Codificador, el Decodificador consiste en un `PositionalEmbedding` y una pila de `DecoderLayer`'s:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADGss2nT4Gt-"
      },
      "source": [
        "<table>\n",
        "<tr>\n",
        "  <th colspan=1>Capa Decoder + Embedding + PE</th>\n",
        "<tr>\n",
        "<tr>\n",
        "  <td>\n",
        "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/Decoder.png\"/>\n",
        "  </td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2q49vtv5lzd3"
      },
      "source": [
        "Definimos el Decoder extendiendo `tf.keras.layers.Layer`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5_d5-PLQXwY"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size,\n",
        "               dropout_rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size,\n",
        "                                             d_model=d_model)\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "    self.dec_layers = [\n",
        "        DecoderLayer(d_model=d_model, num_heads=num_heads,\n",
        "                     dff=dff, dropout_rate=dropout_rate)\n",
        "        for _ in range(num_layers)]\n",
        "\n",
        "    self.last_attn_scores = None\n",
        "\n",
        "  def call(self, x, context):\n",
        "    # `x` es token-IDs shape (batch, target_seq_len)\n",
        "    x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x  = self.dec_layers[i](x, context)\n",
        "\n",
        "    self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n",
        "\n",
        "    # EL shape de x es (batch_size, target_seq_len, d_model).\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eALcB--YMmLf"
      },
      "source": [
        "Probar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyHdG_jWPgKu"
      },
      "outputs": [],
      "source": [
        "# Instanciar el decoder\n",
        "sample_decoder = Decoder(num_layers=4,\n",
        "                         d_model=512,\n",
        "                         num_heads=8,\n",
        "                         dff=2048,\n",
        "                         vocab_size=8000)\n",
        "\n",
        "output = sample_decoder(\n",
        "    x=en,\n",
        "    context=pt_emb)\n",
        "\n",
        "# Shapes.\n",
        "print(en.shape)\n",
        "print(pt_emb.shape)\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ioJ4XJAUAReI"
      },
      "outputs": [],
      "source": [
        "sample_decoder.last_attn_scores.shape  # (batch, heads, target_seq, input_seq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3uvMP5vNuOV"
      },
      "source": [
        "Una vez creados el codificador y el decodificador Transformer, es hora de construir el modelo Transformer y entrenarlo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y54xnJnuYgJ7"
      },
      "source": [
        "## El Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSi8vBN1lzd4"
      },
      "source": [
        "You now have `Encoder` and `Decoder`. To complete the `Transformer` model, you need to put them together and add a final linear (`Dense`) layer which converts the resulting vector at each location into output token probabilities.\n",
        "\n",
        "The output of the decoder is the input to this final linear layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46nL2X_84Iud"
      },
      "source": [
        "<table>\n",
        "<tr>\n",
        "  <th colspan=1>El transformer</th>\n",
        "<tr>\n",
        "<tr>\n",
        "  <td>\n",
        "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/transformer.png\"/>\n",
        "  </td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5vSbJ_gKx7C"
      },
      "source": [
        "Crea el `Transformer` extendiendo `tf.keras.Model`:\n",
        "\n",
        "> Nota: El [artículo original](https://arxiv.org/pdf/1706.03762.pdf), sección 3.4, comparte la matriz de pesos entre la capa de embedding y la capa lineal final. Para mantener las cosas simples, este tutorial utiliza dos matrices de pesos separadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PED3bIpOYkBu"
      },
      "outputs": [],
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, *, num_layers, d_model, num_heads, dff,\n",
        "               input_vocab_size, target_vocab_size, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.encoder = Encoder(num_layers=num_layers, d_model=d_model,\n",
        "                           num_heads=num_heads, dff=dff,\n",
        "                           vocab_size=input_vocab_size,\n",
        "                           dropout_rate=dropout_rate)\n",
        "\n",
        "    self.decoder = Decoder(num_layers=num_layers, d_model=d_model,\n",
        "                           num_heads=num_heads, dff=dff,\n",
        "                           vocab_size=target_vocab_size,\n",
        "                           dropout_rate=dropout_rate)\n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    # Para usar el `.fit` del modelo keras usted debe pasar\n",
        "    # todas las inputs como el primer argumento\n",
        "    context, x  = inputs\n",
        "\n",
        "    context = self.encoder(context)  # (batch_size, context_len, d_model)\n",
        "\n",
        "    x = self.decoder(x, context)  # (batch_size, target_len, d_model)\n",
        "\n",
        "    # Capa final densa lineal\n",
        "    logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n",
        "\n",
        "    try:\n",
        "      # Eliminar las máscaras para que no afecten el cálculo del loss y métricas\n",
        "      # b/250038731 --> relacionado con este bug que fue reportado\n",
        "      del logits._keras_mask\n",
        "    except AttributeError:\n",
        "      pass\n",
        "\n",
        "    # retornar la salida final\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsINyf1VEQLC"
      },
      "source": [
        "### Hiperparámetros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjwMq_ixlzd5"
      },
      "source": [
        "Para mantener este ejemplo pequeño y relativamente rápido, el número de capas (`num_layers`), la dimensionalidad de los embeddings (`d_model`) y la dimensionalidad interna de la capa `FeedForward` (`dff`) se han reducido.\n",
        "\n",
        "El modelo base descrito en el artículo original del Transformer utilizaba `num_layers=6`, `d_model=512` y `dff=2048`.\n",
        "\n",
        "El número de cabezas de auto-atención será (`num_heads=4`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzyo6KDfVyhl"
      },
      "outputs": [],
      "source": [
        "num_layers = 2\n",
        "d_model = 128\n",
        "dff = 256\n",
        "num_heads = 4\n",
        "dropout_rate = 0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g08YOE-zHRqY"
      },
      "source": [
        "### Probemos el transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYbXDEhhlzd6"
      },
      "source": [
        "Instanciar el modelo `Transformer`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UiysUa--4tOU"
      },
      "outputs": [],
      "source": [
        "transformer = Transformer(\n",
        "    num_layers=num_layers,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    dff=dff,\n",
        "    input_vocab_size=tokenizers.pt.get_vocab_size().numpy(),\n",
        "    target_vocab_size=tokenizers.en.get_vocab_size().numpy(),\n",
        "    dropout_rate=dropout_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qbw3CYn2tQQx"
      },
      "source": [
        "Probar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8eO85hpFHmE"
      },
      "outputs": [],
      "source": [
        "output = transformer((pt, en))\n",
        "\n",
        "print(en.shape)\n",
        "print(pt.shape)\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olTLrK8pAcLd"
      },
      "outputs": [],
      "source": [
        "# acceder a los scores de atención\n",
        "attn_scores = transformer.decoder.dec_layers[-1].last_attn_scores\n",
        "print(attn_scores.shape)  # (batch, heads, target_seq, input_seq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfoBfC2oQtEy"
      },
      "source": [
        "## Training\n",
        "\n",
        "Tiempo de entrenar!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYEGhEOtzn5W"
      },
      "source": [
        "### Configurar el optimizador"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SL4G5bS6lzd5"
      },
      "source": [
        "Utilizar el optimizador Adam con un planificador personalizado para la tasa de aprendizaje según la fórmula del Transformer original. [paper](https://arxiv.org/abs/1706.03762).\n",
        "\n",
        "$$\\Large{lrate = d_{model}^{-0.5} * \\min(step{\\_}num^{-0.5}, step{\\_}num \\cdot warmup{\\_}steps^{-1.5})}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYQdOO1axwEI"
      },
      "outputs": [],
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    step = tf.cast(step, dtype=tf.float32)\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzXq5LWgRN63"
      },
      "source": [
        "Instanciar el optimizador (`tf.keras.optimizers.Adam`):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7r4scdulztRx"
      },
      "outputs": [],
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
        "                                     epsilon=1e-9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTb2S4RnQ8DU"
      },
      "source": [
        "Probar el scheduler para el learning rate:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xij3MwYVRAAS"
      },
      "outputs": [],
      "source": [
        "plot_lr_planificador(learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgkDE7hzo8r5"
      },
      "source": [
        "### Ajustar función de pérdida y métricas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6y7rNP5lzd6"
      },
      "source": [
        "Dado que las secuencias objetivo están rellenadas (padded), es importante aplicar una máscara de padding al calcular la pérdida. Utiliza la función de pérdida de entropía cruzada (`tf.keras.losses.SparseCategoricalCrossentropy`):"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def masked_loss(label, pred):\n",
        "  mask = label != 0 # Indica padding\n",
        "  # from_logits=True indica que las predicciones no han pasado por softmax.\n",
        "  # reduction='none' hace que se devuelva la pérdida por cada ejemplo.\n",
        "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none')\n",
        "\n",
        "  loss = loss_object(label, pred)\n",
        "  mask = tf.cast(mask, dtype=loss.dtype)\n",
        "  # Aplica la máscara a la pérdida, multiplicando las pérdidas de las posiciones\n",
        "  # de padding por cero, lo que las elimina del cálculo total.\n",
        "  loss *= mask\n",
        "\n",
        "  # Calcula la pérdida promedio solo sobre las posiciones no enmascaradas.\n",
        "  # Suma todas las pérdidas y divide por el número de posiciones no enmascaradas.\n",
        "  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
        "  return loss\n",
        "\n",
        "\n",
        "def masked_accuracy(label, pred):\n",
        "  # Obtiene la clase predicha con la probabilidad más alta (el índice máximo)\n",
        "  # a lo largo del eje de vocabulario (axis=2).\n",
        "  pred = tf.argmax(pred, axis=2)\n",
        "  # Convierte las etiquetas al mismo tipo de dato que las predicciones para comparar.\n",
        "  label = tf.cast(label, pred.dtype)\n",
        "  # Crea un tensor booleano donde True indica que la predicción coincide con la etiqueta.\n",
        "  match = label == pred\n",
        "\n",
        "  # Crea una máscara donde True indica que la etiqueta no es padding (no es 0).\n",
        "  mask = label != 0\n",
        "\n",
        "  # Combina la máscara con las coincidencias. Solo consideramos como \"match\"\n",
        "  # las predicciones correctas en las posiciones que no son padding.\n",
        "  match = match & mask\n",
        "\n",
        "  # Convierte los booleanos de 'match' y 'mask' a float para poder calcular la media.\n",
        "  match = tf.cast(match, dtype=tf.float32)\n",
        "  mask = tf.cast(mask, dtype=tf.float32)\n",
        "  # Calcula la precisión promedio solo sobre las posiciones no enmascaradas.\n",
        "  # Suma las coincidencias (1 para cada predicción correcta no enmascarada)\n",
        "  # y divide por el número total de posiciones no enmascaradas.\n",
        "  return tf.reduce_sum(match)/tf.reduce_sum(mask)"
      ],
      "metadata": {
        "id": "Vy6Rsqj1O8y5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYEasEOsdn5W"
      },
      "source": [
        "### Entrenar el modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mk8vwuN24hafK"
      },
      "source": [
        "Con todo listo, vamos a compilar usando `model.compile`, y luego entrenar con `model.fit`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Una1v0hDlIsT"
      },
      "outputs": [],
      "source": [
        "transformer.compile(\n",
        "    loss=masked_loss,\n",
        "    optimizer=optimizer,\n",
        "    metrics=[masked_accuracy])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jg35qKvVlctp"
      },
      "outputs": [],
      "source": [
        "transformer.fit(train_batches,\n",
        "                epochs=10,\n",
        "                validation_data=val_batches)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxKpqCbzSW6z"
      },
      "source": [
        "## Ejecutar inferencia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mk8vwuN1SafK"
      },
      "source": [
        "Ahora puedes probar el modelo realizando una traducción. Los siguientes pasos se utilizan para la inferencia:\n",
        "\n",
        "* Codifica la frase de entrada utilizando el tokenizador portugués (`tokenizers.pt`). Esta es la entrada del codificador.\n",
        "* La entrada del decodificador se inicializa con el token `[START]`.\n",
        "* Calcula las máscaras de padding y las máscaras causales (para la auto-atención causal).\n",
        "* El `decodificador` luego genera las predicciones observando la `salida del codificador` y su propia salida (auto-atención).\n",
        "* Concatena el token predicho a la entrada del decodificador y lo pasa de nuevo al decodificador.\n",
        "* En este enfoque, el decodificador predice el siguiente token basándose en los tokens que predijo previamente.\n",
        "\n",
        "Nota: El modelo está optimizado para un _entrenamiento eficiente_ y realiza una predicción del siguiente token para cada token en la salida simultáneamente. Esto es redundante durante la inferencia, y solo se utiliza la última predicción. Este modelo puede hacerse más eficiente para la inferencia si solo se calcula la última predicción cuando se ejecuta en modo de inferencia (`training=False`).\n",
        "\n",
        "Define la clase `Translator` extendiendo `tf.Module`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eY_uXsOhSmbb"
      },
      "outputs": [],
      "source": [
        "class Translator(tf.Module):\n",
        "  def __init__(self, tokenizers, transformer):\n",
        "    self.tokenizers = tokenizers\n",
        "    self.transformer = transformer\n",
        "\n",
        "  def __call__(self, sentence, max_length=MAX_TOKENS):\n",
        "    # La frase de entrada es portugués, por lo que se añaden los tokens `[START]` y `[END]`.\n",
        "    assert isinstance(sentence, tf.Tensor)\n",
        "    if len(sentence.shape) == 0:\n",
        "      sentence = sentence[tf.newaxis]\n",
        "\n",
        "    sentence = self.tokenizers.pt.tokenize(sentence).to_tensor()\n",
        "\n",
        "    encoder_input = sentence\n",
        "\n",
        "    # Como el lenguaje de sálida es inglés\n",
        "    # Inicializar con el token `[START]`\n",
        "    start_end = self.tokenizers.en.tokenize([''])[0]\n",
        "    start = start_end[0][tf.newaxis]\n",
        "    end = start_end[1][tf.newaxis]\n",
        "\n",
        "    # con el TensorArray es posible hacer seguimiento al blucle dinámico\n",
        "    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
        "    output_array = output_array.write(0, start)\n",
        "\n",
        "    for i in tf.range(max_length):\n",
        "      # convierte la lista de tokens generados secuencialmente\n",
        "      # (almacenada en el TensorArray) en un tensor con la forma (1, secuencia_de_tokens),\n",
        "      # donde la secuencia de tokens representa la traducción generada hasta ese punto.\n",
        "      output = tf.transpose(output_array.stack())\n",
        "      predictions = self.transformer([encoder_input, output], training=False)\n",
        "\n",
        "      # Seleccionar las predicciones para el último token de `seq_len`.\n",
        "      predictions = predictions[:, -1:, :]  # Shape `(batch_size, 1, vocab_size)`.\n",
        "      # Encontrar la pos del token id con la mayor probabilidad\n",
        "      predicted_id = tf.argmax(predictions, axis=-1)\n",
        "\n",
        "      # Concatenar la predicción con los anteriores tokens del decoder.\n",
        "      output_array = output_array.write(i+1, predicted_id[0])\n",
        "\n",
        "      if predicted_id == end:\n",
        "        break\n",
        "\n",
        "    output = tf.transpose(output_array.stack())\n",
        "    # La dimensión de sálida es `(1, tokens)`.\n",
        "    text = tokenizers.en.detokenize(output)[0]  # Shape: `()`.\n",
        "\n",
        "    tokens = tokenizers.en.lookup(output)[0]\n",
        "\n",
        "    # `@tf.function` optimiza la función, dificultando el acceso\n",
        "    # a valores dinámicos en bucles. Recalculamos la atención\n",
        "    # final fuera del bucle para obtener `attention_weights`.\n",
        "    self.transformer([encoder_input, output[:,:-1]], training=False)\n",
        "    attention_weights = self.transformer.decoder.last_attn_scores\n",
        "\n",
        "    return text, tokens, attention_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJ3o-65iS6CN"
      },
      "source": [
        "Nota: Esta función utiliza un bucle unrolled, no un bucle dinámico. Genera `MAX_TOKENS` en cada llamada. Consulta el tutorial de [NMT con atención](https://www.tensorflow.org/text/tutorials/nmt_with_attention) para ver un ejemplo de implementación con un bucle dinámico, que puede ser mucho más eficiente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeUJafisS435"
      },
      "source": [
        "Probemos la traducción:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NjbvpHUTEia"
      },
      "outputs": [],
      "source": [
        "translator = Translator(tokenizers, transformer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buUeDo58TIoD"
      },
      "source": [
        "Ejemplo 1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9CEm4cuTGtw"
      },
      "outputs": [],
      "source": [
        "sentence = 'este é um problema que temos que resolver.'\n",
        "ground_truth = 'this is a problem we have to solve .'\n",
        "\n",
        "translated_text, translated_tokens, attention_weights = translator(\n",
        "    tf.constant(sentence))\n",
        "plot_traduccion(sentence, translated_text, ground_truth)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfJrFBZ6TJxc"
      },
      "source": [
        "Ejemplo 2:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elmz_Ly7THuJ"
      },
      "outputs": [],
      "source": [
        "sentence = 'os meus vizinhos ouviram sobre esta ideia.'\n",
        "ground_truth = 'and my neighboring homes heard about this idea .'\n",
        "\n",
        "translated_text, translated_tokens, attention_weights = translator(\n",
        "    tf.constant(sentence))\n",
        "plot_traduccion(sentence, translated_text, ground_truth)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY7NfEjrTOCr"
      },
      "source": [
        "Ejemplo 3:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmmtPo3vTOwj"
      },
      "outputs": [],
      "source": [
        "sentence = 'vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.'\n",
        "ground_truth = \"so i'll just share with you some stories very quickly of some magical things that have happened.\"\n",
        "\n",
        "translated_text, translated_tokens, attention_weights = translator(\n",
        "    tf.constant(sentence))\n",
        "plot_traduccion(sentence, translated_text, ground_truth)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aB_03k0kTQLb"
      },
      "source": [
        "## Crear los plots de atención"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miZXl9i-TSs6"
      },
      "source": [
        "Usando la clase traductor `Translator` que almacena los scores de atención, podemos usarlos para ver su relevancia:\n",
        "\n",
        "Por ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3m2wcNLTU8K"
      },
      "outputs": [],
      "source": [
        "sentence = 'este é o primeiro livro que eu fiz.'\n",
        "ground_truth = \"this is the first book i've ever done.\"\n",
        "\n",
        "translated_text, translated_tokens, attention_weights = translator(\n",
        "    tf.constant(sentence))\n",
        "plot_traduccion(sentence, translated_text, ground_truth)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rhE_LW7TZ40"
      },
      "source": [
        "Crear una función que grafique la atención cuando se genera un token:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yI4YWU2uXDeW"
      },
      "outputs": [],
      "source": [
        "head = 0\n",
        "# Shape: `(batch=1, num_heads, seq_len_q, seq_len_k)`.\n",
        "attention_heads = tf.squeeze(attention_weights, 0)\n",
        "attention = attention_heads[head]\n",
        "attention.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "facNouzOXMSu"
      },
      "source": [
        "Son las inputs tokens en portugués:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMEpyioWTmSN"
      },
      "outputs": [],
      "source": [
        "in_tokens = tf.convert_to_tensor([sentence])\n",
        "in_tokens = tokenizers.pt.tokenize(in_tokens).to_tensor()\n",
        "in_tokens = tokenizers.pt.lookup(in_tokens)[0]\n",
        "in_tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLg9HTKCXPKz"
      },
      "source": [
        "Estas son las sálidas (tokens en inglés, traducción)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzvIo5uYTnHG"
      },
      "outputs": [],
      "source": [
        "translated_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBMujUb1Tr4C"
      },
      "outputs": [],
      "source": [
        "plot_attention_weights(sentence,\n",
        "                       translated_tokens,\n",
        "                       attention_weights[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zz4uIDbT1OU"
      },
      "source": [
        "## Exportar el modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zunHPJJzT4Cz"
      },
      "source": [
        "Hemos probado el modelo y la inferencia funciona. A continuación, puedes exportarlo como un `tf.saved_model`. Para aprender cómo guardar y cargar un modelo en formato SavedModel, consulta [esta guía](https://www.tensorflow.org/guide/saved_model).\n",
        "\n",
        "Crea una clase llamada `ExportTranslator` extendiendo la subclase `tf.Module` con un `@tf.function` en el método `__call__`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZhv5h4AT_n5"
      },
      "outputs": [],
      "source": [
        "class ExportTranslator(tf.Module):\n",
        "  def __init__(self, translator):\n",
        "    self.translator = translator\n",
        "\n",
        "  @tf.function(input_signature=[tf.TensorSpec(shape=[], dtype=tf.string)])\n",
        "  def __call__(self, sentence):\n",
        "    (result,\n",
        "     tokens,\n",
        "     attention_weights) = self.translator(sentence, max_length=MAX_TOKENS)\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wm1_eRPvUCUm"
      },
      "outputs": [],
      "source": [
        "# Empaqueta el objeto `translator` en la nueva clase `ExportTranslator` creada:\n",
        "translator = ExportTranslator(translator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VPH4T5XUDnc"
      },
      "source": [
        "Dado que el modelo está decodificando las predicciones utilizando `tf.argmax`, las predicciones son deterministas. El modelo original y uno recargado desde su `SavedModel` deberían dar predicciones idénticas:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GITRCiAYUE5w"
      },
      "outputs": [],
      "source": [
        "translator('este é o primeiro livro que eu fiz.').numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_v--e1XmUFw3"
      },
      "outputs": [],
      "source": [
        "tf.saved_model.save(translator, export_dir='translator')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KJSQEzlUGo-"
      },
      "outputs": [],
      "source": [
        "reloaded = tf.saved_model.load('translator')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIVpKWBNUHhr"
      },
      "outputs": [],
      "source": [
        "reloaded('este é o primeiro livro que eu fiz.').numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri2i6cTxUI00"
      },
      "source": [
        "## Conclusión\n",
        "\n",
        "En este tutorial aprendiste sobre:\n",
        "\n",
        "* Los Transformers y su importancia en el aprendizaje automático\n",
        "* Atención, auto-atención y atención multi-cabeza\n",
        "* Codificación posicional con embeddings\n",
        "* La arquitectura codificador-decodificador del Transformer original\n",
        "* Enmascaramiento en la auto-atención\n",
        "* Cómo juntar todo para traducir texto\n",
        "\n",
        "Las desventajas de esta arquitectura son:\n",
        "\n",
        "- Para una serie temporal, la salida para un paso de tiempo se calcula a partir de la *historia completa* en lugar de solo las entradas y el estado oculto actual. Esto _podría_ ser menos eficiente.\n",
        "- Si la entrada tiene una relación temporal/espacial, como texto o imágenes, debe añadirse alguna codificación posicional o el modelo efectivamente verá una bolsa de palabras."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Este notebook se basó en el notebook de [Neural Machine Translation with a Transformer and Keras](https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/transformer.ipynb) para el curso de Deep Learning práctico en 3 semanas.*"
      ],
      "metadata": {
        "id": "XrkZTt0EqMU4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BYAxmQVSqljB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}